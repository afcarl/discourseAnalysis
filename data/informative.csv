title	plot
A priori and a posteriori	"The Latin phrases a priori (lit. ""from the earlier"") and a posteriori (lit. ""from the latter"") are philosophical terms of art popularized by Immanuel Kant's Critique of Pure Reason (first published in 1781, second edition in 1787), one of the most influential works in the history of philosophy. However, in their Latin forms they appear in Latin translations of Euclid's Elements, of about 300 BC, a work widely considered during the early European modern period as the model for precise thinking.
These terms are used with respect to reasoning (epistemology) to distinguish necessary conclusions from first premises (i.e., what must come before sense observation) from conclusions based on sense observation (which must follow it). Thus, the two kinds of knowledge, justification, or argument may be glossed:
A priori knowledge or justification is independent of experience, as with mathematics (3+2=5), tautologies (""All bachelors are unmarried""), and deduction from pure reason (e.g., ontological proofs).
A posteriori knowledge or justification is dependent on experience or empirical evidence, as with most aspects of science and personal knowledge.
There are many points of view on these two types of knowledge, and their relationship is one of the oldest problems in modern philosophy.
The terms a priori and a posteriori are primarily used as adjectives to modify the noun ""knowledge"" (for example, ""a priori knowledge""). However, ""a priori"" is sometimes used to modify other nouns, such as ""truth"". Philosophers also may use ""apriority"" and ""aprioricity"" as nouns to refer (approximately) to the quality of being ""a priori"".
Although definitions and use of the terms have varied in the history of philosophy, they have consistently labeled two separate epistemological notions. See also the related distinctions: deductive/inductive, analytic/synthetic, necessary/contingent."
Abbasid	"The Abbasid Caliphate (/əˈbæsᵻd/ or /ˈæbəsᵻd/ Arabic: الخلافة العباسية‎ al-Khilāfah al-‘Abbāsīyah) was the third of the Islamic caliphates to succeed the Islamic prophet Muhammad. The Abbasid dynasty descended from Muhammad's youngest uncle, Abbas ibn Abd al-Muttalib (566–653 CE), from whom the dynasty takes its name. They ruled as caliphs, for most of their period from their capital in Baghdad in modern-day Iraq, after assuming authority over the Muslim empire from the Umayyads in 750 CE (132 AH).
The Abbasid caliphate first centered its government in Kufa, but in 762 the caliph Al-Mansur founded the city of Baghdad, north of the Sasanian capital city of Ctesiphon. The choice of a capital so close to Persia proper reflected a growing reliance on Persian bureaucrats, most notably of the Barmakid family, to govern the territories conquered by Arab Muslims, as well as an increasing inclusion of non-Arab Muslims in the ummah. Despite this initial cooperation, the Abbasids of the late 8th century had alienated both Arab mawali and Iranian bureaucrats, and were forced to cede authority over Al-Andalus and Maghreb to the Umayyads, Morocco to the Idrisid dynasty, Ifriqiya to the Aghlabids, and Egypt to the Shi'ite Caliphate of the Fatimids. The political power of the caliphs largely ended with the rise of the Buyids and the Seljuq Turks. Although Abbasid leadership over the vast Islamic empire was gradually reduced to a ceremonial religious function, the dynasty retained control over its Mesopotamian demesne. The capital city of Baghdad became a center of science, culture, philosophy and invention during the Golden Age of Islam.
This period of cultural fruition ended in 1258 with the sack of Baghdad by the Mongols under Hulagu Khan. The Abbasid line of rulers, and Muslim culture in general, recentered themselves in the Mamluk capital of Cairo in 1261. Though lacking in political power, the dynasty continued to claim authority in religious matters until after the Ottoman conquest of Egypt (1517)."
Actualization	"Self-actualization is a term that has been used in various psychology theories, often in slightly different ways. The term was originally introduced by the organismic theorist Kurt Goldstein for the motive to realize one's full potential. Expressing one's creativity, quest for spiritual enlightenment, pursuit of knowledge, and the desire to give to society are examples of self-actualization. In Goldstein's view, it is the organism's master motive, the only real motive: ""the tendency to actualize itself as fully as possible is the basic drive... the drive of self-actualization."" Carl Rogers similarly wrote of ""the curative force in psychotherapy – man's tendency to actualize himself, to become his potentialities... to express and activate all the capacities of the organism."" The concept was brought most fully to prominence in Abraham Maslow's hierarchy of needs theory as the final level of psychological development that can be achieved when all basic and mental needs are essentially fulfilled and the ""actualization"" of the full personal potential takes place, although he adapted this viewpoint later on in life, and saw it more flexibly.
Self-actualization can be seen as similar to words and concepts such as self-discovery, self-reflection, self-realisation and self-exploration.
As Abraham Maslow noted, the basic needs of humans must be met (e.g. food, shelter, warmth, security, sense of belonging) before a person can achieve self-actualization – the need to be good, to be fully alive and to find meaning in life. Research shows that when people live lives that are different from their true nature and capabilities, they are less likely to be happy than those whose goals and lives match. For example, someone who has inherent potential to be a great artist or teacher may never realize his/her talents if their energy is focused on attaining the basic needs of humans."
Al-Kindi	"Abu Yūsuf Yaʻqūb ibn ʼIsḥāq aṣ-Ṣabbāḥ al-Kindī (Arabic: أبو يوسف يعقوب بن إسحاق الصبّاح الكندي‎, Latin: Alkindus) (c. 801–873 AD), known as ""the Philosopher of the Arabs"", was a Muslim Arab philosopher, polymath, mathematician, physician and musician. Al-Kindi was the first of the Muslim peripatetic philosophers, and is unanimously hailed as the ""father of Islamic or Arabic philosophy"" for his synthesis, adaptation and promotion of Greek and Hellenistic philosophy in the Muslim world.
Al-Kindi was a descendant of the Kinda tribe. He was born in Basra and educated in Baghdad. Al-Kindi became a prominent figure in the House of Wisdom, and a number of Abbasid Caliphs appointed him to oversee the translation of Greek scientific and philosophical texts into the Arabic language. This contact with ""the philosophy of the ancients"" (as Greek philosophy was often referred to by Muslim scholars) had a profound effect on his intellectual development, and led him to write hundreds of original treatises of his own on a range of subjects ranging from metaphysics, ethics, logic and psychology, to medicine, pharmacology, mathematics, astronomy, astrology and optics, and further afield to more practical topics like perfumes, swords, jewels, glass, dyes, zoology, tides, mirrors, meteorology and earthquakes.
In the field of mathematics, al-Kindi played an important role in introducing Indian numerals to the Islamic and Christian world. He was a pioneer in cryptanalysis and devised several new methods of breaking ciphers. Using his mathematical and medical expertise, he was able to develop a scale that would allow doctors to quantify the potency of their medication.
The central theme underpinning al-Kindi's philosophical writings is the compatibility between philosophy and other ""orthodox"" Islamic sciences, particularly theology. And many of his works deal with subjects that theology had an immediate interest in. These include the nature of God, the soul and prophetic knowledge. But despite the important role he played in making philosophy accessible to Muslim intellectuals, his own philosophical output was largely overshadowed by that of al-Farabi and very few of his texts are available for modern scholars to examine."
Albert Einstein	"Albert Einstein (/ˈaɪnstaɪn/; German: [ˈalbɛɐ̯t ˈaɪnʃtaɪn]; 14 March 1879 – 18 April 1955) was a German-born theoretical physicist. He developed the general theory of relativity, one of the two pillars of modern physics (alongside quantum mechanics). Einstein's work is also known for its influence on the philosophy of science. Einstein is best known in popular culture for his mass–energy equivalence formula E = mc2 (which has been dubbed ""the world's most famous equation""). He received the 1921 Nobel Prize in Physics for his ""services to theoretical physics"", in particular his discovery of the law of the photoelectric effect, a pivotal step in the evolution of quantum theory.
Near the beginning of his career, Einstein thought that Newtonian mechanics was no longer enough to reconcile the laws of classical mechanics with the laws of the electromagnetic field. This led to the development of his special theory of relativity. He realized, however, that the principle of relativity could also be extended to gravitational fields, and with his subsequent theory of gravitation in 1916, he published a paper on general relativity. He continued to deal with problems of statistical mechanics and quantum theory, which led to his explanations of particle theory and the motion of molecules. He also investigated the thermal properties of light which laid the foundation of the photon theory of light. In 1917, Einstein applied the general theory of relativity to model the large-scale structure of the universe.
He was visiting the United States when Adolf Hitler came to power in 1933 and, being Jewish, did not go back to Germany, where he had been a professor at the Berlin Academy of Sciences. He settled in the U.S., becoming an American citizen in 1940. On the eve of World War II, he endorsed a letter to President Franklin D. Roosevelt alerting him to the potential development of ""extremely powerful bombs of a new type"" and recommending that the U.S. begin similar research. This eventually led to what would become the Manhattan Project. Einstein supported defending the Allied forces, but largely denounced the idea of using the newly discovered nuclear fission as a weapon. Later, with the British philosopher Bertrand Russell, Einstein signed the Russell–Einstein Manifesto, which highlighted the danger of nuclear weapons. Einstein was affiliated with the Institute for Advanced Study in Princeton, New Jersey, until his death in 1955.
Einstein published more than 300 scientific papers along with over 150 non-scientific works. On 5 December 2014, universities and archives announced the release of Einstein's papers, comprising more than 30,000 unique documents. Einstein's intellectual achievements and originality have made the word ""Einstein"" synonymous with ""genius""."
Algebra	"Algebra (from Arabic ""al-jabr"" meaning ""reunion of broken parts"") is one of the broad parts of mathematics, together with number theory, geometry and analysis. In its most general form, algebra is the study of mathematical symbols and the rules for manipulating these symbols; it is a unifying thread of almost all of mathematics. As such, it includes everything from elementary equation solving to the study of abstractions such as groups, rings, and fields. The more basic parts of algebra are called elementary algebra, the more abstract parts are called abstract algebra or modern algebra. Elementary algebra is generally considered to be essential for any study of mathematics, science, or engineering, as well as such applications as medicine and economics. Abstract algebra is a major area in advanced mathematics, studied primarily by professional mathematicians. Much early work in algebra, as the Arabic origin of its name suggests, was done in the Middle East, by mathematicians such as al-Khwārizmī (780 – 850) and Omar Khayyam (1048–1131).
Elementary algebra differs from arithmetic in the use of abstractions, such as using letters to stand for numbers that are either unknown or allowed to take on many values. For example, in  the letter  is unknown, but the law of inverses can be used to discover its value: . In E = mc2, the letters  and  are variables, and the letter  is a constant, the speed of light in a vacuum. Algebra gives methods for solving equations and expressing formulas that are much easier (for those who know how to use them) than the older method of writing everything out in words.
The word algebra is also used in certain specialized ways. A special kind of mathematical object in abstract algebra is called an ""algebra"", and the word is used, for example, in the phrases linear algebra and algebraic topology.
A mathematician who does research in algebra is called an algebraist."
Antibiotic	"Antibiotics, also called antibacterials, are a type of antimicrobial drug used in the treatment and prevention of bacterial infection. They may either kill or inhibit the growth of bacteria. A limited number of antibiotics also possess antiprotozoal activity. Antibiotics are not effective against viruses such as the common cold or influenza, and may be harmful when taken inappropriately.
In 1928, Alexander Fleming identified penicillin, the first chemical compound with antibiotic properties. Fleming was working on a culture of disease-causing bacteria when he noticed the spores of little green mold in one of his culture plates. He observed that the presence of the mold killed or prevented the growth of the bacteria.
Antibiotics revolutionized medicine in the 20th century, and have together with vaccination led to the near eradication of diseases such as tuberculosis in the developed world. Their effectiveness and easy access led to overuse, especially in livestock raising, prompting bacteria to develop resistance. This has led to widespread problems with antimicrobial and antibiotic resistance, so much as to prompt the World Health Organization to classify antimicrobial resistance as a ""serious threat [that] is no longer a prediction for the future, it is happening right now in every region of the world and has the potential to affect anyone, of any age, in any country"".
The era of antibacterial chemotherapy began with the discovery of arsphenamine, first synthesized by Alfred Bertheim and Paul Ehrlich in 1907, used to treat syphilis. The first systemically active antibacterial drug, prontosil was discovered in 1933 by Gerhard Domagk, for which he was awarded the 1939 Nobel Prize. All classes of antibiotics in use today were first discovered prior to the mid 1980s.
Sometimes the term antibiotic is used to refer to any substance used against microbes, synonymous to antimicrobial, leading to the widespread but incorrect belief that antibiotics can be used against viruses. Some sources distinguish between antibacterial and antibiotic; antibacterials used in soaps and cleaners etc., but not as medicine. This article treats the terms as synonymous and according to the most widespread definition of antibiotics being a substance used against bacteria."
Antibiotics	"Antibiotics, also called antibacterials, are a type of antimicrobial drug used in the treatment and prevention of bacterial infection. They may either kill or inhibit the growth of bacteria. A limited number of antibiotics also possess antiprotozoal activity. Antibiotics are not effective against viruses such as the common cold or influenza, and may be harmful when taken inappropriately.
In 1928, Alexander Fleming identified penicillin, the first chemical compound with antibiotic properties. Fleming was working on a culture of disease-causing bacteria when he noticed the spores of little green mold in one of his culture plates. He observed that the presence of the mold killed or prevented the growth of the bacteria.
Antibiotics revolutionized medicine in the 20th century, and have together with vaccination led to the near eradication of diseases such as tuberculosis in the developed world. Their effectiveness and easy access led to overuse, especially in livestock raising, prompting bacteria to develop resistance. This has led to widespread problems with antimicrobial and antibiotic resistance, so much as to prompt the World Health Organization to classify antimicrobial resistance as a ""serious threat [that] is no longer a prediction for the future, it is happening right now in every region of the world and has the potential to affect anyone, of any age, in any country"".
The era of antibacterial chemotherapy began with the discovery of arsphenamine, first synthesized by Alfred Bertheim and Paul Ehrlich in 1907, used to treat syphilis. The first systemically active antibacterial drug, prontosil was discovered in 1933 by Gerhard Domagk, for which he was awarded the 1939 Nobel Prize. All classes of antibiotics in use today were first discovered prior to the mid 1980s.
Sometimes the term antibiotic is used to refer to any substance used against microbes, synonymous to antimicrobial, leading to the widespread but incorrect belief that antibiotics can be used against viruses. Some sources distinguish between antibacterial and antibiotic; antibacterials used in soaps and cleaners etc., but not as medicine. This article treats the terms as synonymous and according to the most widespread definition of antibiotics being a substance used against bacteria."
Antibody	"An antibody (Ab), also known as an immunoglobulin (Ig), is a large, Y-shaped protein produced mainly by plasma cells that is used by the immune system to identify and neutralize pathogens such as bacteria and viruses. The antibody recognizes a unique molecule of the harmful agent, called an antigen, via the variable region. Each tip of the ""Y"" of an antibody contains a paratope (analogous to a lock) that is specific for one particular epitope (similarly analogous to a key) on an antigen, allowing these two structures to bind together with precision. Using this binding mechanism, an antibody can tag a microbe or an infected cell for attack by other parts of the immune system, or can neutralize its target directly (for example, by blocking a part of a microbe that is essential for its invasion and survival). Depending on the antigen, the binding may impede the biological process causing the disease or may recruit macrophages to destroy the foreign substance. The ability of an antibody to communicate with the other components of the immune system is mediated via its Fc region (located at the base of the ""Y""), which contains a conserved glycosylation site involved in these interactions. The production of antibodies is the main function of the humoral immune system.
Antibodies are secreted by B cells of the adaptive immune system, mostly by differentiated B cells called plasma cells. Antibodies can occur in two physical forms, a soluble form that is secreted from the cell to be free in the blood plasma, and a membrane-bound form that is attached to the surface of a B cell and is referred to as the B-cell receptor (BCR). The BCR is found only on the surface of B cells and facilitates the activation of these cells and their subsequent differentiation into either antibody factories called plasma cells or memory B cells that will survive in the body and remember that same antigen so the B cells can respond faster upon future exposure. In most cases, interaction of the B cell with a T helper cell is necessary to produce full activation of the B cell and, therefore, antibody generation following antigen binding. Soluble antibodies are released into the blood and tissue fluids, as well as many secretions to continue to survey for invading microorganisms.
Antibodies are glycoproteins belonging to the immunoglobulin superfamily. They constitute most of the gamma globulin fraction of the blood proteins. They are typically made of basic structural units—each with two large heavy chains and two small light chains. There are several different types of antibody heavy chains based on five different types of crystallisable fragments (Fc) that may be attached to the antigen-binding fragments. The five different types of Fc regions allow antibodies to be grouped into five isotypes. Each Fc region of a particular antibody isotype is able to bind to its specific Fc Receptor (except for IgD, which is essentially the BCR), thus allowing the antigen-antibody complex to mediate different roles depending on which FcR it binds. The ability of an antibody to bind to its corresponding FcR is further modulated by the structure of the glycan(s) present at conserved sites within its Fc region. The ability of antibodies to bind to FcRs helps to direct the appropriate immune response for each different type of foreign object they encounter. For example, IgE is responsible for an allergic response consisting of mast cell degranulation and histamine release. IgE's Fab paratope binds to allergic antigen, for example house dust mite particles, while its Fc region binds to Fc receptor ε. The allergen-IgE-FcRε interaction mediates allergic signal transduction to induce conditions such as asthma.
Though the general structure of all antibodies is very similar, a small region at the tip of the protein is extremely variable, allowing millions of antibodies with slightly different tip structures, or antigen-binding sites, to exist. This region is known as the hypervariable region. Each of these variants can bind to a different antigen. This enormous diversity of antibody paratopes on the antigen-binding fragments allows the immune system to recognize an equally wide variety of antigens. The large and diverse population of antibody paratope is generated by random recombination events of a set of gene segments that encode different antigen-binding sites (or paratopes), followed by random mutations in this area of the antibody gene, which create further diversity. This recombinational process that produces clonal antibody paratope diversity is called V(D)J or VJ recombination. Basically, the antibody paratope is polygenic, made up of three genes, V, D, and J. Each paratope locus is also polymorphic, such that during antibody production, one allele of V, one of D, and one of J is chosen. These gene segments are then joined together using random genetic recombination to produce the paratope. The regions where the genes are randomly recombined together is the hyper variable region used to recognise different antigens on a clonal basis.
Antibody genes also re-organize in a process called class switching that changes the one type of heavy chain Fc fragment to another, creating a different isotype of the antibody that retains the antigen-specific variable region. This allows a single antibody to be used by different types of Fc receptors, expressed on different parts of the immune system."
Antimatter	"In particle physics, antimatter is a material composed of antiparticles, which have the same mass as particles of ordinary matter but opposite charges, as well as other particle properties such as lepton and baryon numbers and quantum spin. Collisions between particles and antiparticles lead to the annihilation of both, giving rise to variable proportions of intense photons (gamma rays), neutrinos, and less massive particle–antiparticle pairs. The total consequence of annihilation is a release of energy available for work, proportional to the total matter and antimatter mass, in accord with the mass–energy equivalence equation, E = mc2.
Antiparticles bind with each other to form antimatter, just as ordinary particles bind to form normal matter. For example, a positron (the antiparticle of the electron) and an antiproton (the antiparticle of the proton) can form an antihydrogen atom. Physical principles indicate that complex antimatter atomic nuclei are possible, as well as anti-atoms corresponding to the known chemical elements. Studies of cosmic rays have identified both positrons and antiprotons, presumably produced by collisions between particles of ordinary matter. Satellite-based searches of cosmic rays for antideuteron and antihelium particles have yielded nothing.
There is considerable speculation as to why the observable universe is composed almost entirely of ordinary matter, as opposed to a more even mixture of matter and antimatter. This asymmetry of matter and antimatter in the visible universe is one of the great unsolved problems in physics. The process by which this inequality between particles and antiparticles developed is called baryogenesis.
Antimatter in the form of anti-atoms is one of the most difficult materials to produce. Antimatter in the form of individual anti-particles, however, is commonly produced by particle accelerators and in some types of radioactive decay. The nuclei of antihelium (both helium-3 and helium-4) have been artificially produced with difficulty. These are the most complex anti-nuclei so far observed."
Archaeology	"Archaeology, or archeology, is the study of human activity through the recovery and analysis of material culture. The archaeological record consists of artifacts, architecture, biofacts or ecofacts, and cultural landscapes. Archaeology can be considered both a social science and a branch of the humanities. In North America, archaeology is considered a sub-field of anthropology, while in Europe archaeology is often viewed as either a discipline in its own right or a sub-field of other disciplines.
Archaeologists study human prehistory and history, from the development of the first stone tools at Lomekwi, eastern Africa, 3.3 million years ago up until recent decades. Archaeology as a field is distinct from the discipline of paleontology, the study of fossil remains. Archaeology is particularly important for learning about prehistoric societies, for whom there may be no written records to study. Prehistory includes over 99% of the human past, from the Paleolithic until the advent of literacy in societies across the world. Archaeology has various goals, which range from understanding culture history to reconstructing past lifeways to documenting and explaining changes in human societies through time.
The discipline involves surveying, excavation and eventually analysis of data collected to learn more about the past. In broad scope, archaeology relies on cross-disciplinary research. It draws upon anthropology, history, art history, classics, ethnology, geography, geology, linguistics, semiology, physics, information sciences, chemistry, statistics, paleoecology, paleontology, paleozoology, paleoethnobotany, and paleobotany.
Archaeology developed out of antiquarianism in Europe during the 19th century, and has since become a discipline practiced across the world. Since its early development, various specific sub-disciplines of archaeology have developed, including maritime archaeology, feminist archaeology and archaeoastronomy, and numerous different scientific techniques have been developed to aid archaeological investigation. Nonetheless, today, archaeologists face many problems, such as dealing with pseudoarchaeology, the looting of artifacts, a lack of public interest, and opposition to the excavation of human remains."
Aristotle	"Aristotle (/ˈærɪˌstɒtəl/; Greek: Ἀριστοτέλης [aristotélɛːs], Aristotélēs; 384–322 BC) was a Greek philosopher and scientist born in the city of Stagira, Chalkidice, on the northern periphery of Classical Greece. His father, Nicomachus, died when Aristotle was a child, whereafter Proxenus of Atarneus became his guardian. At eighteen, he joined Plato's Academy in Athens and remained there until the age of thirty-seven (c. 347 BC). His writings cover many subjects – including physics, biology, zoology, metaphysics, logic, ethics, aesthetics, poetry, theater, music, rhetoric, linguistics, politics and government – and constitute the first comprehensive system of Western philosophy. Shortly after Plato died, Aristotle left Athens and, at the request of Philip of Macedon, tutored Alexander the Great starting from 343 BC. According to the Encyclopædia Britannica, ""Aristotle was the first genuine scientist in history ... [and] every scientist is in his debt.""
Teaching Alexander the Great gave Aristotle many opportunities and an abundance of supplies. He established a library in the Lyceum which aided in the production of many of his hundreds of books. The fact that Aristotle was a pupil of Plato contributed to his former views of Platonism, but, following Plato's death, Aristotle immersed himself in empirical studies and shifted from Platonism to empiricism. He believed all peoples' concepts and all of their knowledge was ultimately based on perception. Aristotle's views on natural sciences represent the groundwork underlying many of his works.
Aristotle's views on physical science profoundly shaped medieval scholarship. Their influence extended into the Renaissance and were not replaced systematically until the Enlightenment and theories such as classical mechanics. Some of Aristotle's zoological observations, such as on the hectocotyl (reproductive) arm of the octopus, were not confirmed or refuted until the 19th century. His works contain the earliest known formal study of logic, which was incorporated in the late 19th century into modern formal logic.
In metaphysics, Aristotelianism profoundly influenced Judeo-Islamic philosophical and theological thought during the Middle Ages and continues to influence Christian theology, especially the scholastic tradition of the Catholic Church. Aristotle was well known among medieval Muslim intellectuals and revered as ""The First Teacher"" (Arabic: المعلم الأول‎).
His ethics, though always influential, gained renewed interest with the modern advent of virtue ethics. All aspects of Aristotle's philosophy continue to be the object of active academic study today. Though Aristotle wrote many elegant treatises and dialogues – Cicero described his literary style as ""a river of gold"" – it is thought that only around a third of his original output has survived."
Artificial intelligence	"Artificial intelligence (AI) is the intelligence exhibited by machines or software. It is also the name of the academic field of study which studies how to create computers and computer software that are capable of intelligent behavior. Major AI researchers and textbooks define this field as ""the study and design of intelligent agents"", in which an intelligent agent is a system that perceives its environment and takes actions that maximize its chances of success. John McCarthy, who coined the term in 1955, defines it as ""the science and engineering of making intelligent machines"".
AI research is highly technical and specialized, and is deeply divided into subfields that often fail to communicate with each other. Some of the division is due to social and cultural factors: subfields have grown up around particular institutions and the work of individual researchers. AI research is also divided by several technical issues. Some subfields focus on the solution of specific problems. Others focus on one of several possible approaches or on the use of a particular tool or towards the accomplishment of particular applications.
The central problems (or goals) of AI research include reasoning, knowledge, planning, learning, natural language processing (communication), perception and the ability to move and manipulate objects. General intelligence is still among the field's long-term goals. Currently popular approaches include statistical methods, computational intelligence and traditional symbolic AI. There are a large number of tools used in AI, including versions of search and mathematical optimization, logic, methods based on probability and economics, and many others. The AI field is interdisciplinary, in which a number of sciences and professions converge, including computer science, mathematics, psychology, linguistics, philosophy and neuroscience, as well as other specialized fields such as artificial psychology.
The field was founded on the claim that a central property of humans, human intelligence—the sapience of Homo sapiens sapiens—""can be so precisely described that a machine can be made to simulate it."" This raises philosophical arguments about the nature of the mind and the ethics of creating artificial beings endowed with human-like intelligence, issues which have been explored by myth, fiction and philosophy since antiquity. Artificial intelligence has been the subject of tremendous optimism but has also suffered stunning setbacks. Today AI techniques have become an essential part of the technology industry, providing the heavy lifting for many of the most challenging problems in computer science."
Astrobiology	"Astrobiology is the study of the origin, evolution, distribution, and future of life in the universe: extraterrestrial life and life on Earth. Astrobiology addresses the question of whether life exists beyond Earth, and how humans can detect it if it does (the term exobiology is similar but more specific—it covers the search for life beyond Earth, and the effects of extraterrestrial environments on living things).
Astrobiology makes use of physics, chemistry, astronomy, biology, molecular biology, ecology, planetary science, geography, and geology to investigate the possibility of life on other worlds and help recognize biospheres that might be different from that on Earth. The origin and early evolution of life is an inseparable part of the discipline of astrobiology. Astrobiology concerns itself with interpretation of existing scientific data; given more detailed and reliable data from other parts of the universe, the roots of astrobiology itself—physics, chemistry and biology—may have their theoretical bases challenged. Although speculation is entertained to give context, astrobiology concerns itself primarily with hypotheses that fit firmly into existing scientific theories.
This interdisciplinary field encompasses research on the origin and evolution of planetary systems, origins of organic compounds in space, rock-water-carbon interactions, abiogenesis on Earth, planetary habitability, research on biosignatures for life detection, and studies on the potential for life to adapt to challenges on Earth and in outer space.
The chemistry of life may have begun shortly after the Big Bang, 13.8 billion years ago, during a habitable epoch when the Universe was only 10–17 million years old. According to the panspermia hypothesis, microscopic life—distributed by meteoroids, asteroids and other small Solar System bodies—may exist throughout the universe. According to research published in August 2015, very large galaxies may be more favorable to the creation and development of habitable planets than smaller galaxies, like the Milky Way galaxy. Nonetheless, Earth is the only place in the universe known to harbor life. Estimates of habitable zones around other stars, along with the discovery of hundreds of extrasolar planets and new insights into the extreme habitats here on Earth, suggest that there may be many more habitable places in the universe than considered possible until very recently.
Current studies on the planet Mars by the Curiosity and Opportunity rovers are now searching for evidence of ancient life as well as plains related to ancient rivers or lakes that may have been habitable. The search for evidence of habitability, taphonomy (related to fossils), and organic molecules on the planet Mars is now a primary NASA and ESA objective on Mars."
Atom	"An atom is the smallest constituent unit of ordinary matter that has the properties of a chemical element. Every solid, liquid, gas, and plasma is composed of neutral or ionized atoms. Atoms are very small; typical sizes are around 100 pm (a ten-billionth of a meter, in the short scale). However, atoms do not have well-defined boundaries, and there are different ways to define their size that give different but close values.
Atoms are small enough that classical physics gives noticeably incorrect results. Through the development of physics, atomic models have incorporated quantum principles to better explain and predict the behavior.
Every atom is composed of a nucleus and one or more electrons bound to the nucleus. The nucleus is made of one or more protons and typically a similar number of neutrons (none in hydrogen-1). Protons and neutrons are called nucleons. More than 99.94% of an atom's mass is in the nucleus. The protons have a positive electric charge, the electrons have a negative electric charge, and the neutrons have no electric charge. If the number of protons and electrons are equal, that atom is electrically neutral. If an atom has more or fewer electrons than protons, then it has an overall negative or positive charge, respectively, and it is called an ion.
The electrons of an atom are attracted to the protons in an atomic nucleus by this electromagnetic force. The protons and neutrons in the nucleus are attracted to each other by a different force, the nuclear force, which is usually stronger than the electromagnetic force repelling the positively charged protons from one another. Under certain circumstances the repelling electromagnetic force becomes stronger than the nuclear force, and nucleons can be ejected from the nucleus, leaving behind a different element: nuclear decay resulting in nuclear transmutation.
The number of protons in the nucleus defines to what chemical element the atom belongs: for example, all copper atoms contain 29 protons. The number of neutrons defines the isotope of the element. The number of electrons influences the magnetic properties of an atom. Atoms can attach to one or more other atoms by chemical bonds to form chemical compounds such as molecules. The ability of atoms to associate and dissociate is responsible for most of the physical changes observed in nature, and is the subject of the discipline of chemistry."
Atoms	"An atom is the smallest constituent unit of ordinary matter that has the properties of a chemical element. Every solid, liquid, gas, and plasma is composed of neutral or ionized atoms. Atoms are very small; typical sizes are around 100 pm (a ten-billionth of a meter, in the short scale). However, atoms do not have well-defined boundaries, and there are different ways to define their size that give different but close values.
Atoms are small enough that classical physics gives noticeably incorrect results. Through the development of physics, atomic models have incorporated quantum principles to better explain and predict the behavior.
Every atom is composed of a nucleus and one or more electrons bound to the nucleus. The nucleus is made of one or more protons and typically a similar number of neutrons (none in hydrogen-1). Protons and neutrons are called nucleons. More than 99.94% of an atom's mass is in the nucleus. The protons have a positive electric charge, the electrons have a negative electric charge, and the neutrons have no electric charge. If the number of protons and electrons are equal, that atom is electrically neutral. If an atom has more or fewer electrons than protons, then it has an overall negative or positive charge, respectively, and it is called an ion.
The electrons of an atom are attracted to the protons in an atomic nucleus by this electromagnetic force. The protons and neutrons in the nucleus are attracted to each other by a different force, the nuclear force, which is usually stronger than the electromagnetic force repelling the positively charged protons from one another. Under certain circumstances the repelling electromagnetic force becomes stronger than the nuclear force, and nucleons can be ejected from the nucleus, leaving behind a different element: nuclear decay resulting in nuclear transmutation.
The number of protons in the nucleus defines to what chemical element the atom belongs: for example, all copper atoms contain 29 protons. The number of neutrons defines the isotope of the element. The number of electrons influences the magnetic properties of an atom. Atoms can attach to one or more other atoms by chemical bonds to form chemical compounds such as molecules. The ability of atoms to associate and dissociate is responsible for most of the physical changes observed in nature, and is the subject of the discipline of chemistry."
Automobiles	"A car is a wheeled, self-powered motor vehicle used for transportation and a product of the automotive industry. Most definitions of the term specify that cars are designed to run primarily on roads, to have seating for one to eight people, to typically have four wheels with tyres, and to be constructed principally for the transport of people rather than goods. The year 1886 is regarded as the birth year of the modern car. In that year, German inventor Karl Benz built the Benz Patent-Motorwagen. Cars did not become widely available until the early 20th century. One of the first cars that was accessible to the masses was the 1908 Model T, an American car manufactured by the Ford Motor Company. Cars were rapidly adopted in the United States of America, where they replaced animal-drawn carriages and carts, but took much longer to be accepted in Western Europe and other parts of the world.
Cars are equipped with controls used for driving, parking, passenger comfort and safety, and controlling a variety of lights. Over the decades, additional features and controls have been added to vehicles, making them progressively more complex. Examples include rear reversing cameras, air conditioning, navigation systems, and in car entertainment. Most cars in use in the 2010s are propelled by an internal combustion engine, fueled by deflagration of gasoline (also known as petrol) or diesel. Both fuels cause air pollution and are also blamed for contributing to climate change and global warming. Vehicles using alternative fuels such as ethanol flexible-fuel vehicles and natural gas vehicles are also gaining popularity in some countries. Electric cars, which were invented early in the history of the car, began to become commercially available in 2008.
There are costs and benefits to car use. The costs of car usage include the cost of: acquiring the vehicle, interest payments (if the car is financed), repairs and auto maintenance, fuel, depreciation, driving time, parking fees, taxes, and insurance. The costs to society of car use include: maintaining roads, land use, road congestion, air pollution, public health, health care, and disposing of the vehicle at the end of its life. Road traffic accidents are the largest cause of injury-related deaths worldwide.
The benefits may include on-demand transportation, mobility, independence, and convenience. The societal benefits may include: economic benefits, such as job and wealth creation from car production, sales and maintenance, transportation provision, society well-being derived from leisure and travel opportunities, and revenue generation from the tax opportunities. The ability for humans to move flexibly from place to place has far-reaching implications for the nature of societies. It was estimated in 2010 that the number of cars had risen to over 1 billion vehicles, up from the 500 million of 1986. The numbers are increasing rapidly, especially in China, India and other newly industrialized countries."
Axiom	"An axiom or postulate as defined in classic philosophy, is a statement (in mathematics often shown in symbolic form) that is so evident or well-established, that it is accepted without controversy or question. Thus, the axiom can be used as the premise or starting point for further reasoning or arguments, usually in logic or in mathematics. The word comes from the Greek axíōma (ἀξίωμα) 'that which is thought worthy or fit' or 'that which commends itself as evident.'
As used in modern logic, an axiom is simply a premise or starting point for reasoning. Whether it is meaningful (and, if so, what it means) for an axiom, or any mathematical statement, to be ""true"" is a central question in the philosophy of mathematics, with modern mathematicians holding a multitude of different opinions.
As used in mathematics, the term axiom is used in two related but distinguishable senses: ""logical axioms"" and ""non-logical axioms"". Logical axioms are usually statements that are taken to be true within the system of logic they define (e.g., (A and B) implies A), while non-logical axioms (e.g., a + b = b + a) are actually substantive assertions about the elements of the domain of a specific mathematical theory (such as arithmetic). When used in the latter sense, ""axiom"", ""postulate"", and ""assumption"" may be used interchangeably. In general, a non-logical axiom is not a self-evident truth, but rather a formal logical expression used in deduction to build a mathematical theory. As modern mathematics admits multiple, equally ""true"" systems of logic, precisely the same thing must be said for logical axioms - they both define and are specific to the particular system of logic that is being invoked. To axiomatize a system of knowledge is to show that its claims can be derived from a small, well-understood set of sentences (the axioms). There are typically multiple ways to axiomatize a given mathematical domain.
In both senses, an axiom is any mathematical statement that serves as a starting point from which other statements are logically derived. Within the system they define, axioms (unless redundant) cannot be derived by principles of deduction, nor are they demonstrable by mathematical proofs, simply because they are starting points; there is nothing else from which they logically follow otherwise they would be classified as theorems. However, an axiom in one system may be a theorem in another, and vice versa."
Baghdad	"Baghdad (Arabic: بغداد‎ , Kurdish: Bexda‎, Iraqi pronunciation: [bɐʁˈd̪ɑːd̪]) is the capital of the Republic of Iraq. The population of Baghdad, as of 2011, is approximately 7,216,040, making it the largest city in Iraq, the second largest city in the Arab world (after Cairo, Egypt), and the second largest city in Western Asia (after Tehran, Iran). According to the government, the population of the country has reached 35 million, with 9 million in the capital.
Located along the Tigris River, the city was founded in the 8th century and became the capital of the Abbasid Caliphate. Within a short time of its inception, Baghdad evolved into a significant cultural, commercial, and intellectual center for the Islamic world. This, in addition to housing several key academic institutions (e.g. House of Wisdom), garnered the city a worldwide reputation as the ""Center of Learning"".
Throughout the High Middle Ages, Baghdad was considered to be the largest city in the world with an estimated population of 1,200,000 people. The city was largely destroyed at the hands of the Mongol Empire in 1258, resulting in a decline that would linger through many centuries due to frequent plagues and multiple successive empires. With the recognition of Iraq as an independent state (formerly the British Mandate of Mesopotamia) in 1938, Baghdad gradually regained some of its former prominence as a significant center of Arab culture.
In contemporary times, the city has often faced severe infrastructural damage, most recently due to the 2003 invasion of Iraq, and the subsequent Iraq War that lasted until December 2011. In recent years, the city has been frequently subjected to insurgency attacks. As of 2012, Baghdad was listed as one of the least hospitable places in the world to live, and was ranked by Mercer as the worst of 221 major cities as measured by quality-of-life."
Biochemistry	"Biochemistry, sometimes called biological chemistry, is the study of chemical processes within and relating to living organisms. By controlling information flow through biochemical signaling and the flow of chemical energy through metabolism, biochemical processes give rise to the complexity of life. Over the last decades of the 20th century, biochemistry has become so successful at explaining living processes that now almost all areas of the life sciences from botany to medicine to genetics are engaged in biochemical research. Today, the main focus of pure biochemistry is on understanding how biological molecules give rise to the processes that occur within living cells, which in turn relates greatly to the study and understanding of tissues, organs, and whole organisms—that is, all of biology.
Biochemistry is closely related to molecular biology, the study of the molecular mechanisms by which genetic information encoded in DNA is able to result in the processes of life. Depending on the exact definition of the terms used, molecular biology can be thought of as a branch of biochemistry, or biochemistry as a tool with which to investigate and study molecular biology.
Much of biochemistry deals with the structures, functions and interactions of biological macromolecules, such as proteins, nucleic acids, carbohydrates and lipids, which provide the structure of cells and perform many of the functions associated with life. The chemistry of the cell also depends on the reactions of smaller molecules and ions. These can be inorganic, for example water and metal ions, or organic, for example the amino acids, which are used to synthesize proteins. The mechanisms by which cells harness energy from their environment via chemical reactions are known as metabolism. The findings of biochemistry are applied primarily in medicine, nutrition, and agriculture. In medicine, biochemists investigate the causes and cures of diseases. In nutrition, they study how to maintain health and study the effects of nutritional deficiencies. In agriculture, biochemists investigate soil and fertilizers, and try to discover ways to improve crop cultivation, crop storage and pest control."
Biogeography	"Biogeography is the study of the distribution of species and ecosystems in geographic space and through (geological) time. Organisms and biological communities often vary in a regular fashion along geographic gradients of latitude, elevation, isolation and habitat area. Phytogeography is the branch of biogeography that studies the distribution of plants. Zoogeography is the branch that studies distribution of animals.
Knowledge of spatial variation in the numbers and types of organisms is as vital to us today as it was to our early human ancestors, as we adapt to heterogeneous but geographically predictable environments. Biogeography is an integrative field of inquiry that unites concepts and information from ecology, evolutionary biology, geology, and physical geography.
Modern biogeographic research combines information and ideas from many fields, from the physiological and ecological constraints on organismal dispersal to geological and climatological phenomena operating at global spatial scales and evolutionary time frames.
The short-term interactions within a habitat and species of organisms describe the ecological application of biogeography. Historical biogeography describes the long-term, evolutionary periods of time for broader classifications of organisms. Early scientists, beginning with Carl Linnaeus, contributed theories to the contributions of the development of biogeography as a science. Beginning in the mid-18th century, Europeans explored the world and discovered the biodiversity of life. Linnaeus initiated the ways to classify organisms through his exploration of undiscovered territories.
The scientific theory of biogeography grows out of the work of Alexander von Humboldt (1769–1859), Hewett Cottrell Watson (1804–1881), Alphonse de Candolle (1806–1893), Alfred Russel Wallace (1823–1913), Philip Lutley Sclater (1829–1913) and other biologists and explorers."
Biological engineering	"Biological engineering or bio-engineering (including biological systems engineering) is the application of concepts and methods of biology (and secondarily of physics, chemistry, mathematics, and computer science) to solve real-world problems related to SSBS life sciences or the application thereof, using engineering's own analytical and synthetic methodologies and also its traditional sensitivity to the cost and practicality of the solution(s) arrived at. In this context, while traditional engineering applies physical and mathematical sciences to analyze, design and manufacture inanimate tools, structures and processes, biological engineering uses primarily the rapidly developing body of knowledge known as molecular biology to study and advance applications of organisms and to create biotechnology.
An especially important application is the analysis and cost-effective solution of problems related to human health, but the field is much more general than that. For example, biomimetics is a branch of biological engineering which strives to find ways in which the structures and functions of living organisms can be used as models for the design and engineering of materials and machines. Systems biology, on the other hand, seeks to exploit the engineer's familiarity with complex artificial systems, and perhaps the concepts used in ""reverse engineering"", to facilitate the difficult process of recognition of the structure, function, and precise method of operation of complex biological systems.
The differentiation between biological engineering and biomedical engineering can be unclear, as many universities loosely use the terms ""bioengineering"" and ""biomedical engineering"" interchangeably. Biomedical engineers are specifically focused on applying biological and other sciences toward medical innovations, whereas biological engineers are focused principally on applying engineering principles to biology - but not necessarily for medical uses. Hence neither ""biological"" engineering nor ""biomedical"" engineering is wholly contained within the other, as there can be ""non-biological"" products for medical needs as well as ""biological"" products for non-medical needs (the latter including notably biosystems engineering)."
Botany	"Botany, also called plant science(s) or plant biology, is the science of plant life and a branch of biology. A botanist or plant scientist is a scientist who specializes in this field. The term ""botany"" comes from the Ancient Greek word βοτάνη (botanē) meaning ""pasture"", ""grass"", or ""fodder""; βοτάνη is in turn derived from βόσκειν (boskein), ""to feed"" or ""to graze"". Traditionally, botany has also included the study of fungi and algae by mycologists and phycologists respectively, with the study of these three groups of organisms remaining within the sphere of interest of the International Botanical Congress. Nowadays, botanists study approximately 400,000 species of living organisms of which some 260,000 species are vascular plants and about 248,000 are flowering plants.
Botany originated in prehistory as herbalism with the efforts of early humans to identify – and later cultivate – edible, medicinal and poisonous plants, making it one of the oldest branches of science. Medieval physic gardens, often attached to monasteries, contained plants of medical importance. They were forerunners of the first botanical gardens attached to universities, founded from the 1540s onwards. One of the earliest was the Padua botanical garden. These gardens facilitated the academic study of plants. Efforts to catalogue and describe their collections were the beginnings of plant taxonomy, and led in 1753 to the binomial system of Carl Linnaeus that remains in use to this day.
In the 19th and 20th centuries, new techniques were developed for the study of plants, including methods of optical microscopy and live cell imaging, electron microscopy, analysis of chromosome number, plant chemistry and the structure and function of enzymes and other proteins. In the last two decades of the 20th century, botanists exploited the techniques of molecular genetic analysis, including genomics and proteomics and DNA sequences to classify plants more accurately.
Modern botany is a broad, multidisciplinary subject with inputs from most other areas of science and technology. Research topics include the study of plant structure, growth and differentiation, reproduction, biochemistry and primary metabolism, chemical products, development, diseases, evolutionary relationships, systematics, and plant taxonomy. Dominant themes in 21st century plant science are molecular genetics and epigenetics, which are the mechanisms and control of gene expression during differentiation of plant cells and tissues. Botanical research has diverse applications in providing staple foods, materials such as timber, oil, rubber, fibre and drugs, in modern horticulture, agriculture and forestry, plant propagation, breeding and genetic modification, in the synthesis of chemicals and raw materials for construction and energy production, in environmental management, and the maintenance of biodiversity."
Brain	"The brain is an organ that serves as the center of the nervous system in all vertebrate and most invertebrate animals. Only a few invertebrates such as sponges, jellyfish, adult sea squirts and starfish do not have a brain; diffuse or localised nerve nets are present instead. The brain is located in the head, usually close to the primary sensory organs for such senses as vision, hearing, balance, taste, and smell. The brain is the most complex organ in a vertebrate's body. In a typical human, the cerebral cortex (the largest part) is estimated to contain 15–33 billion neurons, each connected by synapses to several thousand other neurons. These neurons communicate with one another by means of long protoplasmic fibers called axons, which carry trains of signal pulses called action potentials to distant parts of the brain or body targeting specific recipient cells.
Physiologically, the function of the brain is to exert centralized control over the other organs of the body. The brain acts on the rest of the body both by generating patterns of muscle activity and by driving the secretion of chemicals called hormones. This centralized control allows rapid and coordinated responses to changes in the environment. Some basic types of responsiveness such as reflexes can be mediated by the spinal cord or peripheral ganglia, but sophisticated purposeful control of behavior based on complex sensory input requires the information integrating capabilities of a centralized brain.
The operations of individual brain cells are now understood in considerable detail but the way they cooperate in ensembles of millions is yet to be solved. Recent models in modern neuroscience treat the brain as a biological computer, very different in mechanism from an electronic computer, but similar in the sense that it acquires information from the surrounding world, stores it, and processes it in a variety of ways, analogous to the central processing unit (CPU) in a computer.
This article compares the properties of brains across the entire range of animal species, with the greatest attention to vertebrates. It deals with the human brain insofar as it shares the properties of other brains. The ways in which the human brain differs from other brains are covered in the human brain article. Several topics that might be covered here are instead covered there because much more can be said about them in a human context. The most important is brain disease and the effects of brain damage, covered in the human brain article because the most common diseases of the human brain either do not show up in other species, or else manifest themselves in different ways."
Broadcasting	"Broadcasting is the distribution of audio and/or video content to a dispersed audience via any electronic mass communications medium, but typically one using the electromagnetic spectrum (radio waves), in a one-to-many model. Broadcasting began with AM radio broadcasting which came into popular use starting with the invention of the crystal detector in 1906. Before this, all forms of electronic communication, radio, telephone, and telegraph, were ""one-to-one"", with the message intended for a single recipient. The term ""broadcasting"", borrowed from the agricultural method of sowing seeds in a field by casting them broadly about, was coined by either KDKA manager Frank Conrad or RCA historian George Clark around 1920 to distinguish this new activity of ""one-to-many"" communication; a single radio station transmitting to multiple listeners.
Over the air broadcasting is usually associated with radio and television, though in practice radio and television transmissions take place using both wires and radio waves. The receiving parties may include the general public or a relatively small subset; the point is that anyone with the appropriate receiving technology can receive the signal. The field of broadcasting includes a wide range of practices, from relatively private exchanges such as public radio, community radio and commercial radio, public television, and commercial television.
U.S. Code of Federal Regulations, title 47, part 97 defines ""broadcasting"" as ""transmissions intended for reception by the general public, either direct or relayed"". Private or two-way telecommunications transmissions do not qualify under this definition. For example, amateur (""ham"") and citizens band (CB) radio operators are not allowed to broadcast. As defined, ""transmitting"" and ""broadcasting"" are not the same.
Transmission of radio and television programs from a radio or television station to home receivers over the spectrum is referred to as OTA (over the air) or terrestrial broadcasting and in most countries requires a broadcasting license. Transmissions using a combination of satellite and wired transmission, like cable television (which also retransmits OTA stations with their consent), are also considered broadcasts, and do not require a license. Transmissions of television and radio via streaming digital technology have increasingly been referred to as broadcasting as well, though strictly speaking this is incorrect."
Byzantine empire	"The Byzantine Empire, sometimes referred to as the Eastern Roman Empire, was the continuation of the Roman Empire in the East during Late Antiquity and the Middle Ages, when its capital city was Constantinople (modern-day Istanbul, originally founded as Byzantium). It survived the fragmentation and fall of the Western Roman Empire in the 5th century AD and continued to exist for an additional thousand years until it fell to the Ottoman Turks in 1453. During most of its existence, the empire was the most powerful economic, cultural, and military force in Europe. Both ""Byzantine Empire"" and ""Eastern Roman Empire"" are historiographical terms created after the end of the realm; its citizens continued to refer to their empire as the Roman Empire (Ancient Greek: Βασιλεία τῶν Ῥωμαίων, tr. Basileia tôn Rhōmaiōn; Latin: Imperium Romanum), or Romania (Ῥωμανία), and to themselves as ""Romans"".
Several events from the 4th to 6th centuries mark the period of transition during which the Roman Empire's Greek East and Latin West divided. Constantine I (r. 324–337) reorganised the empire, made Constantinople the new capital, and legalised Christianity. Under Theodosius I (r. 379–395), Christianity became the Empire's official state religion and other religious practices were proscribed. Finally, under the reign of Heraclius (r. 610–641), the Empire's military and administration were restructured and adopted Greek for official use instead of Latin. Thus, although the Roman state continued and Roman state traditions were maintained, modern historians distinguish Byzantium from ancient Rome insofar as it was centred on Constantinople, oriented towards Greek rather than Latin culture, and characterised by Orthodox Christianity.
The borders of the Empire evolved significantly over its existence, as it went through several cycles of decline and recovery. During the reign of Justinian I (r. 527–565), the Empire reached its greatest extent after reconquering much of the historically Roman western Mediterranean coast, including North Africa, Italy, and Rome itself, which it held for two more centuries. During the reign of Maurice (r. 582–602), the Empire's eastern frontier was expanded and the north stabilised. However, his assassination caused the Byzantine–Sasanian War of 602–628, which exhausted the Empire's resources and contributed to major territorial losses during the Muslim conquests of the seventh century. In a matter of years the Empire lost its richest provinces, Egypt and Syria, to the Arabs.
During the Macedonian dynasty (10th–11th centuries), the Empire again expanded and experienced the two-century long Macedonian Renaissance, which came to an end with the loss of much of Asia Minor to the Seljuk Turks after the Battle of Manzikert in 1071. This battle opened the way for the Turks to settle in Anatolia as a homeland.
The Empire recovered again during the Komnenian restoration, such that by the 12th century Constantinople was the largest and wealthiest European city. However, it was delivered a mortal blow during the Fourth Crusade, when Constantinople was sacked in 1204 and the territories that the Empire formerly governed were divided into competing Byzantine Greek and Latin realms. Despite the eventual recovery of Constantinople in 1261, the Byzantine Empire remained only one of several small rival states in the area for the final two centuries of its existence. Its remaining territories were progressively annexed by the Ottomans over the 15th century. The Fall of Constantinople to the Ottoman Empire in 1453 finally ended the Byzantine Empire."
Calculator	"An electronic calculator is a small, portable electronic device used to perform both basic operations of arithmetic and complex mathematical operations.
The first solid state electronic calculator was created in the 1960s, building on the extensive history of tools such as the abacus (developed around 2000 BC), and the mechanical calculator (developed in the 17th century AD). It was developed in parallel with the analog computers of the day.
The pocket sized devices became available in the 1970s, especially after the first microprocessor developed by Intel for the Japanese calculator company Busicom. They later became commonly used within the Oil and Gas industry.
Modern electronic calculators vary: from cheap, give-away, credit-card-sized models—to sturdy desktop models with built-in printers. They became popular in the mid-1970s (as integrated circuits made their size and cost small). By the end of that decade—calculator prices had reduced to a point where a basic calculator was affordable to most and they became common in schools.
Computer operating systems as far back as early Unix have included interactive calculator programs such as dc and hoc, and calculator functions are included in almost all PDA-type devices (save a few dedicated address book and dictionary devices).
In addition to general purpose calculators, there are those designed for specific markets; for example, there are scientific calculators which include trigonometric and statistical calculations. Some calculators even have the ability to do computer algebra. Graphing calculators can be used to graph functions defined on the real line, or higher-dimensional Euclidean space. Currently, basic calculators are inexpensive, but the scientific and graphing models tend to be higher priced.
In 1986, calculators still represented an estimated 41% of the world's general-purpose hardware capacity to compute information. This diminished to less than 0.05% by 2007."
Cancer	"Cancer is a group of diseases involving abnormal cell growth with the potential to invade or spread to other parts of the body. Not all tumors are cancerous; benign tumors do not spread to other parts of the body. Possible signs and symptoms include: a new lump, abnormal bleeding, a prolonged cough, unexplained weight loss, and a change in bowel movements among others. While these symptoms may indicate cancer, they may also occur due to other issues. There are over 100 different known cancers that affect humans.
Tobacco use is the cause of about 22% of cancer deaths. Another 10% is due to obesity, a poor diet, lack of physical activity, and consumption of alcohol. Other factors include certain infections, exposure to ionizing radiation, and environmental pollutants. In the developing world nearly 20% of cancers are due to infections such as hepatitis B, hepatitis C, and human papillomavirus (HPV). These factors act, at least partly, by changing the genes of a cell. Typically many such genetic changes are required before cancer develops. Approximately 5–10% of cancers are due to genetic defects inherited from a person's parents. Cancer can be detected by certain signs and symptoms or screening tests. It is then typically further investigated by medical imaging and confirmed by biopsy.
Many cancers can be prevented by not smoking, maintaining a healthy weight, not drinking too much alcohol, eating plenty of vegetables, fruits and whole grains, being vaccinated against certain infectious diseases, not eating too much processed and red meat, and avoiding too much exposure to sunlight. Early detection through screening is useful for cervical and colorectal cancer. The benefits of screening in breast cancer are controversial. Cancer is often treated with some combination of radiation therapy, surgery, chemotherapy, and targeted therapy. Pain and symptom management are an important part of care. Palliative care is particularly important in those with advanced disease. The chance of survival depends on the type of cancer and extent of disease at the start of treatment. In children under 15 at diagnosis the five-year survival rate in the developed world is on average 80%. For cancer in the United States the average five-year survival rate is 66%.
In 2012 about 14.1 million new cases of cancer occurred globally (not including skin cancer other than melanoma). It caused about 8.2 million deaths or 14.6% of all human deaths. The most common types of cancer in males are lung cancer, prostate cancer, colorectal cancer, and stomach cancer, and in females, the most common types are breast cancer, colorectal cancer, lung cancer, and cervical cancer. If skin cancer other than melanoma were included in total new cancers each year it would account for around 40% of cases. In children, acute lymphoblastic leukaemia and brain tumors are most common except in Africa where non-Hodgkin lymphoma occurs more often. In 2012, about 165,000 children under 15 years of age were diagnosed with cancer. The risk of cancer increases significantly with age and many cancers occur more commonly in developed countries. Rates are increasing as more people live to an old age and as lifestyle changes occur in the developing world. The financial costs of cancer have been estimated at $1.16 trillion US dollars per year as of 2010."
Celestial body	"An astronomical object or celestial object is a naturally occurring physical entity, association, or structure that current science has demonstrated to exist in the observable universe. The term astronomical object is sometimes used interchangeably with astronomical body. Typically, an astronomical (celestial) body refers to a single, cohesive structure that is bound together by gravity (and sometimes by electromagnetism). Examples include the asteroids, moons, planets and the stars. Astronomical objects are gravitationally bound structures that are associated with a position in space, but may consist of multiple independent astronomical bodies or objects. These objects range from single planets to star clusters, nebulae or entire galaxies. A comet may be described as a body, in reference to the frozen nucleus of ice and dust, or as an object, when describing the nucleus with its diffuse coma and tail.
The universe can be viewed as having a hierarchical structure. At the largest scales, the fundamental component of assembly is the galaxy, which are assembled out of dwarf galaxies. The galaxies are organized into groups and clusters, often within larger superclusters, that are strung along great filaments between nearly empty voids, forming a web that spans the observable universe. Galaxies and dwarf galaxies have a variety of morphologies, with the shapes determined by their formation and evolutionary histories, including interaction with other galaxies. Depending on the category, a galaxy may have one or more distinct features, such as spiral arms, a halo and a nucleus. At the core, most galaxies have a supermassive black hole, which may result in an active galactic nucleus. Galaxies can also have satellites in the form of dwarf galaxies and globular clusters.
The constituents of a galaxy are formed out of gaseous matter that assembles through gravitational self-attraction in a hierarchical manner. At this level, the resulting fundamental components are the stars, which are typically assembled in clusters from the various condensing nebulae. The great variety of stellar forms are determined almost entirely by the mass, composition and evolutionary state of these stars. Stars may be found in multi-star systems that orbit about each other in a hierarchical organization. A planetary system and various minor objects such as asteroids, comets and debris, can form in a hierarchical process of accretion from the protoplanetary disks that surrounds newly formed stars.
The various distinctive types of stars are shown by the Hertzsprung–Russell diagram (H–R diagram)—a plot of absolute stellar luminosity versus surface temperature. Each star follows an evolutionary track across this diagram. If this track takes the star through a region containing an intrinsic variable type, then its physical properties can cause it to become a variable star. An example of this is the instability strip, a region of the H-R diagram that includes Delta Scuti, RR Lyrae and Cepheid variables. Depending on the initial mass of the star and the presence or absence of a companion, a star may spend the last part of its life as a compact object; either a white dwarf, neutron star, or black hole."
Charles Darwin	"Charles Robert Darwin, FRS FRGS FLS FZS (/ˈdɑːrwɪn/; 12 February 1809 – 19 April 1882) was an English naturalist and geologist, best known for his contributions to evolutionary theory. He established that all species of life have descended over time from common ancestors, and in a joint publication with Alfred Russel Wallace introduced his scientific theory that this branching pattern of evolution resulted from a process that he called natural selection, in which the struggle for existence has a similar effect to the artificial selection involved in selective breeding.
Darwin published his theory of evolution with compelling evidence in his 1859 book On the Origin of Species, overcoming scientific rejection of earlier concepts of transmutation of species. By the 1870s, the scientific community and much of the general public had accepted evolution as a fact. However, many favoured competing explanations and it was not until the emergence of the modern evolutionary synthesis from the 1930s to the 1950s that a broad consensus developed in which natural selection was the basic mechanism of evolution. In modified form, Darwin's scientific discovery is the unifying theory of the life sciences, explaining the diversity of life.
Darwin's early interest in nature led him to neglect his medical education at the University of Edinburgh; instead, he helped to investigate marine invertebrates. Studies at the University of Cambridge (Christ's College) encouraged his passion for natural science. His five-year voyage on HMS Beagle established him as an eminent geologist whose observations and theories supported Charles Lyell's uniformitarian ideas, and publication of his journal of the voyage made him famous as a popular author.
Puzzled by the geographical distribution of wildlife and fossils he collected on the voyage, Darwin began detailed investigations and in 1838 conceived his theory of natural selection. Although he discussed his ideas with several naturalists, he needed time for extensive research and his geological work had priority. He was writing up his theory in 1858 when Alfred Russel Wallace sent him an essay that described the same idea, prompting immediate joint publication of both of their theories. Darwin's work established evolutionary descent with modification as the dominant scientific explanation of diversification in nature. In 1871 he examined human evolution and sexual selection in The Descent of Man, and Selection in Relation to Sex, followed by The Expression of the Emotions in Man and Animals. His research on plants was published in a series of books, and in his final book, The Formation of Vegetable Mould, through the Actions of Worms published 1881, he examined earthworms and their effect on soil.
Darwin has been described as one of the most influential figures in human history; he was honoured by burial in Westminster Abbey."
Civilization	"A civilization (US) or civilisation (UK) is any complex society characterized by urban development, social stratification, symbolic communication forms (typically, writing systems), and a perceived separation from and domination over the natural environment by a cultural elite. Civilizations are intimately associated with and often further defined by other socio-politico-economic characteristics, including centralization, the domestication of both humans and other organisms, specialization of labor, culturally ingrained ideologies of progress and supremacism, monumental architecture, taxation, societal dependence upon farming as an agricultural practice, and expansionism.
Historically, a civilization was a so-called ""advanced"" culture in contrast to more supposedly primitive cultures. In this broad sense, a civilization contrasts with non-centralized tribal societies, including the cultures of nomadic pastoralists or hunter-gatherers. As an uncountable noun, civilization also refers to the process of a society developing into a centralized, urbanized, stratified structure.
Civilizations are organized in densely populated settlements divided into hierarchical social classes with a ruling elite and subordinate urban and rural populations, which engage in intensive agriculture, mining, small-scale manufacture and trade. Civilization concentrates power, extending human control over the rest of nature, including over other human beings.
The earliest emergence of civilizations is generally associated with the final stages of the Neolithic Revolution, culminating in the relatively rapid process of state formation, a political development associated with the appearance of a governing elite. This neolithic technology and lifestyle was established first in the Middle East (for example at Göbekli Tepe, from about 9,130 BCE), and later in the Yangtze and Yellow river basins in China (for example the Pengtoushan culture from 7,500 BCE), and later spread. But similar ""revolutions"" also began independently from 7,000 BCE in such places as the Norte Chico civilization in Peru and Mesoamerica at the Balsas River. These were among the six civilizations worldwide that arose independently. Mesopotamia is the site of the earliest developments of the Neolithic Revolution from around 10,000 BC. It has been identified as having ""inspired some of the most important developments in human history including the invention of the wheel, the planting of the first cereal crops and the development of cursive script, Mathematics, Astronomy and Agriculture.""
The Neolithic Revolution in turn was dependent upon the development of sedentarism, the domestication of grains and animals and the development lifestyles which allowed economies of scale and the accumulation of surplus production by certain social sectors. The transition from ""complex cultures"" to ""civilisations"", while still disputed, seems to be associated with the development of state structures, in which power was further monopolised by an elite ruling class.
Towards the end of the Neolithic period, various Chalcolithic civilizations began to rise in various ""cradles"" from around 3300 BCE. Chalcolithic Civilizations, as defined above, also developed in Pre-Columbian Americas and, despite an early start in Egypt, Axum and Kush, much later in Iron Age sub-Saharan Africa. The Bronze Age collapse was followed by the Iron Age around 1200 BCE, during which a number of new civilizations emerged, culminating in the Axial Age transition to Classical civilization. A major technological and cultural transition to modernity began approximately 1500 CE in western Europe, and from this beginning new approaches to science and law spread rapidly around the world."
Classical antiquity	"Classical antiquity (also the classical era, classical period or classical age) is a broad term for a long period of cultural history centered on the Mediterranean Sea, comprising the interlocking civilizations of ancient Greece and ancient Rome, collectively known as the Greco-Roman world. It is the period in which Greek and Roman society flourished and wielded great influence throughout Europe, North Africa and Southwestern Asia.
Conventionally, it is taken to begin with the earliest-recorded Epic Greek poetry of Homer (8th–7th century BC), and continues through the emergence of Christianity and the decline of the Roman Empire (5th century AD). It ends with the dissolution of classical culture at the close of Late Antiquity (300–600), blending into the Early Middle Ages (600–1000). Such a wide sampling of history and territory covers many disparate cultures and periods. ""Classical antiquity"" may refer also to an idealised vision among later people of what was, in Edgar Allan Poe's words, ""the glory that was Greece, and the grandeur that was Rome.""
The culture of the ancient Greeks, together with some influences from the ancient Near East, was the basis of art, philosophy, society, and educational ideals, until the Roman imperial period. The Romans preserved, imitated and spread over Europe these ideals until they were able to competitively rival the Greek culture, as the Latin language became widespread and the classical world became bilingual, Greek and Latin. This Greco-Roman cultural foundation has been immensely influential on the language, politics, educational systems, philosophy, science, art, and architecture of the modern world: From the surviving fragments of classical antiquity, a revival movement was gradually formed from the 14th century onwards which came to be known later in Europe as the Renaissance, and again resurgent during various neo-classical revivals in the 18th and 19th centuries."
Classical mechanics	"In physics, classical mechanics and quantum mechanics are the two major sub-fields of mechanics. Classical mechanics is concerned with the set of physical laws describing the motion of bodies under the influence of a system of forces. The study of the motion of bodies is an ancient one, making classical mechanics one of the oldest and largest subjects in science, engineering and technology. It is also widely known as Newtonian mechanics.
Classical mechanics describes the motion of macroscopic objects, from projectiles to parts of machinery, as well as astronomical objects, such as spacecraft, planets, stars, and galaxies. Within classical mechanics are fields of study that describe the behavior of solids, liquids and gases and other specific sub-topics. Classical mechanics also provides extremely accurate results as long as the domain of study is restricted to large objects and the speeds involved do not approach the speed of light. When the objects being examined are sufficiently small, it becomes necessary to introduce the other major sub-field of mechanics, quantum mechanics, which adjusts the laws of physics of macroscopic objects for the atomic nature of matter by including the wave–particle duality of atoms and molecules. When both quantum mechanics and classical mechanics cannot apply, such as at the quantum level with high speeds, quantum field theory (QFT) becomes applicable.
The term classical mechanics was coined in the early 20th century to describe the system of physics begun by Isaac Newton and many contemporary 17th century natural philosophers, and is built upon the earlier astronomical theories of Johannes Kepler, which in turn were based on the precise observations of Tycho Brahe and the studies of terrestrial projectile motion of Galileo. Since these aspects of physics were developed long before the emergence of quantum physics and relativity, some sources exclude Einstein's theory of relativity from this category. However, a number of modern sources do include relativistic mechanics, which in their view represents classical mechanics in its most developed and most accurate form.
The earliest development of classical mechanics is often referred to as Newtonian mechanics, and is associated with the physical concepts employed by and the mathematical methods invented by Newton, Leibniz, and others. Later, more abstract and general methods were developed, leading to reformulations of classical mechanics known as Lagrangian mechanics and Hamiltonian mechanics. These advances were largely made in the 18th and 19th centuries, and they extend substantially beyond Newton's work, particularly through their use of analytical mechanics."
Climate	"Climate is the statistics (usually, mean or variability) of weather, usually over a 30-year interval. It is measured by assessing the patterns of variation in temperature, humidity, atmospheric pressure, wind, precipitation, atmospheric particle count and other meteorological variables in a given region over long periods of time. Climate differs from weather, in that weather only describes the short-term conditions of these variables in a given region.
A region's climate is generated by the climate system, which has five components: atmosphere, hydrosphere, cryosphere, lithosphere, and biosphere.
The climate of a location is affected by its latitude, terrain, and altitude, as well as nearby water bodies and their currents. Climates can be classified according to the average and the typical ranges of different variables, most commonly temperature and precipitation. The most commonly used classification scheme was Köppen climate classification originally developed by Wladimir Köppen. The Thornthwaite system, in use since 1948, incorporates evapotranspiration along with temperature and precipitation information and is used in studying biological diversity and the potential effects on it of climate changes. The Bergeron and Spatial Synoptic Classification systems focus on the origin of air masses that define the climate of a region.
Paleoclimatology is the study of ancient climates. Since direct observations of climate are not available before the 19th century, paleoclimates are inferred from proxy variables that include non-biotic evidence such as sediments found in lake beds and ice cores, and biotic evidence such as tree rings and coral. Climate models are mathematical models of past, present and future climates. Climate change may occur over long and short timescales from a variety of factors; recent warming is discussed in global warming."
Common sense	"Common sense is a basic ability to perceive, understand, and judge things, which is shared by (""common to"") nearly all people and can reasonably be expected of nearly all people without any need for debate.
The everyday understanding of common sense is derived from philosophical discussion involving several European languages. Related terms in other languages include Latin sensus communis, Greek κοινὴ αἲσθησις (koinē aísthēsis), and French bon sens, but these are not straightforward translations in all contexts. Similarly in English, there are different shades of meaning, implying more or less education and wisdom: ""good sense"" is sometimes seen as equivalent to ""common sense"", and sometimes not.
""Common sense"" has at least two specifically philosophical meanings. One is a capability of the animal soul (Greek psukhē) proposed by Aristotle, which enables different individual senses to collectively perceive the characteristics of physical things such as movement and size, which all physical things have in different combinations, allowing people and other animals to distinguish and identify physical things. This common sense is distinct from basic sensory perception and from human rational thinking, but cooperates with both. The second special use of the term is Roman-influenced and is used for the natural human sensitivity for other humans and the community. Just like the everyday meaning, both of these refer to a type of basic awareness and ability to judge which most people are expected to share naturally, even if they can not explain why.
All these meanings of ""common sense"", including the everyday one, are inter-connected in a complex history and have evolved during important political and philosophical debates in modern western civilisation, notably concerning science, politics and economics. The interplay between the meanings has come to be particularly notable in English, as opposed to other western European languages, and the English term has become international.
In modern times the term ""common sense"" has frequently been used for rhetorical effect, sometimes pejorative, and sometimes appealed to positively, as an authority. It can be negatively equated to vulgar prejudice and superstition, or on the contrary it is often positively contrasted to them as a standard for good taste and as the source of the most basic axioms needed for science and logic. This began with Descartes' criticism of it, and what came to be known as the dispute between ""rationalism"" and ""empiricism"". In the opening line of one his most famous books, Discourse on Method, Descartes established the most common modern meaning, and its controversies, when he stated that everyone has a similar and sufficient amount of common sense (bon sens), but it is rarely used well. Therefore, a skeptical logical method described by Descartes needs to be followed and common sense should not be overly relied upon. In the ensuing 18th century Enlightenment, common sense came to be seen more positively as the basis for modern thinking. It was contrasted to metaphysics, which was, like Cartesianism, associated with the ancien régime. Thomas Paine's polemical pamphlet Common Sense (1776) has been described as the most influential political pamphlet of the 18th century, affecting both the American and French revolutions. Today, the concept of common sense, and how it should best be used, remains linked to many of the most perennial topics in epistemology and ethics, with special focus often directed at the philosophy of the modern social sciences."
Communications satellite	"A communications satellite is an artificial satellite that relays and amplifies radio telecommunications signals via a transponder; it creates a communication channel between a source transmitter and a receiver(s) at different locations on Earth. Communications satellites are used for television, telephone, radio, internet, and military applications. There are over 2,000 communications satellites in Earth’s orbit, used by both private and government organizations.
Wireless communication uses electromagnetic waves to carry signals. These waves require line-of-sight, and are thus obstructed by the curvature of the Earth. The purpose of communications satellites is to relay the signal around the curve of the Earth allowing communication between widely separated points. The electromagnetic signals that communication satellites work with, have a large spectrum of wavelengths and frequencies. To keep these waves from interfering with one another, international organizations have certain rules and regulations describing which wavelength a certain company or group can use. By separating out wavelengths, communication satellites will have minimal interference and be able to communicate effectively.
There are two major classes of communications satellites, passive and active. Passive satellites only reflect the signal coming from the source, toward the direction of the receiver. With passive satellites, the reflected signal is not amplified at the satellite, and only a very small amount of the transmitted energy reflects toward the receiver. Since the satellite is so far above Earth the radio signal is attenuated on its long journey due to free-space path loss, so the signal received on Earth is very weak. Active satellites, on the other hand, amplify the received signal before re-transmitting it to the receiver on the ground Passive satellites were the first communications satellites, but are little used now."
Complex systems	"Complex systems present problems both in mathematical modelling and philosophical foundations. The study of complex systems represents a new approach to science that investigates how relationships between parts give rise to the collective behaviors of a system and how the system interacts and forms relationships with its environment.
The equations from which models of complex systems are developed generally derive from statistical physics, information theory and non-linear dynamics and represent organized but unpredictable behaviors of natural systems that are considered fundamentally complex. The physical manifestations of such systems are difficult to define, so a common choice is to identify ""the system"" with the mathematical information model rather than referring to the undefined physical subject the model represents. One of a variety of journals using this approach to complexity is Complex Systems.
Such systems are used to model processes in computer science, biology, economics, physics, chemistry, and many other fields. It is also called complex systems theory, complexity science, study of complex systems,complex networks, network science, sciences of complexity, non-equilibrium physics, and historical physics. A variety of abstract theoretical complex systems is studied as a field of mathematics.
The key problems of complex systems are difficulties with their formal modelling and simulation. From such a perspective, in different research contexts complex systems are defined on the basis of their different attributes. Since all complex systems have many interconnected components, the science of networks and network theory are important and useful tools for the study of complex systems. A theory for the resilience of system of systems represented by a network of interdependent networks was developed by Buldyrev et al. A consensus regarding a single universal definition of complex system does not yet exist.
For systems that are less usefully represented with equations various other kinds of narratives and methods for identifying, exploring, designing and interacting with complex systems are used."
Computed tomography	"A CT scan, also called X-ray computed tomography (X-ray CT) or computerized axial tomography scan (CAT scan), makes use of computer-processed combinations of many X-ray images taken from different angles to produce cross-sectional (tomographic) images (virtual 'slices') of specific areas of a scanned object, allowing the user to see inside the object without cutting.
Digital geometry processing is used to generate a three-dimensional image of the inside of the object from a large series of two-dimensional radiographic images taken around a single axis of rotation. Medical imaging is the most common application of X-ray CT. Its cross-sectional images are used for diagnostic and therapeutic purposes in various medical disciplines. The rest of this article discusses medical-imaging X-ray CT; industrial applications of X-ray CT are discussed at industrial computed tomography scanning.
As X-ray CT is the most common form of CT in medicine and various other contexts, the term computed tomography alone (or CT) is often used to refer to X-ray CT, although other types exist (such as positron emission tomography [PET] and single-photon emission computed tomography [SPECT]). Older and less preferred terms that also refer to X-ray CT are computed axial tomography (CAT scan) and computer-aided/assisted tomography. X-ray CT is a form of radiography, although the word ""radiography"" used alone usually refers, by wide convention, to non-tomographic radiography.
CT produces a volume of data that can be manipulated in order to demonstrate various bodily structures based on their ability to block the X-ray beam. Although, historically, the images generated were in the axial or transverse plane, perpendicular to the long axis of the body, modern scanners allow this volume of data to be reformatted in various planes or even as volumetric (3D) representations of structures. Although most common in medicine, CT is also used in other fields, such as nondestructive materials testing. Another example is archaeological uses such as imaging the contents of sarcophagi. Individuals responsible for performing CT exams are called radiographers or radiologic technologists.
Usage of CT has increased dramatically over the last two decades in many countries. An estimated 72 million scans were performed in the United States in 2007. One study estimated that as many as 0.4% of current cancers in the United States are due to CTs performed in the past and that this may increase to as high as 1.5 to 2% with 2007 rates of CT usage; however, this estimate is disputed, as there is not a consensus about the existence of damage from low levels of radiation. Kidney problems may occasionally occur following intravenous contrast agents used in some types of studies."
Condensed matter physics	"Condensed matter physics is a branch of physics that deals with the physical properties of condensed phases of matter. Condensed matter physicists seek to understand the behavior of these phases by using physical laws. In particular, they include the laws of quantum mechanics, electromagnetism and statistical mechanics.
The most familiar condensed phases are solids and liquids while more exotic condensed phases include the superconducting phase exhibited by certain materials at low temperature, the ferromagnetic and antiferromagnetic phases of spins on atomic lattices, and the Bose–Einstein condensate found in cold atomic systems. The study of condensed matter physics involves measuring various material properties via experimental probes along with using techniques of theoretical physics to develop mathematical models that help in understanding physical behavior.
The diversity of systems and phenomena available for study makes condensed matter physics the most active field of contemporary physics: one third of all American physicists identify themselves as condensed matter physicists, and the Division of Condensed Matter Physics is the largest division at the American Physical Society. The field overlaps with chemistry, materials science, and nanotechnology, and relates closely to atomic physics and biophysics. Theoretical condensed matter physics shares important concepts and techniques with theoretical particle and nuclear physics.
A variety of topics in physics such as crystallography, metallurgy, elasticity, magnetism, etc., were treated as distinct areas until the 1940s, when they were grouped together as solid state physics. Around the 1960s, the study of physical properties of liquids was added to this list, forming the basis for the new, related specialty of condensed matter physics. According to physicist Philip Warren Anderson, the term was coined by him and Volker Heine, when they changed the name of their group at the Cavendish Laboratories, Cambridge from ""Solid state theory"" to ""Theory of Condensed Matter"" in 1967, as they felt it did not exclude their interests in the study of liquids, nuclear matter and so on. Although Anderson and Heine helped popularize the name ""condensed matter"", it had been present in Europe for some years, most prominently in the form of a journal published in English, French, and German by Springer-Verlag titled Physics of Condensed Matter, which was launched in 1963. The funding environment and Cold War politics of the 1960s and 1970s were also factors that lead some physicists to prefer the name ""condensed matter physics"", which emphasized the commonality of scientific problems encountered by physicists working on solids, liquids, plasmas, and other complex matter, over ""solid state physics"", which was often associated with the industrial applications of metals and semiconductors. The Bell Telephone Laboratories was one of the first institutes to conduct a research program in condensed matter physics.
References to ""condensed"" state can be traced to earlier sources. For example, in the introduction to his 1947 ""Kinetic Theory of Liquids"", Yakov Frenkel proposed in the book, ""The kinetic theory of liquids must accordingly be developed as a generalization and extension of the kinetic theory of solid bodies"".
As a matter of fact, it would be more correct to unify them under the title of ""condensed bodies""."
Confirmation bias	"Confirmation bias, also called confirmatory bias or myside bias, is the tendency to search for, interpret, favor, and recall information in a way that confirms one's beliefs or hypotheses, while giving disproportionately less consideration to alternative possibilities. It is a type of cognitive bias and a systematic error of inductive reasoning. People display this bias when they gather or remember information selectively, or when they interpret it in a biased way. The effect is stronger for emotionally charged issues and for deeply entrenched beliefs. People also tend to interpret ambiguous evidence as supporting their existing position. Biased search, interpretation and memory have been invoked to explain attitude polarization (when a disagreement becomes more extreme even though the different parties are exposed to the same evidence), belief perseverance (when beliefs persist after the evidence for them is shown to be false), the irrational primacy effect (a greater reliance on information encountered early in a series) and illusory correlation (when people falsely perceive an association between two events or situations).
A series of experiments in the 1960s suggested that people are biased toward confirming their existing beliefs. Later work re-interpreted these results as a tendency to test ideas in a one-sided way, focusing on one possibility and ignoring alternatives. In certain situations, this tendency can bias people's conclusions. Explanations for the observed biases include wishful thinking and the limited human capacity to process information. Another explanation is that people show confirmation bias because they are weighing up the costs of being wrong, rather than investigating in a neutral, scientific way.
Confirmation biases contribute to overconfidence in personal beliefs and can maintain or strengthen beliefs in the face of contrary evidence. Poor decisions due to these biases have been found in political and organizational contexts."
Consciousness	"Consciousness is the state or quality of awareness, or, of being aware of an external object or something within oneself. It has been defined as: sentience, awareness, subjectivity, the ability to experience or to feel, wakefulness, having a sense of selfhood, and the executive control system of the mind. Despite the difficulty in definition, many philosophers believe that there is a broadly shared underlying intuition about what consciousness is. As Max Velmans and Susan Schneider wrote in The Blackwell Companion to Consciousness: ""Anything that we are aware of at a given moment forms part of our consciousness, making conscious experience at once the most familiar and most mysterious aspect of our lives.""
Western philosophers, since the time of Descartes and Locke, have struggled to comprehend the nature of consciousness and pin down its essential properties. Issues of concern in the philosophy of consciousness include whether the concept is fundamentally coherent; whether consciousness can ever be explained mechanistically; whether non-human consciousness exists and if so how can it be recognized; how consciousness relates to language; whether consciousness can be understood in a way that does not require a dualistic distinction between mental and physical states or properties; and whether it may ever be possible for computing machines like computers or robots to be conscious, a topic studied in the field of artificial intelligence.
Thanks to recent developments in technology, consciousness has become a significant topic of research in psychology, neuropsychology and neuroscience within the past few decades. The primary focus is on understanding what it means biologically and psychologically for information to be present in consciousness—that is, on determining the neural and psychological correlates of consciousness. The majority of experimental studies assess consciousness by asking human subjects for a verbal report of their experiences (e.g., ""tell me if you notice anything when I do this""). Issues of interest include phenomena such as subliminal perception, blindsight, denial of impairment, and altered states of consciousness produced by alcohol and other drugs, or spiritual or meditative techniques.
In medicine, consciousness is assessed by observing a patient's arousal and responsiveness, and can be seen as a continuum of states ranging from full alertness and comprehension, through disorientation, delirium, loss of meaningful communication, and finally loss of movement in response to painful stimuli. Issues of practical concern include how the presence of consciousness can be assessed in severely ill, comatose, or anesthetized people, and how to treat conditions in which consciousness is impaired or disrupted."
Correlation does not imply causation	"""Correlation does not imply causation"" is a phrase used in statistics to emphasize that a correlation between two variables does not imply that one causes the other. Many statistical tests calculate correlation between variables. A few go further, using correlation as a basis for testing a hypothesis of a true causal relationship; examples are the Granger causality test and convergent cross mapping.
The counter-assumption, that ""correlation proves causation,"" is considered a questionable cause logical fallacy in that two events occurring together are taken to have a cause-and-effect relationship. This fallacy is also known as cum hoc ergo propter hoc, Latin for ""with this, therefore because of this,"" and ""false cause."" A similar fallacy, that an event that follows another was necessarily a consequence of the first event, is sometimes described as post hoc ergo propter hoc (Latin for ""after this, therefore because of this."")
For example, in a widely studied case, numerous epidemiological studies showed that women taking combined hormone replacement therapy (HRT) also had a lower-than-average incidence of coronary heart disease (CHD), leading doctors to propose that HRT was protective against CHD. But randomized controlled trials showed that HRT caused a small but statistically significant increase in risk of CHD. Re-analysis of the data from the epidemiological studies showed that women undertaking HRT were more likely to be from higher socio-economic groups (ABC1), with better-than-average diet and exercise regimens. The use of HRT and decreased incidence of coronary heart disease were coincident effects of a common cause (i.e. the benefits associated with a higher socioeconomic status), rather than a direct cause and effect, as had been supposed.
As with any logical fallacy, identifying that the reasoning behind an argument is flawed does not imply that the resulting conclusion is false. In the instance above, if the trials had found that hormone replacement therapy does in fact have a negative incidence on the likelihood of coronary heart disease the assumption of causality would have been correct, although the logic behind the assumption would still have been flawed."
Crystallography	"Crystallography is the experimental science of determining the arrangement of atoms in the crystalline solids (see crystal structure). The word ""crystallography"" derives from the Greek words crystallon ""cold drop, frozen drop"", with its meaning extending to all solids with some degree of transparency, and grapho ""I write"". In July 2012, the United Nations recognised the importance of the science of crystallography by proclaiming that 2014 would be the International Year of Crystallography. X-ray crystallography is used to determine the structure of large biomolecules such as proteins.
Before the development of X-ray diffraction crystallography (see below), the study of crystals was based on physical measurements of their geometry. This involved measuring the angles of crystal faces relative to each other and to theoretical reference axes (crystallographic axes), and establishing the symmetry of the crystal in question. This physical measurement is carried out using a goniometer. The position in 3D space of each crystal face is plotted on a stereographic net such as a Wulff net or Lambert net. The pole to each face is plotted on the net. Each point is labelled with its Miller index. The final plot allows the symmetry of the crystal to be established.
Crystallographic methods now depend on analysis of the diffraction patterns of a sample targeted by a beam of some type. X-rays are most commonly used; other beams used include electrons or neutrons. This is facilitated by the wave properties of the particles. Crystallographers often explicitly state the type of beam used, as in the terms X-ray crystallography, neutron diffraction and electron diffraction. These three types of radiation interact with the specimen in different ways.
X-rays interact with the spatial distribution of electrons in the sample.
Electrons are charged particles and therefore interact with the total charge distribution of both the atomic nuclei and the electrons of the sample.
Neutrons are scattered by the atomic nuclei through the strong nuclear forces, but in addition, the magnetic moment of neutrons is non-zero. They are therefore also scattered by magnetic fields. When neutrons are scattered from hydrogen-containing materials, they produce diffraction patterns with high noise levels. However, the material can sometimes be treated to substitute deuterium for hydrogen.
Because of these different forms of interaction, the three types of radiation are suitable for different crystallographic studies."
Cultural studies	"Cultural studies is a field of theoretically, politically, and empirically engaged cultural analysis that was initially developed by British academics in the late 1950s, 1960s and 1970s, and has been subsequently taken up and transformed by scholars from many different disciplines around the world. Cultural studies is avowedly and even radically interdisciplinary and can sometimes be seen as antidisciplinary. As cultural studies scholar Toby Miller has written, ""cultural studies is a tendency across disciplines, rather than a discipline itself."" Although most practitioners of cultural studies are professional academics, Gilbert Rodman has argued in his 2015 book, Why Cultural Studies?, that the field must be understood to include some non-academic cultural analysts and practitioners as well as academic ones. A key concern for cultural studies practitioners is the examination of the forces within and through which socially organized people conduct and participate in the construction of their everyday lives.
The field of cultural studies encompasses a range of theoretical and methodological perspectives and practices. Although distinct from the disciplines of cultural anthropology and ethnic studies, cultural studies draws upon and has contributed to each of these disciplines. Cultural studies concentrates upon the political dynamics of contemporary culture, its historical foundations, defining traits, and conflicts. CS researchers generally investigate how cultural practices relate to wider systems of power associated with or operating through social phenomena, such as ideology, class structures, national formations, ethnicity, sexual orientation, gender and generation. Cultural studies views cultures not as fixed, bounded, stable and discrete entities, but rather as constantly interacting and changing sets of practices and processes.
Cultural studies combines a variety of politically engaged critical approaches drawn from and including semiotics, Marxism, feminist theory, ethnography, critical race theory, poststructuralism, postcolonialism, social theory, political theory, history, philosophy, literary theory, media theory, film/video studies, communication studies, political economy, translation studies, museum studies and art history/criticism to study cultural phenomena in various societies and historical periods. Thus, cultural studies seeks to understand how meaning is generated, disseminated, contested, bound up with systems of power and control, and produced from the social, political and economic spheres within a particular social formation or conjuncture. Important theories of cultural hegemony and agency have both influenced and been developed by the cultural studies movement, as have many recent major communication theories and agendas, such as those which attempt to explain and analyze the cultural forces related to processes of globalization.
During the rise of neo-liberalism in Britain and the US, cultural studies both became a global force/movement, and attracted the ire of many conservative opponents both within and beyond universities for a variety of reasons. Some left-wing critics associated particularly with Marxist forms of political economy also attacked cultural studies for allegedly overstating the importance of cultural phenomena. While cultural studies continues to have its detractors, the field has become a kind of world-wide movement that is to this day associated with a raft of scholarly associations and programs, annual international conferences, publications, students and practitioners, from Taiwan to Amsterdam and from Bangalore to Santa Cruz. Somewhat distinct approaches to cultural studies have emerged in different national and regional contexts such as the United States, Canada, Australia, New Zealand, Latin America, Asia, Africa and Italy."
Curium	"Curium is a transuranic radioactive chemical element with symbol Cm and atomic number 96. This element of the actinide series was named after Marie and Pierre Curie – both were known for their research on radioactivity. Curium was first intentionally produced and identified in July 1944 by the group of Glenn T. Seaborg at the University of California, Berkeley. The discovery was kept secret and only released to the public in November 1945. Most curium is produced by bombarding uranium or plutonium with neutrons in nuclear reactors – one tonne of spent nuclear fuel contains about 20 grams of curium.
Curium is a hard, dense, silvery metal with a relatively high melting point and boiling point for an actinide. Whereas it is paramagnetic at ambient conditions, it becomes antiferromagnetic upon cooling, and other magnetic transitions are also observed for many curium compounds. In compounds, curium usually exhibits valence +3 and sometimes +4, and the +3 valence is predominant in solutions. Curium readily oxidizes, and its oxides are a dominant form of this element. It forms strongly fluorescent complexes with various organic compounds, but there is no evidence of its incorporation into bacteria and archaea. When introduced into the human body, curium accumulates in the bones, lungs and liver, where it promotes cancer.
All known isotopes of curium are radioactive and have a small critical mass for a sustained nuclear chain reaction. They predominantly emit α-particles, and the heat released in this process can potentially produce electricity in radioisotope thermoelectric generators. This application is hindered by the scarcity, high cost and radioactivity of curium isotopes. Curium is used in production of heavier actinides and of the 238Pu radionuclide for power sources in artificial pacemakers. It served as the α-source in the alpha particle X-ray spectrometers installed on several space probes, including the Sojourner, Spirit, Opportunity and Curiosity Mars rovers and the Philae lander on comet 67P/Churyumov-Gerasimenko, to analyze the composition and structure of the surface."
Cybernetics	"Cybernetics is a transdisciplinary approach for exploring regulatory systems, their structures, constraints, and possibilities. In the 21st century, the term is often used in a rather loose way to imply ""control of any system using technology;"" this has blunted its meaning to such an extent that many writers avoid using it.
Cybernetics is relevant to the study of systems, such as mechanical, physical, biological, cognitive, and social systems. Cybernetics is applicable when a system being analyzed incorporates a closed signaling loop; that is, where action by the system generates some change in its environment and that change is reflected in that system in some manner (feedback) that triggers a system change, originally referred to as a ""circular causal"" relationship.
System dynamics, a related field, originated with applications of electrical engineering control theory to other kinds of simulation models (especially business systems) by Jay Forrester at MIT in the 1950s.
Concepts studied by cyberneticists include, but are not limited to: learning, cognition, adaptation, social control, emergence, communication, efficiency, efficacy, and connectivity. These concepts are studied by other subjects such as engineering and biology, but in cybernetics these are abstracted from the context of the individual organism or device.
Norbert Wiener defined cybernetics in 1948 as ""the scientific study of control and communication in the animal and the machine."" The word cybernetics comes from Greek κυβερνητική (kybernetike), meaning ""governance"", i.e., all that are pertinent to κυβερνάω (kybernao), the latter meaning ""to steer, navigate or govern"", hence κυβέρνησις (kybernesis), meaning ""government"", is the government while κυβερνήτης (kybernetes) is the governor or the captain. Contemporary cybernetics began as an interdisciplinary study connecting the fields of control systems, electrical network theory, mechanical engineering, logic modeling, evolutionary biology, neuroscience, anthropology, and psychology in the 1940s, often attributed to the Macy Conferences. During the second half of the 20th century cybernetics evolved in ways that distinguish first-order cybernetics (about observed systems) from second-order cybernetics (about observing systems). More recently there is talk about a third-order cybernetics (doing in ways that embraces first and second-order).
Fields of study which have influenced or been influenced by cybernetics include game theory, system theory (a mathematical counterpart to cybernetics), perceptual control theory, sociology, psychology (especially neuropsychology, behavioral psychology, cognitive psychology), philosophy, architecture, and organizational theory."
DNA	"Deoxyribonucleic acid (/diˈɒksiˌraɪboʊnjʊˌkliːɪk, -ˌkleɪɪk/; DNA) is a molecule that carries most of the genetic instructions used in the development, functioning and reproduction of all known living organisms and many viruses. DNA (along with RNA) is a nucleic acid; alongside proteins and carbohydrates, nucleic acids compose the three major macromolecules essential for all known forms of life. Most DNA molecules consist of two biopolymer strands coiled around each other to form a double helix. The two DNA strands are known as polynucleotides since they are composed of simpler units called nucleotides. Each nucleotide is composed of a nitrogen-containing nucleobase—either cytosine (C), guanine (G), adenine (A), or thymine (T)—as well as a monosaccharide sugar called deoxyribose and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. According to base pairing rules (A with T, and C with G), hydrogen bonds bind the nitrogenous bases of the two separate polynucleotide strands to make double-stranded DNA. The total amount of related DNA base pairs on Earth is estimated at 5.0 x 1037, and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon).
DNA stores biological information. The DNA backbone is resistant to cleavage, and both strands of the double-stranded structure store the same biological information. Biological information is replicated as the two strands are separated. A significant portion of DNA (more than 98% for humans) is non-coding, meaning that these sections do not serve as patterns for protein sequences.
The two strands of DNA run in opposite directions to each other and are therefore anti-parallel. Attached to each sugar is one of four types of nucleobases (informally, bases). It is the sequence of these four nucleobases along the backbone that encodes biological information. Under the genetic code, RNA strands are translated to specify the sequence of amino acids within proteins. These RNA strands are initially created using DNA strands as a template in a process called transcription.
Within cells, DNA is organized into long structures called chromosomes. During cell division these chromosomes are duplicated in the process of DNA replication, providing each cell its own complete set of chromosomes. Eukaryotic organisms (animals, plants, fungi, and protists) store most of their DNA inside the cell nucleus and some of their DNA in organelles, such as mitochondria or chloroplasts. In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm. Within the chromosomes, chromatin proteins such as histones compact and organize DNA. These compact structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed.
DNA was first isolated by Friedrich Miescher in 1869. Its molecular structure was identified by James Watson and Francis Crick in 1953, whose model-building efforts were guided by X-ray diffraction data acquired by Rosalind Franklin. DNA is used by researchers as a molecular tool to explore physical laws and theories, such as the ergodic theorem and the theory of elasticity. The unique material properties of DNA have made it an attractive molecule for material scientists and engineers interested in micro- and nano-fabrication. Among notable advances in this field are DNA origami and DNA-based hybrid materials."
Dentistry	"Dentistry is a branch of medicine that is involved in the study, diagnosis, prevention, and treatment of diseases, disorders and conditions of the oral cavity, commonly in the dentition but also the oral mucosa, and of adjacent and related structures and tissues, particularly in the maxillofacial (jaw and facial) area. Although primarily associated with teeth among the general public, the field of dentistry or dental medicine is not limited to teeth but includes other aspects of the craniofacial complex including the temperomandibular and other supporting structures. The term dentistry comes from odontology (from Ancient Greek ὀδούς (odoús, ""tooth"")) – the study of the structure, development, and abnormalities of the teeth. Because of their substantial overlap in concept, dentistry is often also understood to subsume the now largely defunct medical specialty of stomatology (the study of the mouth and its disorders and diseases) for which reason the two terms are used interchangeably in certain regions.
Dentistry is widely considered  important for overall health. Dental treatment is carried out by the dental team, which often consists of a dentist and dental auxiliaries (dental assistants, dental hygienists, dental technicians, and dental therapists). Most dentists work in private practices (primary care), although some work in dental hospitals and hospitals (secondary care) and institutions (prisons, armed forces bases, etc.).
The history of dentistry is almost as ancient as the history of humanity and civilization with the earliest evidence dating from 7000 BC. Remains from the early Harappan periods of the Indus Valley Civilization (c. 3300 BC) show evidence of teeth having been drilled dating back 9,000 years. It is thought that dental surgery was the first specialization from medicine."
Descartes	"René Descartes (/ˈdeɪˌkɑːrt/; French: [ʁəne dekaʁt]; Latinized: Renatus Cartesius; adjectival form: ""Cartesian""; 31 March 1596 – 11 February 1650) was a French philosopher, mathematician, and scientist. Dubbed the father of modern western philosophy, much of subsequent Western philosophy is a response to his writings, which are studied closely to this day. He spent about 20 years of his life in the Dutch Republic.
Descartes's Meditations on First Philosophy continues to be a standard text at most university philosophy departments. Descartes's influence in mathematics is equally apparent; the Cartesian coordinate system — allowing reference to a point in space as a set of numbers, and allowing algebraic equations to be expressed as geometric shapes in a two- or three-dimensional coordinate system (and conversely, shapes to be described as equations) — was named after him. He is credited as the father of analytical geometry, the bridge between algebra and geometry, used in the discovery of infinitesimal calculus and analysis. Descartes was also one of the key figures in the scientific revolution.
Descartes refused to accept the authority of previous philosophers, and refused to trust his own senses. He frequently set his views apart from those of his predecessors. In the opening section of the Passions of the Soul, a treatise on the early modern version of what are now commonly called emotions, Descartes goes so far as to assert that he will write on this topic ""as if no one had written on these matters before"". Many elements of his philosophy have precedents in late Aristotelianism, the revived Stoicism of the 16th century, or in earlier philosophers like Augustine. In his natural philosophy, he differs from the schools on two major points: First, he rejects the splitting of corporeal substance into matter and form; second, he rejects any appeal to final ends—divine or natural—in explaining natural phenomena. In his theology, he insists on the absolute freedom of God's act of creation.
Descartes laid the foundation for 17th-century continental rationalism, later advocated by Baruch Spinoza and Gottfried Leibniz, and opposed by the empiricist school of thought consisting of Hobbes, Locke, Berkeley, and Hume. Leibniz, Spinoza and Descartes were all well-versed in mathematics as well as philosophy, and Descartes and Leibniz contributed greatly to science as well.
His best known philosophical statement is ""Cogito ergo sum"" (French: Je pense, donc je suis; I think, therefore I am), found in part IV of Discourse on the Method (1637; written in French but with inclusion of ""Cogito ergo sum"") and §7 of part I of Principles of Philosophy (1644; written in Latin)."
Descent with modification	"Evolution is change in the heritable traits of biological populations over successive generations. Evolutionary processes give rise to diversity at every level of biological organisation, including the levels of species, individual organisms, and molecules.
All life on Earth shares a common ancestor known as the last universal ancestor, which lived approximately 3.5–3.8 billion years ago, although a study in 2015 found ""remains of biotic life"" from 4.1 billion years ago in ancient rocks in Western Australia. According to one of the researchers, ""If life arose relatively quickly on Earth ... then it could be common in the universe.""
Repeated formation of new species (speciation), change within species (anagenesis), and loss of species (extinction) throughout the evolutionary history of life on Earth are demonstrated by shared sets of morphological and biochemical traits, including shared DNA sequences. These shared traits are more similar among species that share a more recent common ancestor, and can be used to reconstruct a biological ""tree of life"" based on evolutionary relationships (phylogenetics), using both existing species and fossils. The fossil record includes a progression from early biogenic graphite, to microbial mat fossils, to fossilized multicellular organisms. Existing patterns of biodiversity have been shaped both by speciation and by extinction. More than 99 percent of all species that ever lived on Earth are estimated to be extinct. Estimates of Earth's current species range from 10 to 14 million, of which about 1.2 million have been documented.
In the mid-19th century, Charles Darwin formulated the scientific theory of evolution by natural selection, published in his book On the Origin of Species (1859). Evolution by natural selection is a process demonstrated by the observation that more offspring are produced than can possibly survive, along with three facts about populations: 1) traits vary among individuals with respect to morphology, physiology, and behaviour (phenotypic variation), 2) different traits confer different rates of survival and reproduction (differential fitness), and 3) traits can be passed from generation to generation (heritability of fitness). Thus, in successive generations members of a population are replaced by progeny of parents better adapted to survive and reproduce in the biophysical environment in which natural selection takes place. This teleonomy is the quality whereby the process of natural selection creates and preserves traits that are seemingly fitted for the functional roles they perform. Natural selection is the only known cause of adaptation but not the only known cause of evolution. Other, nonadaptive causes of microevolution include mutation and genetic drift.
In the early 20th century the modern evolutionary synthesis integrated classical genetics with Darwin's theory of evolution by natural selection through the discipline of population genetics. The importance of natural selection as a cause of evolution was accepted into other branches of biology. Moreover, previously held notions about evolution, such as orthogenesis, evolutionism, and other beliefs about innate ""progress"" within the largest-scale trends in evolution, became obsolete scientific theories. Scientists continue to study various aspects of evolutionary biology by forming and testing hypotheses, constructing mathematical models of theoretical biology and biological theories, using observational data, and performing experiments in both the field and the laboratory.
In terms of practical application, an understanding of evolution has been instrumental to developments in numerous scientific and industrial fields, including agriculture, human and veterinary medicine, and the life sciences in general. Discoveries in evolutionary biology have made a significant impact not just in the traditional branches of biology but also in other academic disciplines, including biological anthropology, and evolutionary psychology. Evolutionary Computation, a sub-field of Artificial Intelligence, is the result of the application of Darwinian principles to problems in Computer Science."
Diffraction	"Diffraction refers to various phenomena which occur when a wave encounters an obstacle or a slit. It is defined as the bending of light around the corners of an obstacle or aperture into the region of geometrical shadow of the obstacle. In classical physics, the diffraction phenomenon is described as the interference of waves according to the Huygens–Fresnel principle. These characteristic behaviors are exhibited when a wave encounters an obstacle or a slit that is comparable in size to its wavelength. Similar effects occur when a light wave travels through a medium with a varying refractive index, or when a sound wave travels through a medium with varying acoustic impedance. Diffraction occurs with all waves, including sound waves, water waves, and electromagnetic waves such as visible light, X-rays and radio waves.
Since physical objects have wave-like properties (at the atomic level), diffraction also occurs with matter and can be studied according to the principles of quantum mechanics. Italian scientist Francesco Maria Grimaldi coined the word ""diffraction"" and was the first to record accurate observations of the phenomenon in 1660.
While diffraction occurs whenever propagating waves encounter such changes, its effects are generally most pronounced for waves whose wavelength is roughly comparable to the dimensions of the diffracting object or slit. If the obstructing object provides multiple, closely spaced openings, a complex pattern of varying intensity can result. This is due to the addition, or interference, of different parts of a wave that travels to the observer by different paths, where different path lengths result in different phases (see diffraction grating and wave superposition). The formalism of diffraction can also describe the way in which waves of finite extent propagate in free space. For example, the expanding profile of a laser beam, the beam shape of a radar antenna and the field of view of an ultrasonic transducer can all be analyzed using diffraction equations."
Ecology	"Ecology (from Greek: οἶκος, ""house"", or ""environment""; -λογία, ""study of"") is the scientific analysis and study of interactions among organisms and their environment. It is an interdisciplinary field that includes biology, geography, and Earth science. Ecology includes the study of interactions organisms have with each other, other organisms, and with abiotic components of their environment. Topics of interest to ecologists include the diversity, distribution, amount (biomass), and number (population) of particular organisms, as well as cooperation and competition between organisms, both within and among ecosystems. Ecosystems are composed of dynamically interacting parts including organisms, the communities they make up, and the non-living components of their environment. Ecosystem processes, such as primary production, pedogenesis, nutrient cycling, and various niche construction activities, regulate the flux of energy and matter through an environment. These processes are sustained by organisms with specific life history traits, and the variety of organisms is called biodiversity. Biodiversity, which refers to the varieties of species, genes, and ecosystems, enhances certain ecosystem services.
Ecology is not synonymous with environment, environmentalism, natural history, or environmental science. It is closely related to evolutionary biology, genetics, and ethology. An important focus for ecologists is to improve the understanding of how biodiversity affects ecological function. Ecologists seek to explain:
Life processes, interactions, and adaptations
The movement of materials and energy through living communities
The successional development of ecosystems
The abundance and distribution of organisms and biodiversity in the context of the environment.
Ecology is a human science as well. There are many practical applications of ecology in conservation biology, wetland management, natural resource management (agroecology, agriculture, forestry, agroforestry, fisheries), city planning (urban ecology), community health, economics, basic and applied science, and human social interaction (human ecology). For example, the Circles of Sustainability approach treats ecology as more than the environment 'out there'. It is not treated as separate from humans. Organisms (including humans) and resources compose ecosystems which, in turn, maintain biophysical feedback mechanisms that moderate processes acting on living (biotic) and non-living (abiotic) components of the planet. Ecosystems sustain life-supporting functions and produce natural capital like biomass production (food, fuel, fiber, and medicine), the regulation of climate, global biogeochemical cycles, water filtration, soil formation, erosion control, flood protection, and many other natural features of scientific, historical, economic, or intrinsic value.
The word ""ecology"" (""Ökologie"") was coined in 1866 by the German scientist Ernst Haeckel (1834–1919). Ecological thought is derivative of established currents in philosophy, particularly from ethics and politics. Ancient Greek philosophers such as Hippocrates and Aristotle laid the foundations of ecology in their studies on natural history. Modern ecology became a much more rigorous science in the late 19th century. Evolutionary concepts relating to adaptation and natural selection became the cornerstones of modern ecological theory."
Economics	"Economics is the social science that describes the factors that determine the production, distribution and consumption of goods and services.
The term economics comes from the Ancient Greek οἰκονομία from οἶκος (oikos, ""house"") and νόμος (nomos, ""custom"" or ""law""), hence ""rules of the house (hold for good management)"". 'Political economy' was the earlier name for the subject, but economists in the late 19th century suggested ""economics"" as a shorter term for ""economic science"" to establish itself as a separate discipline outside of political science and other social sciences.
Economics focuses on the behavior and interactions of economic agents and how economies work. Consistent with this focus, primary textbooks often distinguish between microeconomics and macroeconomics. Microeconomics examines the behavior of basic elements in the economy, including individual agents and markets, their interactions, and the outcomes of interactions. Individual agents may include, for example, households, firms, buyers, and sellers. Macroeconomics analyzes the entire economy (meaning aggregated production, consumption, savings, and investment) and issues affecting it, including unemployment of resources (labor, capital, and land), inflation, economic growth, and the public policies that address these issues (monetary, fiscal, and other policies).
Other broad distinctions within economics include those between positive economics, describing ""what is,"" and normative economics, advocating ""what ought to be""; between economic theory and applied economics; between rational and behavioral economics; and between mainstream economics (more ""orthodox"" and dealing with the ""rationality-individualism-equilibrium nexus"") and heterodox economics (more ""radical"" and dealing with the ""institutions-history-social structure nexus"").
Besides the traditional concern in production, distribution, and consumption in an economy, economic analysis may be applied throughout society, as in business, finance, health care, and government. Economic analyses may also be applied to such diverse subjects as crime, education, the family, law, politics, religion, social institutions, war, science, and the environment. Education, for example, requires time, effort, and expenses, plus the foregone income and experience, yet these losses can be weighted against future benefits education may bring to the agent or the economy. At the turn of the 21st century, the expanding domain of economics in the social sciences has been described as economic imperialism.

The ultimate goal of economics is to improve the living conditions of people in their everyday life. "
Einstein	"Albert Einstein (/ˈaɪnstaɪn/; German: [ˈalbɛɐ̯t ˈaɪnʃtaɪn]; 14 March 1879 – 18 April 1955) was a German-born theoretical physicist. He developed the general theory of relativity, one of the two pillars of modern physics (alongside quantum mechanics). Einstein's work is also known for its influence on the philosophy of science. Einstein is best known in popular culture for his mass–energy equivalence formula E = mc2 (which has been dubbed ""the world's most famous equation""). He received the 1921 Nobel Prize in Physics for his ""services to theoretical physics"", in particular his discovery of the law of the photoelectric effect, a pivotal step in the evolution of quantum theory.
Near the beginning of his career, Einstein thought that Newtonian mechanics was no longer enough to reconcile the laws of classical mechanics with the laws of the electromagnetic field. This led to the development of his special theory of relativity. He realized, however, that the principle of relativity could also be extended to gravitational fields, and with his subsequent theory of gravitation in 1916, he published a paper on general relativity. He continued to deal with problems of statistical mechanics and quantum theory, which led to his explanations of particle theory and the motion of molecules. He also investigated the thermal properties of light which laid the foundation of the photon theory of light. In 1917, Einstein applied the general theory of relativity to model the large-scale structure of the universe.
He was visiting the United States when Adolf Hitler came to power in 1933 and, being Jewish, did not go back to Germany, where he had been a professor at the Berlin Academy of Sciences. He settled in the U.S., becoming an American citizen in 1940. On the eve of World War II, he endorsed a letter to President Franklin D. Roosevelt alerting him to the potential development of ""extremely powerful bombs of a new type"" and recommending that the U.S. begin similar research. This eventually led to what would become the Manhattan Project. Einstein supported defending the Allied forces, but largely denounced the idea of using the newly discovered nuclear fission as a weapon. Later, with the British philosopher Bertrand Russell, Einstein signed the Russell–Einstein Manifesto, which highlighted the danger of nuclear weapons. Einstein was affiliated with the Institute for Advanced Study in Princeton, New Jersey, until his death in 1955.
Einstein published more than 300 scientific papers along with over 150 non-scientific works. On 5 December 2014, universities and archives announced the release of Einstein's papers, comprising more than 30,000 unique documents. Einstein's intellectual achievements and originality have made the word ""Einstein"" synonymous with ""genius""."
Electric lighting	"An electric light is a device that produces visible light by the flow of electric current. It is the most common form of artificial lighting and is essential to modern society, providing interior lighting for buildings and exterior light for evening and nighttime activities. In technical usage, a replaceable component that produces light from electricity is called a lamp. Compact lamps are commonly called light bulbs; for example, the incandescent light bulb. Lamps usually have a base made of ceramic, metal, glass or plastic, which secures the lamp in the socket of a light fixture. The electrical connection to the socket may be made with a screw-thread base, two metal pins, two metal caps or a bayonet cap.
The three main categories of electric lights are incandescent lamps, which produce light by a filament heated white-hot by electric current, gas-discharge lamps, which produce light by means of an electric arc through a gas, and LED lamps, which produce light by a flow of electrons across a band gap in a semiconductor.
Before electric lighting became common in the early 20th century, people used candles, gas lights, oil lamps, and fires. Humphry Davy developed the first incandescent light in 1802, followed by the first practical electric arc light in 1806. By the 1870s, Davy's arc lamp had been successfully commercialized, and was used to light many public spaces. The development of a steadily glowing filament suitable for interior lighting took longer, but by the early twentieth century inventors had successfully developed options, replacing the arc light with incandescents.
The energy efficiency of electric lighting has increased radically since the first demonstration of arc lamps and the incandescent light bulb of the 19th century. Modern electric light sources come in a profusion of types and sizes adapted to myriad applications. Most modern electric lighting is powered by centrally generated electric power, but lighting may also be powered by mobile or standby electric generators or battery systems. Battery-powered lights, usually called ""flashlights"" or ""torches"", are used for portability and as backups when the main lights fail."
Electromagnetic theory	"Maxwell's equations are a set of partial differential equations that, together with the Lorentz force law, form the foundation of classical electrodynamics, classical optics, and electric circuits. These fields in turn underlie modern electrical and communications technologies. Maxwell's equations describe how electric and magnetic fields are generated and altered by each other and by charges and currents. They are named after the physicist and mathematician James Clerk Maxwell, who published an early form of those equations between 1861 and 1862.
The equations have two major variants. The ""microscopic"" set of Maxwell's equations uses total charge and total current, including the complicated charges and currents in materials at the atomic scale; it has universal applicability but may be infeasible to calculate. The ""macroscopic"" set of Maxwell's equations defines two new auxiliary fields that describe large-scale behaviour without having to consider these atomic scale details, but it requires the use of parameters characterizing the electromagnetic properties of the relevant materials.
The term ""Maxwell's equations"" is often used for other forms of Maxwell's equations. For example, space-time formulations are commonly used in high energy and gravitational physics. These formulations, defined on space-time rather than space and time separately, are manifestly compatible with special and general relativity. In quantum mechanics and analytical mechanics, versions of Maxwell's equations based on the electric and magnetic potentials are preferred.
Since the mid-20th century, it has been understood that Maxwell's equations are not exact but are a classical field theory approximation to the more accurate and fundamental theory of quantum electrodynamics. In many situations, though, deviations from Maxwell's equations are immeasurably small. Exceptions include nonclassical light, photon-photon scattering, quantum optics, and many other phenomena related to photons or virtual photons."
Electron	"The electron is a subatomic particle, symbol e− or β−, with a negative elementary electric charge. Electrons belong to the first generation of the lepton particle family, and are generally thought to be elementary particles because they have no known components or substructure. The electron has a mass that is approximately 1/1836 that of the proton. Quantum mechanical properties of the electron include an intrinsic angular momentum (spin) of a half-integer value in units of ħ, which means that it is a fermion. Being fermions, no two electrons can occupy the same quantum state, in accordance with the Pauli exclusion principle. Like all matter, electrons have properties of both particles and waves, and so can collide with other particles and can be diffracted like light. The wave properties of electrons are easier to observe with experiments than those of other particles like neutrons and protons because electrons have a lower mass and hence a higher De Broglie wavelength for typical energies.
Many physical phenomena involve electrons in an essential role, such as electricity, magnetism, and thermal conductivity, and they also participate in gravitational, electromagnetic and weak interactions. An electron generates an electric field surrounding it. An electron moving relative to an observer generates a magnetic field. External electromagnetic fields affect an electron according to the Lorentz force law. Electrons radiate or absorb energy in the form of photons when accelerated. Laboratory instruments are capable of containing and observing individual electrons as well as electron plasma using electromagnetic fields, whereas dedicated telescopes can detect electron plasma in outer space. Electrons are involved in many applications such as electronics, welding, cathode ray tubes, electron microscopes, radiation therapy, lasers, gaseous ionization detectors and particle accelerators.
Interactions involving electrons and other subatomic particles are of interest in fields such as chemistry and nuclear physics. The Coulomb force interaction between positive protons inside atomic nuclei and negative electrons composes atoms. Ionization or changes in the proportions of particles changes the binding energy of the system. The exchange or sharing of the electrons between two or more atoms is the main cause of chemical bonding. British natural philosopher Richard Laming first hypothesized the concept of an indivisible quantity of electric charge to explain the chemical properties of atoms in 1838; Irish physicist George Johnstone Stoney named this charge 'electron' in 1891, and J. J. Thomson and his team of British physicists identified it as a particle in 1897. Electrons can also participate in nuclear reactions, such as nucleosynthesis in stars, where they are known as beta particles. Electrons may be created through beta decay of radioactive isotopes and in high-energy collisions, for instance when cosmic rays enter the atmosphere. The antiparticle of the electron is called the positron; it is identical to the electron except that it carries electrical and other charges of the opposite sign. When an electron collides with a positron, both particles may be totally annihilated, producing gamma ray photons."
Electronics	"Electronics is the science of how to control electric energy, energy in which the electrons have a fundamental role. Electronics deals with electrical circuits that involve active electrical components such as vacuum tubes, transistors, diodes and integrated circuits, and associated passive electrical components and interconnection technologies. Commonly, electronic devices contain circuitry consisting primarily or exclusively of active semiconductors supplemented with passive elements; such a circuit is described as an electronic circuit.
The nonlinear behaviour of active components and their ability to control electron flows makes amplification of weak signals possible, and electronics is widely used in information processing, telecommunication, and signal processing. The ability of electronic devices to act as switches makes digital information processing possible. Interconnection technologies such as circuit boards, electronics packaging technology, and other varied forms of communication infrastructure complete circuit functionality and transform the mixed components into a regular working system.
Electronics is distinct from electrical and electro-mechanical science and technology, which deal with the generation, distribution, switching, storage, and conversion of electrical energy to and from other energy forms using wires, motors, generators, batteries, switches, relays, transformers, resistors, and other passive components. This distinction started around 1906 with the invention by Lee De Forest of the triode, which made electrical amplification of weak radio signals and audio signals possible with a non-mechanical device. Until 1950 this field was called ""radio technology"" because its principal application was the design and theory of radio transmitters, receivers, and vacuum tubes.
Today, most electronic devices use semiconductor components to perform electron control. The study of semiconductor devices and related technology is considered a branch of solid-state physics, whereas the design and construction of electronic circuits to solve practical problems come under electronics engineering. This article focuses on engineering aspects of electronics."
Electrons	"The electron is a subatomic particle, symbol e− or β−, with a negative elementary electric charge. Electrons belong to the first generation of the lepton particle family, and are generally thought to be elementary particles because they have no known components or substructure. The electron has a mass that is approximately 1/1836 that of the proton. Quantum mechanical properties of the electron include an intrinsic angular momentum (spin) of a half-integer value in units of ħ, which means that it is a fermion. Being fermions, no two electrons can occupy the same quantum state, in accordance with the Pauli exclusion principle. Like all matter, electrons have properties of both particles and waves, and so can collide with other particles and can be diffracted like light. The wave properties of electrons are easier to observe with experiments than those of other particles like neutrons and protons because electrons have a lower mass and hence a higher De Broglie wavelength for typical energies.
Many physical phenomena involve electrons in an essential role, such as electricity, magnetism, and thermal conductivity, and they also participate in gravitational, electromagnetic and weak interactions. An electron generates an electric field surrounding it. An electron moving relative to an observer generates a magnetic field. External electromagnetic fields affect an electron according to the Lorentz force law. Electrons radiate or absorb energy in the form of photons when accelerated. Laboratory instruments are capable of containing and observing individual electrons as well as electron plasma using electromagnetic fields, whereas dedicated telescopes can detect electron plasma in outer space. Electrons are involved in many applications such as electronics, welding, cathode ray tubes, electron microscopes, radiation therapy, lasers, gaseous ionization detectors and particle accelerators.
Interactions involving electrons and other subatomic particles are of interest in fields such as chemistry and nuclear physics. The Coulomb force interaction between positive protons inside atomic nuclei and negative electrons composes atoms. Ionization or changes in the proportions of particles changes the binding energy of the system. The exchange or sharing of the electrons between two or more atoms is the main cause of chemical bonding. British natural philosopher Richard Laming first hypothesized the concept of an indivisible quantity of electric charge to explain the chemical properties of atoms in 1838; Irish physicist George Johnstone Stoney named this charge 'electron' in 1891, and J. J. Thomson and his team of British physicists identified it as a particle in 1897. Electrons can also participate in nuclear reactions, such as nucleosynthesis in stars, where they are known as beta particles. Electrons may be created through beta decay of radioactive isotopes and in high-energy collisions, for instance when cosmic rays enter the atmosphere. The antiparticle of the electron is called the positron; it is identical to the electron except that it carries electrical and other charges of the opposite sign. When an electron collides with a positron, both particles may be totally annihilated, producing gamma ray photons."
Emmy Noether	"Emmy Noether (German: [ˈnøːtɐ]; official name Amalie Emmy Noether; 23 March 1882 – 14 April 1935) was a German Jewish mathematician known for her landmark contributions to abstract algebra and theoretical physics. She was described by Pavel Alexandrov, Albert Einstein, Jean Dieudonné, Hermann Weyl, and Norbert Wiener as the most important woman in the history of mathematics. As one of the leading mathematicians of her time, she developed the theories of rings, fields, and algebras. In physics, Noether's theorem explains the connection between symmetry and conservation laws.
Noether was born to a Jewish family in the Franconian town of Erlangen; her father was a mathematician, Max Noether. She originally planned to teach French and English after passing the required examinations, but instead studied mathematics at the University of Erlangen, where her father lectured. After completing her dissertation in 1907 under the supervision of Paul Gordan, she worked at the Mathematical Institute of Erlangen without pay for seven years. At the time, women were largely excluded from academic positions. In 1915, she was invited by David Hilbert and Felix Klein to join the mathematics department at the University of Göttingen, a world-renowned center of mathematical research. The philosophical faculty objected, however, and she spent four years lecturing under Hilbert's name. Her habilitation was approved in 1919, allowing her to obtain the rank of Privatdozent.
Noether remained a leading member of the Göttingen mathematics department until 1933; her students were sometimes called the ""Noether boys"". In 1924, Dutch mathematician B. L. van der Waerden joined her circle and soon became the leading expositor of Noether's ideas: her work was the foundation for the second volume of his influential 1931 textbook, Moderne Algebra. By the time of her plenary address at the 1932 International Congress of Mathematicians in Zürich, her algebraic acumen was recognized around the world. The following year, Germany's Nazi government dismissed Jews from university positions, and Noether moved to the United States to take up a position at Bryn Mawr College in Pennsylvania. In 1935 she underwent surgery for an ovarian cyst and, despite signs of a recovery, died four days later at the age of 53.
Noether's mathematical work has been divided into three ""epochs"". In the first (1908–19), she made contributions to the theories of algebraic invariants and number fields. Her work on differential invariants in the calculus of variations, Noether's theorem, has been called ""one of the most important mathematical theorems ever proved in guiding the development of modern physics"". In the second epoch (1920–26), she began work that ""changed the face of [abstract] algebra"". In her classic paper Idealtheorie in Ringbereichen (Theory of Ideals in Ring Domains, 1921) Noether developed the theory of ideals in commutative rings into a tool with wide-ranging applications. She made elegant use of the ascending chain condition, and objects satisfying it are named Noetherian in her honor. In the third epoch (1927–35), she published works on noncommutative algebras and hypercomplex numbers and united the representation theory of groups with the theory of modules and ideals. In addition to her own publications, Noether was generous with her ideas and is credited with several lines of research published by other mathematicians, even in fields far removed from her main work, such as algebraic topology."
Encyclopædia Britannica	"The Encyclopædia Britannica (Latin for ""British Encyclopaedia""), published by Encyclopædia Britannica, Inc., is a general knowledge English-language encyclopaedia. It is written by about 100 full-time editors and more than 4,000 contributors, who have included 110 Nobel Prize winners and five American presidents. The 2010 version of the 15th edition, which spans 32 volumes and 32,640 pages, was the last printed edition; digital content and distribution has continued since then.
The Britannica is the oldest English-language encyclopaedia still in production. It was first published between 1768 and 1771 in the Scottish capital of Edinburgh, as three volumes. The encyclopaedia grew in size: the second edition was 10 volumes, and by its fourth edition (1801–1810) it had expanded to 20 volumes. Its rising stature as a scholarly work helped recruit eminent contributors, and the 9th (1875–1889) and 11th editions (1911) are landmark encyclopaedias for scholarship and literary style. Beginning with the 11th edition and following its acquisition by an American firm, the Britannica shortened and simplified articles to broaden its appeal to the North American market. In 1933, the Britannica became the first encyclopaedia to adopt ""continuous revision"", in which the encyclopaedia is continually reprinted, with every article updated on a schedule. In March 2012, Encyclopædia Britannica, Inc. announced it would no longer publish printed editions, and would focus instead on Encyclopædia Britannica Online.
The 15th edition has a three-part structure: a 12-volume Micropædia of short articles (generally fewer than 750 words), a 17-volume Macropædia of long articles (two to 310 pages), and a single Propædia volume to give a hierarchical outline of knowledge. The Micropædia is meant for quick fact-checking and as a guide to the Macropædia; readers are advised to study the Propædia outline to understand a subject's context and to find more detailed articles. Over 70 years, the size of the Britannica has remained steady, with about 40 million words on half a million topics. Though published in the United States since 1901, the Britannica has for the most part maintained British English spelling."
Energy	"In physics, energy is a property of objects which can be transferred to other objects or converted into different forms. The ""ability of a system to perform work"" is a common description, but it is difficult to give one single comprehensive definition of energy because of its many forms. For instance, in SI units, energy is measured in joules, and one joule is defined ""mechanically"", being the energy transferred to an object by the mechanical work of moving it a distance of 1 metre against a force of 1 newton. However, there are many other definitions of energy, depending on the context, such as thermal energy, radiant energy, electromagnetic, nuclear, etc., where definitions are derived that are the most convenient.
Common energy forms include the kinetic energy of a moving object, the potential energy stored by an object's position in a force field (gravitational, electric or magnetic), the elastic energy stored by stretching solid objects, the chemical energy released when a fuel burns, the radiant energy carried by light, and the thermal energy due to an object's temperature. All of the many forms of energy are convertible to other kinds of energy. In Newtonian physics, there is a universal law of conservation of energy which says that energy can be neither created nor be destroyed; however, it can change from one form to another.
For ""closed systems"" with no external source or sink of energy, the first law of thermodynamics states that a system's energy is constant unless energy is transferred in or out by mechanical work or heat, and that no energy is lost in transfer. This means that it is impossible to create or destroy energy. While heat can always be fully converted into work in a reversible isothermal expansion of an ideal gas, for cyclic processes of practical interest in heat engines the second law of thermodynamics states that the system doing work always loses some energy as waste heat. This creates a limit to the amount of heat energy that can do work in a cyclic process, a limit called the available energy. Mechanical and other forms of energy can be transformed in the other direction into thermal energy without such limitations. The total energy of a system can be calculated by adding up all forms of energy in the system.
Examples of energy transformation include generating electric energy from heat energy via a steam turbine, or lifting an object against gravity using electrical energy driving a crane motor. Lifting against gravity performs mechanical work on the object and stores gravitational potential energy in the object. If the object falls to the ground, gravity does mechanical work on the object which transforms the potential energy in the gravitational field to the kinetic energy released as heat on impact with the ground. Our Sun transforms nuclear potential energy to other forms of energy; its total mass does not decrease due to that in itself (since it still contains the same total energy even if in different forms), but its mass does decrease when the energy escapes out to its surroundings, largely as radiant energy.
Mass and energy are closely related. According to the theory of mass–energy equivalence, any object that has mass when stationary in a frame of reference (called rest mass) also has an equivalent amount of energy whose form is called rest energy in that frame, and any additional energy acquired by the object above that rest energy will increase an object's mass. For example, if you had a sensitive enough scale, you could measure an increase in mass after heating an object.
Living organisms require available energy to stay alive, such as the energy humans get from food. Civilisation gets the energy it needs from energy resources such as fossil fuels, nuclear fuel, or renewable energy. The processes of Earth's climate and ecosystem are driven by the radiant energy Earth receives from the sun and the geothermal energy contained within the earth."
Entertainment	"Entertainment is a form of activity that holds the attention and interest of an audience, or gives pleasure and delight. It can be an idea or a task, but is more likely to be one of the activities or events that have developed over thousands of years specifically for the purpose of keeping an audience's attention. Although people's attention is held by different things, because individuals have different preferences in entertainment, most forms are recognisable and familiar. Storytelling, music, drama, dance, and different kinds of performance exist in all cultures, were supported in royal courts, developed into sophisticated forms and over time became available to all citizens. The process has been accelerated in modern times by an entertainment industry which records and sells entertainment products. Entertainment evolves and can be adapted to suit any scale, ranging from an individual who chooses a private entertainment from a now enormous array of pre-recorded products; to a banquet adapted for two; to any size or type of party, with appropriate music and dance; to performances intended for thousands; and even for a global audience.
The experience of being entertained has come to be strongly associated with amusement, so that one common understanding of the idea is fun and laughter, although many entertainments have a serious purpose. This may be the case in the various forms of ceremony, celebration, religious festival, or satire for example. Hence, there is the possibility that what appears as entertainment may also be a means of achieving insight or intellectual growth.
An important aspect of entertainment is the audience, which turns a private recreation or leisure activity into entertainment. The audience may have a passive role, as in the case of persons watching a play, opera, television show, or film; or the audience role may be active, as in the case of games, where the participant/audience roles may be routinely reversed. Entertainment can be public or private, involving formal, scripted performance, as in the case of theatre or concerts; or unscripted and spontaneous, as in the case of children's games. Most forms of entertainment have persisted over many centuries, evolving due to changes in culture, technology, and fashion. Films and video games, for example, although they use newer media, continue to tell stories, present drama, and play music. Festivals devoted to music, film, or dance allow audiences to be entertained over a number of consecutive days.
Some activities that once were considered entertaining, particularly public punishments, have been removed from the public arena. Others, such as fencing or archery, once necessary skills for some, have become serious sports and even professions for the participants, at the same time developing into entertainment with wider appeal for bigger audiences. In the same way, other necessary skills, such as cooking, have developed into performances among professionals, staged as global competitions and then broadcast for entertainment. What is entertainment for one group or individual may be regarded as work by another.
The familiar forms of entertainment have the capacity to cross over different media and have demonstrated a seemingly unlimited potential for creative remix. This has ensured the continuity and longevity of many themes, images, and structures."
Environmental chemistry	"Environmental chemistry is the scientific study of the chemical and biochemical phenomena that occur in natural places. It should not be confused with green chemistry, which seeks to reduce potential pollution at its source. It can be defined as the study of the sources, reactions, transport, effects, and fates of chemical species in the air, soil, and water environments; and the effect of human activity and biological activity on these. Environmental chemistry is an interdisciplinary science that includes atmospheric, aquatic and soil chemistry, as well as heavily relying on analytical chemistry and being related to environmental and other areas of science.
Environmental chemistry is the study of chemical processes occurring in the environment which are impacted by humankind's activities. These impacts may be felt on a local scale, through the presence of urban air pollutants or toxic substances arising from a chemical waste site, or on a global scale, through depletion of stratospheric ozone or global warming. The focus in our courses and research activities is upon developing a fundamental understanding of the nature of these chemical processes, so that humankind's activities can be accurately evaluated.
Environmental chemistry involves first understanding how the uncontaminated environment works, which chemicals in what concentrations are present naturally, and with what effects. Without this it would be impossible to accurately study the effects humans have on the environment through the release of chemicals.
Environmental chemists draw on a range of concepts from chemistry and various environmental sciences to assist in their study of what is happening to a chemical species in the environment. Important general concepts from chemistry include understanding chemical reactions and equations, solutions, units, sampling, and analytical techniques."
Environmental science	"Environmental science is an interdisciplinary academic field that integrates physical, biological and information sciences (including ecology, biology, physics, chemistry, zoology, mineralogy, oceanology, limnology, soil science, geology, atmospheric science, and geodesy) to the study of the environment, and the solution of environmental problems. Environmental science emerged from the fields of natural history and medicine during the Enlightenment. Today it provides an integrated, quantitative, and interdisciplinary approach to the study of environmental systems.
Related areas of study include environmental studies and environmental engineering. Environmental studies incorporates more of the social sciences for understanding human relationships, perceptions and policies towards the environment. Environmental engineering focuses on design and technology for improving environmental quality in every aspect.
Environmental scientists work on subjects like the understanding of earth processes, evaluating alternative energy systems, pollution control and mitigation, natural resource management, and the effects of global climate change. Environmental issues almost always include an interaction of physical, chemical, and biological processes. Environmental scientists bring a systems approach to the analysis of environmental problems. Key elements of an effective environmental scientist include the ability to relate space, and time relationships as well as quantitative analysis.
Environmental science came alive as a substantive, active field of scientific investigation in the 1960s and 1970s driven by (a) the need for a multi-disciplinary approach to analyze complex environmental problems, (b) the arrival of substantive environmental laws requiring specific environmental protocols of investigation and (c) the growing public awareness of a need for action in addressing environmental problems. Events that spurred this development included the publication of Rachel Carson's landmark environmental book Silent Spring along with major environmental issues becoming very public, such as the 1969 Santa Barbara oil spill, and the Cuyahoga River of Cleveland, Ohio, ""catching fire"" (also in 1969), and helped increase the visibility of environmental issues and create this new field of study."
Ethology	"Ethology is the scientific and objective study of non-human animal behaviour rather than human behaviour and usually with a focus on behaviour under natural conditions, and viewing behaviour as an evolutionarily adaptive trait. Behaviourism is a term that also describes the scientific and objective study of animal behaviour, but usually refers to the study of human behavior and trained behavioural responses in a laboratory context, without a particular emphasis on evolutionary adaptivity.
Many naturalists have studied aspects of animal behaviour throughout history. Ethology has its scientific roots in the work of Charles Darwin and of American and German ornithologists of the late 19th and early 20th century, including Charles O. Whitman, Oskar Heinroth, and Wallace Craig. The modern discipline of ethology is generally considered to have begun during the 1930s with the work of Dutch biologist Nikolaas Tinbergen and by Austrian biologists Konrad Lorenz and Karl von Frisch, joint awardees of the 1973 Nobel Prize in Physiology or Medicine. Ethology is a combination of laboratory and field science, with a strong relation to some other disciplines such as neuroanatomy, ecology, and evolutionary biology. Ethologists are typically interested in a behavioural process rather than in a particular animal group, and often study one type of behaviour, such as aggression, in a number of unrelated animals.
Ethology is a rapidly growing field. Since the dawn of the 21st century, many aspects of animal communication, emotions, culture, learning and sexuality that the scientific community long thought it understood have been re-examined, and new conclusions reached. New fields, such as neuroethology, have developed.
Understanding ethology or animal behaviour can be important in animal training. Considering the natural behaviours of different species or breeds enables the trainer to select the individuals best suited to perform the required task. It also enables the trainer to encourage the performance of naturally occurring behaviours and also the discontinuance of undesirable behaviours."
Evolution	"Evolution is change in the heritable traits of biological populations over successive generations. Evolutionary processes give rise to diversity at every level of biological organisation, including the levels of species, individual organisms, and molecules.
All life on Earth shares a common ancestor known as the last universal ancestor, which lived approximately 3.5–3.8 billion years ago, although a study in 2015 found ""remains of biotic life"" from 4.1 billion years ago in ancient rocks in Western Australia. According to one of the researchers, ""If life arose relatively quickly on Earth ... then it could be common in the universe.""
Repeated formation of new species (speciation), change within species (anagenesis), and loss of species (extinction) throughout the evolutionary history of life on Earth are demonstrated by shared sets of morphological and biochemical traits, including shared DNA sequences. These shared traits are more similar among species that share a more recent common ancestor, and can be used to reconstruct a biological ""tree of life"" based on evolutionary relationships (phylogenetics), using both existing species and fossils. The fossil record includes a progression from early biogenic graphite, to microbial mat fossils, to fossilized multicellular organisms. Existing patterns of biodiversity have been shaped both by speciation and by extinction. More than 99 percent of all species that ever lived on Earth are estimated to be extinct. Estimates of Earth's current species range from 10 to 14 million, of which about 1.2 million have been documented.
In the mid-19th century, Charles Darwin formulated the scientific theory of evolution by natural selection, published in his book On the Origin of Species (1859). Evolution by natural selection is a process demonstrated by the observation that more offspring are produced than can possibly survive, along with three facts about populations: 1) traits vary among individuals with respect to morphology, physiology, and behaviour (phenotypic variation), 2) different traits confer different rates of survival and reproduction (differential fitness), and 3) traits can be passed from generation to generation (heritability of fitness). Thus, in successive generations members of a population are replaced by progeny of parents better adapted to survive and reproduce in the biophysical environment in which natural selection takes place. This teleonomy is the quality whereby the process of natural selection creates and preserves traits that are seemingly fitted for the functional roles they perform. Natural selection is the only known cause of adaptation but not the only known cause of evolution. Other, nonadaptive causes of microevolution include mutation and genetic drift.
In the early 20th century the modern evolutionary synthesis integrated classical genetics with Darwin's theory of evolution by natural selection through the discipline of population genetics. The importance of natural selection as a cause of evolution was accepted into other branches of biology. Moreover, previously held notions about evolution, such as orthogenesis, evolutionism, and other beliefs about innate ""progress"" within the largest-scale trends in evolution, became obsolete scientific theories. Scientists continue to study various aspects of evolutionary biology by forming and testing hypotheses, constructing mathematical models of theoretical biology and biological theories, using observational data, and performing experiments in both the field and the laboratory.
In terms of practical application, an understanding of evolution has been instrumental to developments in numerous scientific and industrial fields, including agriculture, human and veterinary medicine, and the life sciences in general. Discoveries in evolutionary biology have made a significant impact not just in the traditional branches of biology but also in other academic disciplines, including biological anthropology, and evolutionary psychology. Evolutionary Computation, a sub-field of Artificial Intelligence, is the result of the application of Darwinian principles to problems in Computer Science."
Evolutionary psychology	"Evolutionary psychology (EP) is a theoretical approach in the social and natural sciences that examines psychological structure from a modern evolutionary perspective. It seeks to identify which human psychological traits are evolved adaptations – that is, the functional products of natural selection or sexual selection in human evolution. Adaptationist thinking about physiological mechanisms, such as the heart, lungs, and immune system, is common in evolutionary biology. Some evolutionary psychologists apply the same thinking to psychology, arguing that the modularity of mind is similar to that of the body and with different modular adaptations serving different functions. Evolutionary psychologists argue that much of human behavior is the output of psychological adaptations that evolved to solve recurrent problems in human ancestral environments.
Evolutionary psychologists suggest that EP is not simply a subdiscipline of psychology but that evolutionary theory can provide a foundational, metatheoretical framework that integrates the entire field of psychology, in the same way it has for biology.
Evolutionary psychologists hold that behaviors or traits that occur universally in all cultures are good candidates for evolutionary adaptations including the abilities to infer others' emotions, discern kin from non-kin, identify and prefer healthier mates, and cooperate with others. They report successful tests of theoretical predictions related to such topics as infanticide, intelligence, marriage patterns, promiscuity, perception of beauty, bride price, and parental investment.
The theories and findings of EP have applications in many fields, including economics, environment, health, law, management, psychiatry, politics, and literature.
Criticism of evolutionary psychology involves questions of testability, cognitive and evolutionary assumptions (such as modular functioning of the brain, and large uncertainty about the ancestral environment), importance of non-genetic and non-adaptive explanations, as well as political and ethical issues due to interpretations of research results."
Fiber optic	"An optical fiber (or optical fibre) is a flexible, transparent fiber made by drawing glass (silica) or plastic to a diameter slightly thicker than that of a human hair. Optical fibers are used most often as a means to transmit light between the two ends of the fiber and find wide usage in fiber-optic communications, where they permit transmission over longer distances and at higher bandwidths (data rates) than wire cables. Fibers are used instead of metal wires because signals travel along them with lesser amounts of loss; in addition, fibers are also immune to electromagnetic interference, a problem from which metal wires suffer excessively. Fibers are also used for illumination, and are wrapped in bundles so that they may be used to carry images, thus allowing viewing in confined spaces, as in the case of a fiberscope. Specially designed fibers are also used for a variety of other applications, some of them being fiber optic sensors and fiber lasers.
Optical fibers typically include a transparent core surrounded by a transparent cladding material with a lower index of refraction. Light is kept in the core by the phenomenon of total internal reflection which causes the fiber to act as a waveguide. Fibers that support many propagation paths or transverse modes are called multi-mode fibers (MMF), while those that support a single mode are called single-mode fibers (SMF). Multi-mode fibers generally have a wider core diameter and are used for short-distance communication links and for applications where high power must be transmitted. Single-mode fibers are used for most communication links longer than 1,000 meters (3,300 ft).
An important aspect of a fiber optic communication is that of extension of the fiber optic cables such that the losses brought about by joining two different cables is kept to a minimum. Joining lengths of optical fiber often proves to be more complex than joining electrical wire or cable and involves careful cleaving of the fibers, perfect alignment of the fiber cores, and the splicing of these aligned fiber cores. For applications that demand a permanent connection a mechanical splice which holds the ends of the fibers together mechanically could be used or a fusion splice that uses heat to fuse the ends of the fibers together could be used. Temporary or semi-permanent connections are made by means of specialized optical fiber connectors.
The field of applied science and engineering concerned with the design and application of optical fibers is known as fiber optics."
Final cause	"""Four causes"" refers to an influential principle in Aristotelian thought whereby explanations of change or movement are classified into four fundamental types of answer to the question ""why?"" Aristotle wrote that ""we do not have knowledge of a thing until we have grasped its why, that is to say, its explanation."" While there are cases where classifying an explanation is difficult, or in which classes of explanation might merge, Aristotle was convinced that his four classes of explanation provided an analytical scheme of general applicability.
Aitia, from Greek αἰτία was the word that Aristotle used to refer to the concept of explanation. Traditionally in academic philosophy it has been translated as cause, but this tradition uses the word 'cause' in a peculiar way that is obsolete, or highly specialized and technical in philosophy, not in its most usual current ordinary language usage. The translation of Aristotle's αἰτία that is nearest to current ordinary language is 'explanation'.
Aristotle held that there were four kinds of answers to 'why' questions (in Physics II, 3, and Metaphysics V, 2): In this article, the peculiar philosophical usage of the word 'cause' will be exercised, for tradition's sake, but the reader should not be misled by confusing this peculiar usage with current ordinary language.
A change or movement's material explanation is the aspect of the change or movement which is determined by the material that composes the moving or changing things. For a table, that might be wood; for a statue, that might be bronze or marble.
A change or movement's formal explanation is a change or movement caused by the arrangement, shape or appearance of the thing changing or moving. Aristotle says for example that the ratio 2:1, and number in general, is the explanation of the octave.
A change or movement's efficient or moving explanation consists of things apart from the thing being changed or moved, which interact so as to be an agency within the change or movement. For example, the efficient explanation of a table is a carpenter, or a person working as one, and according to Aristotle the efficient explanation of a boy is a father.
An event's final explanation is the end toward which it directs. That for the sake of which a thing is what it is. For a seed, it might be an adult plant. For a sailboat, it might be sailing. For a ball at the top of a ramp, it might be coming to rest at the bottom. For a person's action, it is the goal."
Formal cause	"""Four causes"" refers to an influential principle in Aristotelian thought whereby explanations of change or movement are classified into four fundamental types of answer to the question ""why?"" Aristotle wrote that ""we do not have knowledge of a thing until we have grasped its why, that is to say, its explanation."" While there are cases where classifying an explanation is difficult, or in which classes of explanation might merge, Aristotle was convinced that his four classes of explanation provided an analytical scheme of general applicability.
Aitia, from Greek αἰτία was the word that Aristotle used to refer to the concept of explanation. Traditionally in academic philosophy it has been translated as cause, but this tradition uses the word 'cause' in a peculiar way that is obsolete, or highly specialized and technical in philosophy, not in its most usual current ordinary language usage. The translation of Aristotle's αἰτία that is nearest to current ordinary language is 'explanation'.
Aristotle held that there were four kinds of answers to 'why' questions (in Physics II, 3, and Metaphysics V, 2): In this article, the peculiar philosophical usage of the word 'cause' will be exercised, for tradition's sake, but the reader should not be misled by confusing this peculiar usage with current ordinary language.
A change or movement's material explanation is the aspect of the change or movement which is determined by the material that composes the moving or changing things. For a table, that might be wood; for a statue, that might be bronze or marble.
A change or movement's formal explanation is a change or movement caused by the arrangement, shape or appearance of the thing changing or moving. Aristotle says for example that the ratio 2:1, and number in general, is the explanation of the octave.
A change or movement's efficient or moving explanation consists of things apart from the thing being changed or moved, which interact so as to be an agency within the change or movement. For example, the efficient explanation of a table is a carpenter, or a person working as one, and according to Aristotle the efficient explanation of a boy is a father.
An event's final explanation is the end toward which it directs. That for the sake of which a thing is what it is. For a seed, it might be an adult plant. For a sailboat, it might be sailing. For a ball at the top of a ramp, it might be coming to rest at the bottom. For a person's action, it is the goal."
Formula	"In science, a formula is a concise way of expressing information symbolically as in a mathematical or chemical formula. The informal use of the term formula in science refers to the general construct of a relationship between given quantities. The plural of formula can be spelled either as formulas or formulae (from the original Latin).
In mathematics, a formula is an entity constructed using the symbols and formation rules of a given logical language. For example, determining the volume of a sphere requires a significant amount of integral calculus or its geometrical analogue, the method of exhaustion; but, having done this once in terms of some parameter (the radius for example), mathematicians have produced a formula to describe the volume: This particular formula is:
V = 4/3 π r3
Having obtained this result, and knowing the radius of any sphere in question, we can quickly and easily determine its volume. Note that the volume V and the radius r are expressed as single letters instead of words or phrases. This convention, while less important in a relatively simple formula, means that mathematicians can more quickly manipulate larger and more complex formulas. Mathematical formulas are often algebraic, closed form, and/or analytical.
In modern chemistry, a chemical formula is a way of expressing information about the proportions of atoms that constitute a particular chemical compound, using a single line of chemical element symbols, numbers, and sometimes other symbols, such as parentheses, brackets, and plus (+) and minus (−) signs. For example, H2O is the chemical formula for water, specifying that each molecule consists of two hydrogen (H) atoms and one oxygen (O) atom. Similarly, O−
3 denotes an ozone molecule consisting of three oxygen atoms and having a net negative charge.
In a general context, formulas are applied to provide a mathematical solution for real world problems. Some may be general: F = ma, which is one expression of Newton's second law, is applicable to a wide range of physical situations. Other formulas may be specially created to solve a particular problem; for example, using the equation of a sine curve to model the movement of the tides in a bay. In all cases, however, formulas form the basis for calculations.
Expressions are distinct from formulas in that they cannot contain an equals sign (=). Whereas formulas are comparable to sentences, expressions are more like phrases."
Four causes	"""Four causes"" refers to an influential principle in Aristotelian thought whereby explanations of change or movement are classified into four fundamental types of answer to the question ""why?"" Aristotle wrote that ""we do not have knowledge of a thing until we have grasped its why, that is to say, its explanation."" While there are cases where classifying an explanation is difficult, or in which classes of explanation might merge, Aristotle was convinced that his four classes of explanation provided an analytical scheme of general applicability.
Aitia, from Greek αἰτία was the word that Aristotle used to refer to the concept of explanation. Traditionally in academic philosophy it has been translated as cause, but this tradition uses the word 'cause' in a peculiar way that is obsolete, or highly specialized and technical in philosophy, not in its most usual current ordinary language usage. The translation of Aristotle's αἰτία that is nearest to current ordinary language is 'explanation'.
Aristotle held that there were four kinds of answers to 'why' questions (in Physics II, 3, and Metaphysics V, 2): In this article, the peculiar philosophical usage of the word 'cause' will be exercised, for tradition's sake, but the reader should not be misled by confusing this peculiar usage with current ordinary language.
A change or movement's material explanation is the aspect of the change or movement which is determined by the material that composes the moving or changing things. For a table, that might be wood; for a statue, that might be bronze or marble.
A change or movement's formal explanation is a change or movement caused by the arrangement, shape or appearance of the thing changing or moving. Aristotle says for example that the ratio 2:1, and number in general, is the explanation of the octave.
A change or movement's efficient or moving explanation consists of things apart from the thing being changed or moved, which interact so as to be an agency within the change or movement. For example, the efficient explanation of a table is a carpenter, or a person working as one, and according to Aristotle the efficient explanation of a boy is a father.
An event's final explanation is the end toward which it directs. That for the sake of which a thing is what it is. For a seed, it might be an adult plant. For a sailboat, it might be sailing. For a ball at the top of a ramp, it might be coming to rest at the bottom. For a person's action, it is the goal."
Fringe science	"There are differing definitions of fringe science. Fringe science may be valid science which is not considered mainstream. Alternatively, it may be either a questionable scientific approach to a field of study or an approach whose status as scientific is dubious or widely questioned. In any case, it is an inquiry in an established field of study which departs significantly from the mainstream theory in that field.
Mainstream scientists typically regard fringe science as highly speculative or even as actually refuted. Fringe science theories are often advanced by persons who have no traditional academic science background, or by researchers outside the mainstream discipline. The general public has difficulty distinguishing between science and its imitators, and in some cases a ""yearning to believe or a generalized suspicion of experts is a very potent incentive to accepting pseudoscientific claims"".
The term ""fringe science"" covers everything from novel hypotheses which can be tested by means of the scientific method to wild ad hoc hypotheses and mumbo jumbo. This has resulted in a tendency to dismiss all fringe science as the domain of pseudoscientists, hobbyists, and cranks.
Other terms used for the questionable areas of fringe science are pathological science, voodoo science, and cargo cult science. Junk science is a term typically used in the political arena to describe ideas considered to be dubious or fraudulent.
A concept that was once accepted by the mainstream scientific community may become fringe science because of a later evaluation of previous research. For example, focal infection theory, which held that focal infections of the tonsils or teeth are a primary cause of systemic disease, was once considered to be medical fact. It has since been dismissed because of lack of evidence.
Some theories that were once rejected as fringe science, but were eventually accepted as mainstream science, are:
continental drift
the existence of Troy
heliocentrism
Norse colonization of the Americas
the Big Bang theory"
Functional magnetic resonance imaging	"Functional magnetic resonance imaging or functional MRI (fMRI) is a functional neuroimaging procedure using MRI technology that measures brain activity by detecting changes associated with blood flow. This technique relies on the fact that cerebral blood flow and neuronal activation are coupled. When an area of the brain is in use, blood flow to that region also increases.
The primary form of fMRI uses the blood-oxygen-level dependent (BOLD) contrast, discovered by Seiji Ogawa. This is a type of specialized brain and body scan used to map neural activity in the brain or spinal cord of humans or other animals by imaging the change in blood flow (hemodynamic response) related to energy use by brain cells. Since the early 1990s, fMRI has come to dominate brain mapping research because it does not require people to undergo shots, surgery, or to ingest substances, or be exposed to ionising radiation, etc.
Other methods of obtaining contrast are arterial spin labeling and diffusion MRI. The latter procedure is similar to MRI but uses the change in magnetization between oxygen-rich and oxygen-poor blood as its basic measure. This measure is frequently corrupted by noise from various sources and hence statistical procedures are used to extract the underlying signal. The resulting brain activation can be presented graphically by color-coding the strength of activation across the brain or the specific region studied. The technique can localize activity to within millimeters but, using standard techniques, no better than within a window of a few seconds.
fMRI is used both in the research world, and to a lesser extent, in the clinical world. It can also be combined and complemented with other measures of brain physiology such as EEG and NIRS. Newer methods which improve both spatial and time resolution are being researched, and these largely use biomarkers other than the BOLD signal. Some companies have developed commercial products such as lie detectors based on fMRI techniques, but the research is not believed to be ripe enough for widespread commercialization."
Funding of science	"Research funding is a term generally covering any funding for scientific research, in the areas of both ""hard"" science and technology and social science. The term often connotes funding obtained through a competitive process, in which potential research projects are evaluated and only the most promising receive funding. Such processes, which are run by government, corporations or foundations, allocate scarce funds.
Most research funding comes from two major sources, corporations (through research and development departments) and government (primarily carried out through universities and specialized government agencies; often known as research councils). Some small amounts of scientific research are carried out (or funded) by charitable foundations, especially in relation to developing cures for diseases such as cancer, malaria and AIDS.
According to OECD, around two-thirds of research and development in scientific and technical fields is carried out by industries, and 20% and 10% respectively by universities and government. Comparatively, in countries with less GDP, such as Portugal and Mexico the industry contribution is significantly lower. The US government spends more than other countries on military R&D, although the proportion has fallen from around 30% in the 1980s to under 20. Government funding for medical research amounts to approximately 36% in the U.S. The government funding proportion in certain industries is higher, and it dominates research in social science and humanities. Similarly, with some exceptions (e.g. biotechnology) government provides the bulk of the funds for basic scientific research. In commercial research and development, all but the most research-oriented corporations focus more heavily on near-term commercialization possibilities rather than ""blue-sky"" ideas or technologies (such as nuclear fusion)."
Galen	"Aelius Galenus or Claudius Galenus (/ɡəˈliːnəs/; Greek: Κλαύδιος Γαληνός; September 129 AD – c. 200/c. 216), often Anglicized as Galen and better known as Galen of Pergamon (/ˈɡeɪlən/), was a prominent Greek physician, surgeon and philosopher in the Roman empire. Arguably the most accomplished of all medical researchers of antiquity, Galen influenced the development of various scientific disciplines, including anatomy, physiology, pathology, pharmacology, and neurology, as well as philosophy and logic.
The son of Aelius Nicon, a wealthy architect with scholarly interests, Galen received a comprehensive education that prepared him for a successful career as a physician and philosopher. Born in Pergamon (present-day Bergama, Turkey), Galen traveled extensively, exposing himself to a wide variety of medical theories and discoveries before settling in Rome, where he served prominent members of Roman society and eventually was given the position of personal physician to several emperors.
Galen's understanding of anatomy and medicine was principally influenced by the then-current theory of humorism (also known as the four humors - black bile, yellow bile, blood, and phlegm), as advanced by ancient Greek physicians such as Hippocrates. His theories dominated and influenced Western medical science for more than 1,300 years. His anatomical reports, based mainly on dissection of monkeys, especially the Barbary macaque, and pigs, remained uncontested until 1543, when printed descriptions and illustrations of human dissections were published in the seminal work De humani corporis fabrica by Andreas Vesalius where Galen's physiological theory was accommodated to these new observations. Galen's theory of the physiology of the circulatory system endured until 1628, when William Harvey published his treatise entitled De motu cordis, in which he established that blood circulates, with the heart acting as a pump. Medical students continued to study Galen's writings until well into the 19th century. Galen conducted many nerve ligation experiments that supported the theory, which is still accepted today, that the brain controls all the motions of the muscles by means of the cranial and peripheral nervous systems.
Galen saw himself as both a physician and a philosopher, as he wrote in his treatise entitled That the Best Physician is also a Philosopher. Galen was very interested in the debate between the rationalist and empiricist medical sects, and his use of direct observation, dissection and vivisection represents a complex middle ground between the extremes of those two viewpoints. Many of his works have been preserved and/or translated from the original Greek, although many were destroyed and some credited to him are believed to be spurious. Although there is some debate over the date of his death, he was no younger than seventy when he died.
In medieval Europe, Galen's writings on anatomy became the mainstay of the medieval physician's university curriculum; but they suffered greatly from stasis and intellectual stagnation. Some of Galen's ideas were incorrect: he did not dissect a human body nor did the medieval lecturers.
Galen's original Greek texts gained renewed prominence during the early modern period. In the 1530s, Belgian anatomist and physician Andreas Vesalius took on a project to translate many of Galen's Greek texts into Latin. Vesalius's most famous work, De humani corporis fabrica, was greatly influenced by Galenic writing and form."
General relativity	"General relativity (GR, also known as the general theory of relativity or GTR) is the geometric theory of gravitation published by Albert Einstein in 1915 and the current description of gravitation in modern physics. General relativity generalizes special relativity and Newton's law of universal gravitation, providing a unified description of gravity as a geometric property of space and time, or spacetime. In particular, the curvature of spacetime is directly related to the energy and momentum of whatever matter and radiation are present. The relation is specified by the Einstein field equations, a system of partial differential equations.
Some predictions of general relativity differ significantly from those of classical physics, especially concerning the passage of time, the geometry of space, the motion of bodies in free fall, and the propagation of light. Examples of such differences include gravitational time dilation, gravitational lensing, the gravitational redshift of light, and the gravitational time delay. The predictions of general relativity have been confirmed in all observations and experiments to date. Although general relativity is not the only relativistic theory of gravity, it is the simplest theory that is consistent with experimental data. However, unanswered questions remain, the most fundamental being how general relativity can be reconciled with the laws of quantum physics to produce a complete and self-consistent theory of quantum gravity.
Einstein's theory has important astrophysical implications. For example, it implies the existence of black holes—regions of space in which space and time are distorted in such a way that nothing, not even light, can escape—as an end-state for massive stars. There is ample evidence that the intense radiation emitted by certain kinds of astronomical objects is due to black holes; for example, microquasars and active galactic nuclei result from the presence of stellar black holes and black holes of a much more massive type, respectively. The bending of light by gravity can lead to the phenomenon of gravitational lensing, in which multiple images of the same distant astronomical object are visible in the sky. General relativity also predicts the existence of gravitational waves, which have since been observed directly by physics collaboration LIGO. In addition, general relativity is the basis of current cosmological models of a consistently expanding universe."
Genetics	"Genetics is the study of genes, genetic variation, and heredity in living organisms. It is generally considered a field of biology, but it intersects frequently with many of the life sciences and is strongly linked with the study of information systems.
The modern science of genetics, seeking to understand this process, began with the work of Imre Festetics, a Hungarian noble, who lived in Brno (Brünn) before Gregor Mendel. Imre Festetics was the first who used the word ""genetics"", more than 80 years earlier than William Bateson. He described several rules of genetic inheritance in his work The genetic law of the Nature (Die genetische Gesätze der Natur, 1819). His second law is the same as what Mendel published. In his third law, he developed the basic principles of mutation (he can be considered a forerunner of Hugo de Vries.
The father of genetics is Gregor Mendel, a late 19th-century scientist and Augustinian friar. Mendel studied 'trait inheritance', patterns in the way traits were handed down from parents to offspring. He observed that organisms (pea plants) inherit traits by way of discrete ""units of inheritance"". This term, still used today, is a somewhat ambiguous definition of what is referred to as a gene.
Trait inheritance and molecular inheritance mechanisms of genes are still primary principles of genetics in the 21st century, but modern genetics has expanded beyond inheritance to studying the function and behavior of genes. Gene structure and function, variation, and distribution are studied within the context of the cell, the organism (e.g. dominance) and within the context of a population. Genetics has given rise to a number of sub-fields including epigenetics and population genetics. Organisms studied within the broad field span the domain of life, including bacteria, plants, animals, and humans.
Genetic processes work in combination with an organism's environment and experiences to influence development and behavior, often referred to as nature versus nurture. The intra- or extra-cellular environment of a cell or organism may switch gene transcription on or off. A classic example is two seeds of genetically identical corn, one placed in a temperate climate and one in an arid climate. While the average height of the two corn stalks may be genetically determined to be equal, the one in the arid climate only grows to half the height of the one in the temperate climate due to lack of water and nutrients in its environment."
Geocentric model	"In astronomy, the geocentric model (also known as geocentrism, or the Ptolemaic system) is a superseded description of the universe, where the Earth is at the center of all the celestial bodies. This model served as the predominant cosmological system in many ancient civilizations such as ancient Greece including the noteworthy systems of Aristotle (see Aristotelian physics) and Ptolemy. As such, they believed that the Sun, Moon, stars, and naked eye planets circled Earth.
Two commonly made observations supported the idea that Earth was the center of the Universe. The stars, the sun, and planets appear to revolve around Earth each day, making Earth the center of that system. The stars were thought to be on a celestial sphere, with the earth at its center, that rotated each day, using a line through the north and south pole as an axis. The stars closest to the equator appeared to rise and fall the greatest distance, but each star circled back to its rising point each day. The second observation supporting the geocentric model was that the Earth does not seem to move from the perspective of an Earth-bound observer, and that it is solid, stable, and unmoving.
Ancient Greek, ancient Roman and medieval philosophers usually combined the geocentric model with a spherical Earth. It is not the same as the older flat Earth model implied in some mythology. The ancient Jewish Babylonian uranography pictured a flat Earth with a dome-shaped rigid canopy named firmament placed over it. (רקיע- rāqîa').
However, the ancient Greeks believed that the motions of the planets were circular and not elliptical, a view that was not challenged in Western culture until the 17th century through the synthesis of theories by Copernicus and Kepler.
The astronomical predictions of Ptolemy's geocentric model were used to prepare astrological and astronomical charts for over 1500 years. The geocentric model held sway into the early modern age, but from the late 16th century onward was gradually superseded by the heliocentric model of Copernicus, Galileo and Kepler. There was much resistance to the transition between these two theories. Christian theologians were reluctant to reject a theory that agreed with Bible passages (e.g. ""Sun, stand you still upon Gibeon"", Joshua 10:12 – King James 2000 Bible). Others felt a new, unknown theory could not subvert an accepted consensus for geocentrism."
Geometry	"Geometry (from the Ancient Greek: γεωμετρία; geo- ""earth"", -metron ""measurement"") is a branch of mathematics concerned with questions of shape, size, relative position of figures, and the properties of space. A mathematician who works in the field of geometry is called a geometer. Geometry arose independently in a number of early cultures as a body of practical knowledge concerning lengths, areas, and volumes, with elements of formal mathematical science emerging in the West as early as Thales (6th century BC). By the 3rd century BC, geometry was put into an axiomatic form by Euclid, whose treatment—Euclidean geometry—set a standard for many centuries to follow. Archimedes developed ingenious techniques for calculating areas and volumes, in many ways anticipating modern integral calculus. The field of astronomy, especially as it relates to mapping the positions of stars and planets on the celestial sphere and describing the relationship between movements of celestial bodies, served as an important source of geometric problems during the next one and a half millennia. In the classical world, both geometry and astronomy were considered to be part of the Quadrivium, a subset of the seven liberal arts considered essential for a free citizen to master.
The introduction of coordinates by René Descartes and the concurrent developments of algebra marked a new stage for geometry, since geometric figures such as plane curves could now be represented analytically in the form of functions and equations. This played a key role in the emergence of infinitesimal calculus in the 17th century. Furthermore, the theory of perspective showed that there is more to geometry than just the metric properties of figures: perspective is the origin of projective geometry. The subject of geometry was further enriched by the study of the intrinsic structure of geometric objects that originated with Euler and Gauss and led to the creation of topology and differential geometry.
In Euclid's time, there was no clear distinction between physical and geometrical space. Since the 19th-century discovery of non-Euclidean geometry, the concept of space has undergone a radical transformation and raised the question of which geometrical space best fits physical space. With the rise of formal mathematics in the 20th century, 'space' (whether 'point', 'line', or 'plane') lost its intuitive contents, so today one has to distinguish between physical space, geometrical spaces (in which 'space', 'point' etc. still have their intuitive meanings) and abstract spaces. Contemporary geometry considers manifolds, spaces that are considerably more abstract than the familiar Euclidean space, which they only approximately resemble at small scales. These spaces may be endowed with additional structure which allow one to speak about length. Modern geometry has many ties to physics as is exemplified by the links between pseudo-Riemannian geometry and general relativity. One of the youngest physical theories, string theory, is also very geometric in flavour.
While the visual nature of geometry makes it initially more accessible than other mathematical areas such as algebra or number theory, geometric language is also used in contexts far removed from its traditional, Euclidean provenance (for example, in fractal geometry and algebraic geometry)."
Geophysics	"Geophysics /dʒiːoʊfɪzɪks/ is a subject of natural science concerned with the physical processes and physical properties of the Earth and its surrounding space environment, and the use of quantitative methods for their analysis. The term geophysics sometimes refers only to the geological applications: Earth's shape; its gravitational and magnetic fields; its internal structure and composition; its dynamics and their surface expression in plate tectonics, the generation of magmas, volcanism and rock formation. However, modern geophysics organizations use a broader definition that includes the water cycle including snow and ice; fluid dynamics of the oceans and the atmosphere; electricity and magnetism in the ionosphere and magnetosphere and solar-terrestrial relations; and analogous problems associated with the Moon and other planets.
Although geophysics was only recognized as a separate discipline in the 19th century, its origins date back to ancient times. The first magnetic compasses were made from lodestones, while more modern magnetic compasses played an important role in the history of navigation. The first seismic instrument was built in 132 BC. Isaac Newton applied his theory of mechanics to the tides and the precession of the equinox; and instruments were developed to measure the Earth's shape, density and gravity field, as well as the components of the water cycle. In the 20th century, geophysical methods were developed for remote exploration of the solid Earth and the ocean, and geophysics played an essential role in the development of the theory of plate tectonics.
Geophysics is applied to societal needs, such as mineral resources, mitigation of natural hazards and environmental protection. Geophysical survey data are used to analyze potential petroleum reservoirs and mineral deposits, locate groundwater, find archaeological relics, determine the thickness of glaciers and soils, and assess sites for environmental remediation."
Gerontology	"Gerontology (from the Greek γέρων, geron, ""old man"" and -λογία, -logia, ""study of""; coined by Ilya Ilyich Mechnikov in 1903) is the study of the social, psychological, cognitive, and biological aspects of aging. It is distinguished from geriatrics, which is the branch of medicine that specializes in the treatment of existing disease in older adults. Gerontologists include researchers and practitioners in the fields of biology, nursing, medicine, criminology, dentistry, social work, physical and occupational therapy, psychology, psychiatry, sociology, economics, political science, architecture, geography, pharmacy, public health, housing, and anthropology.
Gerontology encompasses the following:
studying physical, mental, and social changes in people as they age
investigating the biological aging process itself (biogerontology)
investigating the social and psychosocial impacts of aging (sociogerontology)
investigating the psychological effects on aging (psychogerontology)
investigating the interface of biological aging with aging-associated disease (geroscience)
investigating the effects of an ageing population on society
applying this knowledge to policies and programs, including the macroscopic (for example, government planning) and microscopic (for example, running a nursing home) perspectives.
The multidisciplinary nature of gerontology means that there are a number of subfields, as well as associated fields such as psychology and sociology that overlap with gerontology. Gerontologists view aging in terms of four distinct processes: chronological aging, biological aging, psychological aging, and social aging. Chronological aging is the definition of aging based on a person's years lived from birth. Biological aging refers to the physical changes that reduce the efficiency of organ systems. Psychological aging includes the changes that occur in sensory and perceptual processes, cognitive abilities, adaptive capacity, and personality. Social aging refers to an individual's changing roles and relationships with family, friends, and other informal supports, productive roles and within organizations."
Gottfried Leibniz	"Gottfried Wilhelm (von) Leibniz (/ˈlaɪbnɪts/; German: [ˈɡɔtfʁiːt ˈvɪlhɛlm fɔn ˈlaɪbnɪts] or [ˈlaɪpnɪts]; French: Godefroi Guillaume Leibnitz; July 1, 1646 – November 14, 1716) was a German polymath and philosopher who occupies a prominent place in the history of mathematics and the history of philosophy. Scholars including Bertrand Russell believe Leibniz developed calculus independently of Isaac Newton, and Leibniz's notation has been widely used ever since it was published. It was only in the 20th century that his Law of Continuity and Transcendental Law of Homogeneity found mathematical implementation (by means of non-standard analysis). He became one of the most prolific inventors in the field of mechanical calculators. While working on adding automatic multiplication and division to Pascal's calculator, he was the first to describe a pinwheel calculator in 1685 and invented the Leibniz wheel, used in the arithmometer, the first mass-produced mechanical calculator. He also refined the binary number system, which is the foundation of virtually all digital computers.
In philosophy, Leibniz is most noted for his optimism, i.e. his conclusion that our Universe is, in a restricted sense, the best possible one that God could have created, an idea that was often lampooned by others such as Voltaire. Leibniz, along with René Descartes and Baruch Spinoza, was one of the three great 17th-century advocates of rationalism. The work of Leibniz anticipated modern logic and analytic philosophy, but his philosophy also looks back to the scholastic tradition, in which conclusions are produced by applying reason of first principles or prior definitions rather than to empirical evidence.
Leibniz made major contributions to physics and technology, and anticipated notions that surfaced much later in philosophy, probability theory, biology, medicine, geology, psychology, linguistics, and computer science. He wrote works on philosophy, politics, law, ethics, theology, history, and philology. Leibniz's contributions to this vast array of subjects were scattered in various learned journals, in tens of thousands of letters, and in unpublished manuscripts. He wrote in several languages, but primarily in Latin, French, and German. There is no complete gathering of the writings of Leibniz."
Gravity	"Gravity or gravitation is a natural phenomenon by which all things with energy are brought toward (or gravitate toward) one another, including stars, planets, galaxies and even light and sub-atomic particles. Gravity is responsible for many of the structures in the Universe, by creating spheres of hydrogen — where hydrogen fuses under pressure to form stars — and grouping them into galaxies. On Earth, gravity gives weight to physical objects and causes the tides. Gravity has an infinite range, although its effects become increasingly weaker on farther objects.
Gravity is most accurately described by the general theory of relativity (proposed by Albert Einstein in 1915) which describes gravity not as a force but as a consequence of the curvature of spacetime caused by the uneven distribution of mass/energy; and resulting in gravitational time dilation, where time lapses more slowly in lower (stronger) gravitational potential. However, for most applications, gravity is well approximated by Newton's law of universal gravitation, which postulates that gravity causes a force where two bodies of mass are directly drawn (or 'attracted') to each other according to a mathematical relationship, where the attractive force is proportional to the product of their masses and inversely proportional to the square of the distance between them. This is considered to occur over an infinite range, such that all bodies (with mass) in the universe are drawn to each other no matter how far they are apart.
Gravity is the weakest of the four fundamental interactions of nature. The gravitational attraction is approximately 10−38 times the strength of the strong force (i.e. gravity is 38 orders of magnitude weaker), 10−36 times the strength of the electromagnetic force, and 10−29 times the strength of the weak force. As a consequence, gravity has a negligible influence on the behavior of sub-atomic particles, and plays no role in determining the internal properties of everyday matter (but see quantum gravity). On the other hand, gravity is the dominant interaction at the macroscopic scale, and is the cause of the formation, shape, and trajectory (orbit) of astronomical bodies. It is responsible for various phenomena observed on Earth and throughout the universe; for example, it causes the Earth and the other planets to orbit the Sun, the Moon to orbit the Earth, the formation of tides, and the formation and evolution of galaxies, stars and the Solar System.
In pursuit of a theory of everything, the merging of general relativity and quantum mechanics (or quantum field theory) into a more general theory of quantum gravity has become an area of research."
Gross domestic product	"Gross domestic product (GDP) is a monetary measure of the value of all final goods and services produced in a period (quarterly or yearly). Nominal GDP estimates are commonly used to determine the economic performance of a whole country or region, and to make international comparisons. Nominal GDP, however, does not reflect differences in the cost of living and the inflation rates of the countries; therefore using a GDP PPP per capita basis is arguably more useful when comparing differences in living standards between nations.
GDP is not a complete measure of economic activity. It accounts for final output or value added at each stage of production, but not total output or total sales along the entire production process. It deliberately leaves out business-to-business (B2B) transactions in the early and intermediate stages of production, as well as sales of used goods. In the United States, the Bureau of Economic Analysis (BEA) has introduced a new quarterly statistic called gross output (GO), a broader measure that attempts to add up total sales or revenues at all stages of production. Mark Skousen was the first economist to advocate GO as an important macroeconomic tool. Other countries are following suit, such as the United Kingdom, which now produces an annual statistic called Total Output.
GDP attempts to measure the “use” economy, i.e., the value of finished goods and services ready to be used by consumers, business and government. GDP is similar to the “bottom line” (earnings) of an accounting statement, which determined the “value added” or the value of final use. GO is an estimate of the “make” economy, i.e., the monetary value of sales at all stages of production. Thus, GO is similar to the “top line” (revenues or sales) of an accounting statement. GDP and GO are not mutually exclusive, but are complementary ways of examining the state of an economy.
As Dale Jorgenson, Steve Landefeld, and William Nordhaus conclude in “Gross output [GO] is the natural measure of the production sector, while net output [GDP] is appropriate as a measure of welfare. Both are required in a complete system of accounts.” The largest GDP's by continent are: the United States in the Americas, Germany in Europe, Nigeria in Africa, China in Asia and Australia in Oceania."
Hellenistic civilization	"The Hellenistic period covers the period of ancient Greek (Hellenic) history and Mediterranean history between the death of Alexander the Great in 323 BC and the emergence of the Roman Empire as signified by the Battle of Actium in 31 BC and the subsequent conquest of Ptolemaic Egypt the following year. At this time, Greek cultural influence and power was at its peak in Europe, Africa and Asia, experiencing prosperity and progress in the arts, exploration, literature, theatre, architecture, music, mathematics, philosophy, and science. For example, competitive public games took place, ideas in biology, and popular entertainment in theaters. It is often considered a period of transition, sometimes even of decadence or degeneration, compared to the enlightenment of the Greek Classical era. The Hellenistic period saw the rise of New Comedy, Alexandrian poetry, the Septuagint and the philosophies of Stoicism and Epicureanism. Greek Science was advanced by the works of the mathematician Euclid and the polymath Archimedes. The religious sphere expanded to include new gods such as the Greco-Egyptian Serapis, eastern deities such as Attis and Cybele and the Greek adoption of Buddhism.

After Alexander the Great's ventures in the Persian Empire, Hellenistic kingdoms were established throughout south-west Asia (Seleucid Empire, Kingdom of Pergamon), north-east Africa (Ptolemaic Kingdom) and South Asia (Greco-Bactrian Kingdom, Indo-Greek Kingdom). This resulted in the export of Greek culture and language to these new realms through Greco-Macedonian colonization, spanning as far as modern-day Pakistan. Equally, however, these new kingdoms were influenced by the indigenous cultures, adopting local practices where beneficial, necessary, or convenient. Hellenistic culture thus represents a fusion of the Ancient Greek world with that of the Near East, Middle East, and Southwest Asia, and a departure from earlier Greek attitudes towards ""barbarian"" cultures. The Hellenistic period was characterized by a new wave of Greek colonization (as distinguished from that occurring in the 8th–6th centuries BC) which established Greek cities and kingdoms in Asia and Africa. Those new cities were composed of Greek colonists who came from different parts of the Greek world, and not, as before, from a specific ""mother city"". The main cultural centers expanded from mainland Greece to Pergamon, Rhodes, and new Greek colonies such as Seleucia, Antioch, Alexandria and Ai-Khanoum. This mixture of Greek-speakers gave birth to a common Attic-based dialect, known as Koine Greek, which became the lingua franca through the Hellenistic world.
Scholars and historians are divided as to what event signals the end of the Hellenistic era. The Hellenistic period may be seen to end either with the final conquest of the Greek heartlands by Rome in 146 BC following the Achean War, with the final defeat of the Ptolemaic Kingdom at the Battle of Actium in 31 BC, or even the move by Roman emperor Constantine the Great of the capital of the Roman Empire to Constantinople in 330 AD. ""Hellenistic"" is distinguished from ""Hellenic"" in that the first encompasses the entire sphere of direct ancient Greek influence, while the latter refers to Greece itself."
Higgs boson	"The Higgs boson is an elementary particle in the Standard Model of particle physics. It is the quantum excitation of the Higgs field—a fundamental field of crucial importance to particle physics theory, first suspected to exist in the 1960s, which, unlike other known fields such as the electromagnetic field, takes a non-zero constant value almost everywhere. The question of the Higgs field's existence has been the last unverified part of the Standard Model of particle physics and, according to some, ""the central problem in particle physics"".
The presence of this field, now believed to be confirmed, explains why some fundamental particles have mass when, based on the symmetries controlling their interactions, they should be massless. The existence of the Higgs field would also resolve several other long-standing puzzles, such as the reason for the weak force's extremely short range.
Although it is hypothesized that the Higgs field permeates the entire Universe, evidence for its existence has been very difficult to obtain. In principle, the Higgs field can be detected through its excitations, manifest as Higgs particles, but these are extremely difficult to produce and detect. The importance of this fundamental question led to a 40 year search, and the construction of one of the world's most expensive and complex experimental facilities to date, CERN's Large Hadron Collider, in an attempt to create Higgs bosons and other particles for observation and study. On 4 July 2012, the discovery of a new particle with a mass between 125 and 7002127000000000000♠127 GeV/c2 was announced; physicists suspected that it was the Higgs boson. Since then, the particle has been shown to behave, interact, and decay in many of the ways predicted by the Standard Model. It was also tentatively confirmed to have even parity and zero spin, two fundamental attributes of a Higgs boson. This appears to be the first elementary scalar particle discovered in nature. More studies are needed to verify that the discovered particle has properties matching those predicted for the Higgs boson by the Standard Model, or whether, as predicted by some theories, multiple Higgs bosons exist.
The Higgs boson is named after Peter Higgs, one of six physicists who, in 1964, proposed the mechanism that suggested the existence of such a particle. On December 10, 2013, two of them, Peter Higgs and François Englert, were awarded the Nobel Prize in Physics for their work and prediction (Englert's co-researcher Robert Brout had died in 2011 and the Nobel Prize is not ordinarily given posthumously). Although Higgs's name has come to be associated with this theory, several researchers between about 1960 and 1972 independently developed different parts of it. In mainstream media the Higgs boson has often been called the ""God particle"", from a 1993 book on the topic; the nickname is strongly disliked by many physicists, including Higgs, who regard it as sensationalistic.
In the Standard Model, the Higgs particle is a boson with no spin, electric charge, or colour charge. It is also very unstable, decaying into other particles almost immediately. It is a quantum excitation of one of the four components of the Higgs field. The latter constitutes a scalar field, with two neutral and two electrically charged components that form a complex doublet of the weak isospin SU(2) symmetry. The Higgs field is tachyonic (this does not refer to faster-than-light speeds, it means that symmetry-breaking through condensation of a particle must occur under certain conditions), and has a ""Mexican hat"" shaped potential with nonzero strength everywhere (including otherwise empty space), which in its vacuum state breaks the weak isospin symmetry of the electroweak interaction. When this happens, three components of the Higgs field are ""absorbed"" by the SU(2) and U(1) gauge bosons (the ""Higgs mechanism"") to become the longitudinal components of the now-massive W and Z bosons of the weak force. The remaining electrically neutral component separately couples to other particles known as fermions (via Yukawa couplings), causing these to acquire mass as well. Some versions of the theory predict more than one kind of Higgs fields and bosons. Alternative ""Higgsless"" models may have been considered if the Higgs boson was not discovered.
On 15 December 2015, two teams of physicists, working independently at CERN, reported preliminary hints of a possible new subatomic particle (more specifically, the ATLAS and CMS experiments, using 13 TeV proton collision data, showed a moderate excess around 750 GeV, in the two-photon spectrum): if real, the particle could be either a heavier version of a Higgs boson or a graviton."
History	"History (from Greek ἱστορία, historia, meaning ""inquiry, knowledge acquired by investigation"") is the study of the past, particularly how it relates to humans. It is an umbrella term that relates to past events as well as the memory, discovery, collection, organization, presentation, and interpretation of information about these events. Scholars who write about history are called historians. Events occurring prior to written record are considered prehistory.
History can also refer to the academic discipline which uses a narrative to examine and analyse a sequence of past events, and objectively determine the patterns of cause and effect that determine them. Historians sometimes debate the nature of history and its usefulness by discussing the study of the discipline as an end in itself and as a way of providing ""perspective"" on the problems of the present.
Stories common to a particular culture, but not supported by external sources (such as the tales surrounding King Arthur), are usually classified as cultural heritage or legends, because they do not show the ""disinterested investigation"" required of the discipline of history. Herodotus, a 5th-century BC Greek historian is considered within the Western tradition to be the ""father of history"", and, along with his contemporary Thucydides, helped form the foundations for the modern study of human history. Their works continue to be read today, and the gap between the culture-focused Herodotus and the military-focused Thucydides remains a point of contention or approach in modern historical writing. In Asia, a state chronicle, the Spring and Autumn Annals was known to be compiled from as early as 722 BC although only 2nd century BC texts survived.
Ancient influences have helped spawn variant interpretations of the nature of history which have evolved over the centuries and continue to change today. The modern study of history is wide-ranging, and includes the study of specific regions and the study of certain topical or thematical elements of historical investigation. Often history is taught as part of primary and secondary education, and the academic study of history is a major discipline in university studies."
History of science	"The history of science is the study of the development of science and scientific knowledge, including both the natural sciences and social sciences. (The history of the arts and humanities is termed as the history of scholarship.) Science is a body of empirical, theoretical, and practical knowledge about the natural world, produced by scientists who emphasize the observation, explanation, and prediction of real world phenomena. Historiography of science, in contrast, often draws on the historical methods of both intellectual history and social history.
The English word scientist is relatively recent—first coined by William Whewell in the 19th century. Previously, people investigating nature called themselves natural philosophers. While empirical investigations of the natural world have been described since classical antiquity (for example, by Thales, Aristotle, and others), and scientific methods have been employed since the Middle Ages (for example, by Ibn al-Haytham, and Roger Bacon), the dawn of modern science is often traced back to the early modern period and in particular to the scientific revolution that took place in 16th- and 17th-century Europe. Scientific methods are considered to be so fundamental to modern science that some consider earlier inquiries into nature to be pre-scientific. Traditionally, historians of science have defined science sufficiently broadly to include those inquiries.
From the 18th century through late 20th century, the history of science, especially of the physical and biological sciences, was often presented in a progressive narrative in which true theories replaced false beliefs. More recent historical interpretations, such as those of Thomas Kuhn, tend to portray the history of science in different terms, such as that of competing paradigms or conceptual systems in a wider matrix that includes intellectual, cultural, economic and political themes outside of science."
Human behavior	"Human behavior refers to the array of every physical action and observable emotion associated with individuals, as well as the human race as a whole. While specific traits of one's personality and temperament may be more consistent, other behaviors will change as one moves from birth through adulthood. In addition to being dictated by age and genetics, behavior, driven in part by thoughts and feelings, is an insight into individual psyche, revealing among other things attitudes and values. Social behavior, a subset of human behavior, study the considerable influence of social interaction and culture. Additional influences include ethics, encircling, authority, rapport, hypnosis, persuasion and coercion.
The behavior of humans (and other organisms or even mechanisms) falls within a range with some behavior being common, some unusual, some acceptable, and some outside acceptable limits. In sociology, behavior in general includes actions having no meaning, being not directed at other people, and thus all basic human actions. Behavior in this general sense should not be mistaken with social behavior, which is a more advanced social action, specifically directed at other people. The acceptability of behavior depends heavily upon social norms and is regulated by various means of social control. Human behavior is studied by the specialized academic disciplines of psychiatry, psychology, social work, sociology, economics, and anthropology.
Human behavior is experienced throughout an individual’s entire lifetime. It includes the way they act based on different factors such as genetics, social norms, core faith, and attitude. Behavior is impacted by certain traits each individual has. The traits vary from person to person and can produce different actions or behavior from each person. Social norms also impact behavior. Due to the inherently conformist nature of human society in general, humans are pressured into following certain rules and displaying certain behaviors in society, which conditions the way people behave. Different behaviors are deemed to be either acceptable or unacceptable in different societies and cultures. Core faith can be perceived through the religion and philosophy of that individual. It shapes the way a person thinks and this in turn results in different human behaviors. Attitude can be defined as ""the degree to which the person has a favorable or unfavorable evaluation of the behavior in question."" One's attitude is essentially a reflection of the behavior he or she will portray in specific situations. Thus, human behavior is greatly influenced by the attitudes we use on a daily basis."
ICBM	"An intercontinental ballistic missile (ICBM) is a guided ballistic missile with a minimum range of 5,500 kilometres (3,400 mi) primarily designed for nuclear weapons delivery (delivering one or more thermonuclear warheads). Similarly, conventional, chemical and biological weapons can also be delivered with varying effectiveness, but have never been deployed on ICBMs. Most modern designs support multiple independently targetable reentry vehicles (MIRVs), allowing a single missile to carry several warheads, each of which can strike a different target.
Early ICBMs had limited precision (circular error probable) that allowed them to be used only against the largest targets such as cities. They were seen as a ""safe"" basing option, one that would keep the deterrent force close to home where it would be difficult to attack. Attacks against (especially hardened) military targets, if desired, still demanded the use of a more precise manned bomber. This is due to the inverse-square law, which predicts that the amount of energy dispersed from a single point release of energy (such as a thermonuclear blast) dissipates by the inverse of the square of distance from the single point of release. The result is that the power of a nuclear explosion to rupture hardened structures is greatly decreased by the distance from the impact point of the nuclear weapon. So a near-direct hit is generally necessary, as only diminishing returns are gained by increasing bomb yield.
Second- and third-generation designs (e.g. the LGM-118 Peacekeeper) dramatically improved accuracy to the point where even the smallest point targets can be successfully attacked.
ICBMs are differentiated by having greater range and speed than other ballistic missiles: intermediate-range ballistic missiles (IRBMs), medium-range ballistic missiles (MRBMs), short-range ballistic missiles (SRBMs) (these shorter-range ballistic missiles are known collectively as theatre ballistic missiles). There is no single, standardized definition of what ranges would be categorized as intercontinental, intermediate, medium, or short."
Ibn Sahl	"Ibn Sahl (Arabic: ابن سهل‎) (Abu Saʿd al-ʿAlaʾ ibn Sahl ) (Arabic: أبو سعد العلاء ابن سهل‎) (c. 940–1000) was a Muslim mathematician, physicist and optics engineer of the Islamic Golden Age associated with the Abbasid court of Baghdad. Ibn Sahl's 984 treatise On Burning Mirrors and Lenses sets out his understanding of how curved mirrors and lenses bend and focus light. Ibn Sahl is credited with first discovering the law of refraction, usually called Snell's law. He used the law of refraction to derive lens shapes that focus light with no geometric aberrations, known as anaclastic lenses.
In the reproduction of the figure from Ibn Sahl's manuscript, the critical part is the right-angled triangle. The inner hypotenuse shows the path of an incident ray and the outer hypotenuse shows an extension of the path of the refracted ray if the incident ray met a crystal whose face is vertical at the point where the two hypotenuses intersect. According to Roshdi Rashed, an author and historian of medieval science and mathematics, the ratio of the length of the smaller hypotenuse to the larger is the reciprocal of the refractive index of the crystal.
The lower part of the figure shows a representation of a plano-convex lens (at the right) and its principal axis (the intersecting horizontal line). The curvature of the convex part of the lens brings all rays parallel to the horizontal axis (and approaching the lens from the right) to a focal point on the axis at the left.
In the remaining parts of the treatise, Ibn Sahl dealt with parabolic mirrors, ellipsoidal mirrors, biconvex lenses, and techniques for drawing hyperbolic arcs.
Ibn Sahl's treatise was used by Ibn al-Haitham (965–1039), one of the greatest Arab scholars of optics. In modern times, Rashed found the text to have been dispersed in manuscripts in two different libraries, one in Teheran, and the other in Damascus. He reassembled the surviving portions, translated and published them."
Idealism	"In philosophy, idealism is the group of philosophies which assert that reality, or reality as we can know it, is fundamentally mental, mentally constructed, or otherwise immaterial. Epistemologically, idealism manifests as a skepticism about the possibility of knowing any mind-independent thing. In a sociological sense, idealism emphasizes how human ideas—especially beliefs and values—shape society. As an ontological doctrine, idealism goes further, asserting that all entities are composed of mind or spirit. Idealism thus rejects physicalist and dualist theories that fail to ascribe priority to the mind.
The earliest extant arguments that the world of experience is grounded in the mental derive from India and Greece. The Hindu idealists in India and the Greek Neoplatonists gave panentheistic arguments for an all-pervading consciousness as the ground or true nature of reality. In contrast, the Yogācāra school, which arose within Mahayana Buddhism in India in the 4th century CE, based its ""mind-only"" idealism to a greater extent on phenomenological analyses of personal experience. This turn toward the subjective anticipated empiricists such as George Berkeley, who revived idealism in 18th-century Europe by employing skeptical arguments against materialism.
Beginning with Immanuel Kant, German idealists such as G. W. F. Hegel, Johann Gottlieb Fichte, Friedrich Wilhelm Joseph Schelling, and Arthur Schopenhauer dominated 19th-century philosophy. This tradition, which emphasized the mental or ""ideal"" character of all phenomena, gave birth to idealistic and subjectivist schools ranging from British idealism to phenomenalism to existentialism. The historical influence of this branch of idealism remains central even to the schools that rejected its metaphysical assumptions, such as Marxism, pragmatism and positivism."
Index of branches of science	"
== A ==
Acarology – study of mites
Accidence – grammar book; science of inflections in grammar
Aceology – The science of remedies, or of therapeutics; iamatology.
Acology – study of medical remedies
Acoustics – science of sound
Adenology – study of glands
Aedoeology – science of generative organs
Aerobiology – study of airborne organisms
Aerodonetics – science or study of gliding
Aerodynamics – dynamics of gases; science of movement in a flow of air or gas
Aerolithology – study of aerolites; meteorites
Aerology – study of the atmosphere
Aeronautics – study of navigation through air or space
Aerophilately – collecting of air-mail stamps
Aerostatics – science of air pressure; art of ballooning
Agonistics – art and theory of prize-fighting
Agriology – the comparative study of primitive peoples
Agrobiology – study of plant nutrition; soil yields
Agrology – study of agricultural soils
Agronomics – study of productivity of land
Agrostology – science or study of grasses
Alethiology – study of truth
Algedonics – science of pleasure and pain
Algology – study of algae or the study of pain
Anaesthesiology – study of anaesthetics
Anaglyptics – art of carving in bas-relief
Anagraphy – art of constructing catalogues
Anatomy – study of the structure of the body
Andragogy &ndash
Anemology – study of wind.
Angiology – study of blood flow and lymphatic system
Anthropobiology – study of human biology
Anthropology – study of human cultures
Aphnology – science of wealth
Apiology – study of bees
Arachnology – study of spiders
Archaeology – study of human material remains
Archelogy – the study of first principles
Archology – science of the origins of government
Arctophily – study of teddy bears
Areology – study of Mars
Aretaics – the science of virtue
Aristology – the science or art of dining
Arthrology – study of joints
Astacology – the science of crayfish
Astheniology – study of diseases of weakening and aging
Astrogeology – study of extraterrestrial geology
Astrometeorology – study of effect of stars on climate
Astronomy – study of celestial bodies
Astrophysics – study of behaviour of interstellar matter
Astroseismology – study of star oscillations
Atmology – the science of aqueous vapour
Audiology – study of hearing
Autecology – study of ecology of one species
Autology – scientific study of oneself
Auxology – science of growth
Avionics – the science of electronic devices for aircraft
Axiology – the science of the ultimate nature of value"
Indigenous peoples	"Indigenous people, aboriginal people, or native people, are groups protected in international or national legislation as having a set of specific rights based on their linguistic and historical ties to a particular territory, their cultural and historical distinctiveness from other populations. The legislation is based on the conclusion that certain indigenous people are vulnerable to exploitation, marginalization, oppression, forced assimilation, and genocide by nation states formed from colonising populations or by politically dominant, different ethnic groups.
A special set of political rights in accordance with international law have been set forth by international organizations such as the United Nations, the International Labour Organization and the World Bank. The United Nations has issued a Declaration on the Rights of Indigenous Peoples to guide member-state national policies to collective rights of indigenous people—such as culture, identity, language, and access to employment, health, education, and natural resources. Estimates put the total population of indigenous peoples from 220 million to 350 million.
A defining characteristic for an indigenous group is that it has preserved traditional ways of living, such as present or historical reliance upon subsistence-based production (based on pastoral, horticultural and/or hunting and gathering techniques), and a predominantly non-urbanized society. Not all indigenous groups share these characteristics. Indigenous societies may be either settled in a given locale/region or exhibit a nomadic lifestyle across a large territory, but are generally historically associated with a specific territory on which they depend. Indigenous societies are found in every inhabited climate zone and continent of the world.
Indigenous peoples are increasingly faced with threats to their sovereignty, environment, and access to natural resources. Examples of this can be the deforestation of tropical rainforests where several of the native tribe's subsistence and their normal lifestyle are threatened. Assimilative colonial policies resulted in ongoing issues related to aboriginal child protection."
Inductivism	"Inductivism is the traditional model of scientific method attributed to Francis Bacon, who in 1620 vowed to subvert allegedly traditional thinking. In the Baconian model, one observes nature, proposes a modest law to generalize an observed pattern, confirms it by many observations, ventures a modestly broader law, and confirms that, too, by many more observations, while discarding disconfirmed laws. The laws grow ever broader but never much exceed careful, extensive observation. Thus freed from preconceptions, scientists gradually uncover nature's causal and material structure.
At 1740, David Hume found multiple obstacles to use of experience to infer causality. Hume noted the illogicality of enumerative induction—unrestricted generalization for particular instances to all instances, and stating a universal law—since humans observe sequence of sensory events, not cause and effect. Humans thus perceive neither logical nor natural necessity or impossibility among events. Later philosophers would select, highlight, and nickname Humean principles—Hume's fork, problem of induction, and Hume's law—although Hume accepted the empirical sciences as inevitably inductive, after all.
Alarmed by Hume's seemingly radical empiricism, Immanuel Kant identified its apparent opposite, rationalism, as favored by Descartes and by Spinoza. Seeking middle ground, Kant identified that the necessity bridging the world in itself to human experience is the mind, whose innate constants thus determine space, time, and substance and determine the correct scientific theory. Though protecting both metaphysics and Newtonian physics, Kant discarded scientific realism by restricting science to tracing appearances (phenomena), not unveiling reality (noumena). Kant's transcendental idealism launched German idealism—increasingly speculative metaphysics—while philosophers continued awkward confidence in empirical sciences as inductive.
Refining Baconian inductivism, John Stuart Mill posed his own five methods of discerning causality to describe the reasoning whereby scientists exceed mere inductivism. In the 1830s, opposing metaphysics, Auguste Comte explicated positivism, which, unlike Baconian model, emphasized predictions, confirming them, and laying scientific laws irrefutable by theology or metaphysics. Finding experience to show uniformity of nature and thereby justify enumerative induction, Mill accepted positivism: the first modern philosophy of science, which, simultaneously, was a political philosophy whereby only scientific knowledge was reliable knowledge.
Nearing 1840, William Whewell thought that the inductive sciences, so called, were not so simple, after all, and asked recognition of ""superinduction"", an explanatory scope or principle invented by the mind to unite facts, but not present in the facts. Mill would have none of hypotheticodeductivism, posed by Whewell as science's method, which Whewell believed to sometimes, via other considerations upon the evidence, render scientific theories of known metaphysical truth. By 1880, C S Peirce had clarified the basis of deductive inference and, although recognizing induction, proposed a third type of inference that Peirce called ""abduction"", now otherwise termed inference to the best explanation (IBE).
Since the 1920s, although opposing all metaphysical inference via scientific theories, the logical positivists sought to understand scientific theories as provably false or true as to strictly observations. Though accepting hypotheticodeductivism to originate theories, they launched verificationism whereby Rudolf Carnap tried but never succeeded to formalize an inductive logic whereby a universal law's truth with respect to observational evidence could be quantified as ""degree of confirmation"". Asserting a variant of hypotheticodeductivism termed falsificationism, Karl Popper from the 1930s onward was the first especially vocal critic of inductivism and verificationism as utterly flawed models of science. In 1963, Popper declared that enumerative induction is a myth. Two years later, Gilbert Harman claimed that enumerative induction is a masked effect of IBE.
Thomas Kuhn's 1962 book—explaining that periods of normal science as but a paradigm of science are each overturned by revolutionary science whose paradigm becomes the normal science anew—dissolved logical positivism's grip in the Anglosphere, and inductivism fell. Besides Popper and Kuhn, other postpostivist philosophers of science—including Paul Feyerabend, Imre Lakatos, and Larry Laudan—have all but unanimously rejected inductivism. Among them, those who have asserted scientific realism—that scientific theory can and does offer approximately true understanding of nature's unobservable aspects—have tended to claim that scientists develop approximately true theories about nature through IBE. And yet IBE, which, so far, cannot be trained, lacks particular rules of inference. By the 21st century's turn, inductivism's heir was Bayesianism."
Industrial engineering	"Industrial engineering is a branch of engineering which deals with the optimization of complex processes or systems. Industrial engineers work to eliminate waste of time, money, materials, man-hours, machine time, energy and other resources that do not generate value. According to the Institute of Industrial Engineers, they figure out how to do things better. They engineer processes and systems that improve quality and productivity.
Industrial engineers are the only engineering professionals trained specifically to be productivity and quality improvement specialists. As they work to improve processes on a technical point of view, but also to optimise the efficiency and profitability of businesses, many practitioners say that an industrial engineering education offers the best of both worlds: an education in both engineering and business.
Industrial engineering is concerned with the development, improvement, and implementation of integrated systems of people, money, knowledge, information, equipment, energy, materials, analysis and synthesis, as well as the mathematical, physical and social sciences together with the principles and methods of engineering design to specify, predict, and evaluate the results to be obtained from such systems or processes. While industrial engineering is a traditional and longstanding engineering discipline subject to (and eligible for) professional engineering licensure in most jurisdictions, its underlying concepts overlap considerably with certain business-oriented disciplines such as operations management.
Depending on the sub-specialties involved, industrial engineering may also be known as, or overlap with, operations management, management science, operations research, systems engineering, management engineering, manufacturing engineering, ergonomics or human factors engineering, safety engineering, or others, depending on the viewpoint or motives of the user."
Information technology	"Information technology (IT) is the application of computers to store, retrieve, transmit and manipulate data, often in the context of a business or other enterprise. IT is considered a subset of information and communications technology (ICT). In 2012, Zuppo proposed an ICT hierarchy where each hierarchy level ""contain some degree of commonality in that they are related to technologies that facilitate the transfer of information and various types of electronically mediated communications."" Business/IT was one level of the ICT hierarchy.
The term is commonly used as a synonym for computers and computer networks, but it also encompasses other information distribution technologies such as television and telephones. Several industries are associated with information technology, including computer hardware, software, electronics, semiconductors, internet, telecom equipment, engineering, healthcare, e-commerce and computer services.
Humans have been storing, retrieving, manipulating and communicating information since the Sumerians in Mesopotamia developed writing in about 3000 BC, but the term information technology in its modern sense first appeared in a 1958 article published in the Harvard Business Review; authors Harold J. Leavitt and Thomas L. Whisler commented that ""the new technology does not yet have a single established name. We shall call it information technology (IT)."" Their definition consists of three categories: techniques for processing, the application of statistical and mathematical methods to decision-making, and the simulation of higher-order thinking through computer programs.
Based on the storage and processing technologies employed, it is possible to distinguish four distinct phases of IT development: pre-mechanical (3000 BC – 1450 AD), mechanical (1450–1840), electromechanical (1840–1940) electronic (1940–present), and moreover, IT as a service. This article focuses on the most recent period (electronic), which began in about 1940."
Inoculation	"Inoculation (also known as variolation) is a historical method for the prevention of smallpox by deliberate introduction of material from smallpox pustules into the skin. This generally produced a less severe infection than naturally-acquired smallpox, but still induced immunity to it. The term entered medical English through horticultural usage meaning to graft a bud (or eye) from one plant into another. It is derived from the Latin in + oculus (eye). Though innoculation/innoculate is sometimes seen, this is incorrect, possibly erroneously thought to be related to innocuous, which is derived from the Latin in + nocuus (not harmful).
The terms inoculation, vaccination, immunization and injection are often used synonymously to refer to artificial induction of immunity against various infectious diseases. This is supported by some dictionaries. However, there are some important historical and current differences. In English medicine inoculation referred only to the prevention of smallpox until the very early 1800s. When Edward Jenner introduced smallpox vaccine in 1798 this was initially called cowpox inoculation or vaccine inoculation. Soon, to avoid confusion, smallpox inoculation was referred to as variolation (from variola = smallpox) and cowpox inoculation was referred to as vaccination (from Jenner's use of Variolae vaccinae = smallpox of the cow). Then, in 1891 Louis Pasteur proposed that the terms vaccine/vaccination should be extended to include the new protective procedures being developed. Immunization refers to the use of all vaccines but also extends to the use of antitoxin, which contains preformed antibody to e.g. diphtheria or tetanus exotoxins. Inoculation is now more or less synonymous in nontechnical usage with injection etc., and the question e.g. 'Have you had your flu injection/vaccination/inoculation/immunization?' should not cause confusion. The focus is on what is being given and why, not the literal meaning of the technique used.
Inoculation also has a specific meaning for procedures done in vitro. These include the transfer of microorganisms into and from laboratory apparatus such as test tubes and petri dishes in research and diagnostic laboratories, and also in commercial applications such as brewing, baking and the production of antibiotics.
In almost all cases the material inoculated is called the inoculum, or less commonly the inoculant, although the term culture is also used for work done in vitro."
Integrated circuits	"An integrated circuit or monolithic integrated circuit (also referred to as an IC, a chip, or a microchip) is a set of electronic circuits on one small plate (""chip"") of semiconductor material, normally silicon. This can be made much smaller than a discrete circuit made from independent electronic components. ICs can be made very compact, having up to several billion transistors and other electronic components in an area the size of a human fingernail. The width of each conducting line in a circuit can be made smaller and smaller as the technology advances; in 2008 it dropped below 100 nanometers, and has now been reduced to tens of nanometers.
ICs were made possible by experimental discoveries showing that semiconductor devices could perform the functions of vacuum tubes and by mid-20th-century technology advancements in semiconductor device fabrication. The integration of large numbers of tiny transistors into a small chip was an enormous improvement over the manual assembly of circuits using discrete electronic components. The integrated circuit's mass production capability, reliability and building-block approach to circuit design ensured the rapid adoption of standardized integrated circuits in place of designs using discrete transistors.
ICs have two main advantages over discrete circuits: cost and performance. Cost is low because the chips, with all their components, are printed as a unit by photolithography rather than being constructed one transistor at a time. Furthermore, packaged ICs use much less material than discrete circuits. Performance is high because the IC's components switch quickly and consume little power (compared to their discrete counterparts) as a result of the small size and close proximity of the components. As of 2012, typical chip areas range from a few square millimeters to around 450 mm2, with up to 9 million transistors per mm2.
Integrated circuits are used in virtually all electronic equipment today and have revolutionized the world of electronics. Computers, mobile phones, and other digital home appliances are now inextricable parts of the structure of modern societies, made possible by the low cost of ICs."
Interdisciplinarity	"Interdisciplinarity involves the combining of two or more academic disciplines into one activity (e.g., a research project). It is about creating something new by crossing boundaries, and thinking across them. It is related to an interdiscipline or an interdisciplinary field, which is an organizational unit that crosses traditional boundaries between academic disciplines or schools of thought, as new needs and professions emerge.
The term interdisciplinary is applied within education and training pedagogies to describe studies that use methods and insights of several established disciplines or traditional fields of study. Interdisciplinarity involves researchers, students, and teachers in the goals of connecting and integrating several academic schools of thought, professions, or technologies—along with their specific perspectives—in the pursuit of a common task. The epidemiology of AIDS or global warming require understanding of diverse disciplines to solve complex problems. Interdisciplinary may be applied where the subject is felt to have been neglected or even misrepresented in the traditional disciplinary structure of research institutions, for example, women's studies or ethnic area studies. Interdisciplinarity can likewise be applied to complex subjects that can only be understood by combining the perspectives of two or more fields.
The adjective interdisciplinary is most often used in educational circles when researchers from two or more disciplines pool their approaches and modify them so that they are better suited to the problem at hand, including the case of the team-taught course where students are required to understand a given subject in terms of multiple traditional disciplines. For example, the subject of land use may appear differently when examined by different disciplines, for instance, biology, chemistry, economics, geography, and politics."
International relations	"International relations (IR) or international affairs, depending on academic institution, is either a field of political science or an interdisciplinary academic field similar to global studies, in which students take a variety of internationally focused courses in social science and humanities disciplines. In both cases, the field studies relationships among countries, the roles of sovereign states, inter-governmental organizations (IGOs), international non-governmental organizations (INs), non-governmental organizations (NGOs), and multinational corporations (MNCs). International relations is an academic and a public policy field, and so can be positive and normative, because it analyzes and formulates the foreign policy of a given State.
As political activity, international relations dates from the time of the Greek historian Thucydides (c. 460–395 BC), and, in the early 20th century, became a discrete academic field (No. 5901 in the 4-digit UNESCO Nomenclature) within political science. In practice International Relations and International Affairs forms a separate academic program or field from Political Science, and the courses taught therein are highly interdisciplinary.
For example, international relations draws from the fields of: technology and engineering, economics, history, international law, demography, philosophy, geography, social work, sociology, anthropology, criminology, psychology, gender studies, cultural studies, culturology, and diplomacy. The scope of international relations comprehends globalization, diplomatic relations, state sovereignty, international security, ecological sustainability, nuclear proliferation, nationalism, economic development, global finance, as well as terrorism and organized crime, human security, foreign interventionism, and human rights, as well, as, more recently, comparative religion."
Internet	"The Internet is the global system of interconnected mainframe, personal, and wireless computer networks that use the Internet protocol suite (TCP/IP) to link billions of devices worldwide. It is a network of networks that consists of millions of private, public, academic, business, and government networks of local to global scope, linked by a broad array of electronic, wireless, and optical networking technologies. The Internet carries an extensive range of information resources and services, such as the inter-linked hypertext documents and applications of the World Wide Web (WWW), electronic mail, Usenet newsgroups, telephony, and peer-to-peer networks for file sharing.
Although the Internet protocol suite has been used by academia and the military industrial complex since the early 1980s, rapid adoption of its use was driven by events of the late 1980s and 1990s such as more powerful and affordable computers, the advent of fiber optics, the popularization of HTTP and the Web browser, and a push towards opening the technology to commerce. Internet use grew rapidly in the West from the mid-1990s and from the late 1990s in the developing world. In the 21 years since 1995, Internet use has grown 100-times to reach over one third of the world population, leading to its services and technologies being incorporated into virtually every aspect of contemporary life. The impact of the Internet has been so immense that it has been referred to as the ""8th continent"".
The origins of the Internet date back to research and development commissioned by the United States government, the United Kingdom government and the government of France in the 1960s to build robust, fault-tolerant communication via computer networks. This work led to the primary precursor networks: the ARPANET, in the United States, the Mark 1 NPL network in the United Kingdom and CYCLADES in France. The interconnection of regional academic networks in the 1980s marks the beginning of the transition to the modern Internet. From the late 1980s onward, the network experienced sustained exponential growth as generations of institutional, personal, and mobile computers were connected to it.
Most traditional communications media, including telephony and television, are being reshaped or redefined by the Internet, giving birth to new services such as Internet telephony and Internet television. Newspaper, book, and other print publishing are adapting to website technology, or are reshaped into blogging and web feeds. The entertainment industry was initially the fastest growing segment on the Internet. The Internet has enabled and accelerated new forms of personal interactions through instant messaging, Internet forums, and social networking. Online shopping has grown exponentially both for major retailers and small artisans and traders. Business-to-business and financial services on the Internet affect supply chains across entire industries.
The Internet has no centralized governance in either technological implementation or policies for access and usage; each constituent network sets its own policies. Only the overreaching definitions of the two principal name spaces in the Internet, the Internet Protocol address space and the Domain Name System (DNS), are directed by a maintainer organization, the Internet Corporation for Assigned Names and Numbers (ICANN). The technical underpinning and standardization of the core protocols are an activity of the Internet Engineering Task Force (IETF), a non-profit organization of loosely affiliated international participants that anyone may associate with by contributing technical expertise."
Introduction to evolution	"Evolution is the process of change in all forms of life over generations, and evolutionary biology is the study of how evolution occurs. Biological populations evolve through genetic changes that correspond to changes in the organisms' observable traits. Genetic changes include mutations, which are caused by damage or replication errors in an organism's DNA. As the genetic variation of a population drifts randomly over generations, natural selection gradually leads traits to become more or less common based on the relative reproductive success of organisms with those traits.
The age of the Earth is about 4.54 billion years old. The earliest undisputed evidence of life on Earth dates at least from 3.5 billion years ago, during the Eoarchean Era after a geological crust started to solidify following the earlier molten Hadean Eon. There are microbial mat fossils found in 3.48 billion-year-old sandstone discovered in Western Australia. Other early physical evidences of life include graphite, a biogenic substance, in 3.7 billion-year-old metasedimentary rocks discovered in western Greenland and, in 2015, ""remains of biotic life"" found in 4.1 billion-year-old rocks in Western Australia. According to one of the researchers, ""If life arose relatively quickly on Earth ... then it could be common in the universe."" More than 99 percent of all species, amounting to over five billion species, that ever lived on Earth are estimated to be extinct. Estimates on the number of Earth's current species range from 10 million to 14 million, of which about 1.2 million have been documented and over 86 percent have not yet been described.
Evolution does not attempt to explain the origin of life (covered instead by abiogenesis), but it does explain how the extremely simple early lifeforms evolved into the complex ecosystem that we see today. Based on the similarities between all present-day organisms, all life on Earth originated through common descent from a last universal ancestor from which all known species have diverged through the process of evolution. All individuals have hereditary material in the form of genes that are received from their parents, then passed on to any offspring. Among offspring there are variations of genes due to the introduction of new genes via random changes called mutations or via reshuffling of existing genes during sexual reproduction. The offspring differs from the parent in minor random ways. If those differences are helpful, the offspring is more likely to survive and reproduce. This means that more offspring in the next generation will have that helpful difference and individuals will not have equal chances of reproductive success. In this way, traits that result in organisms being better adapted to their living conditions become more common in descendant populations. These differences accumulate resulting in changes within the population. This process is responsible for the many diverse life forms in the world.
The forces of evolution are most evident when populations become isolated, either through geographic distance or by other mechanisms that prevent genetic exchange. Over time, isolated populations can branch off into new species.
The majority of genetic mutations neither assist, change the appearance of, nor bring harm to individuals. Through the process of genetic drift, these mutated genes are neutrally sorted among populations and survive across generations by chance alone. In contrast to genetic drift, natural selection is not a random process because it acts on traits that are necessary for survival and reproduction. Natural selection and random genetic drift are constant and dynamic parts of life and over time this has shaped the branching structure in the tree of life.
The modern understanding of evolution began with the 1859 publication of Charles Darwin's On the Origin of Species. In addition, Gregor Mendel's work with plants helped to explain the hereditary patterns of genetics. Fossil discoveries in paleontology, advances in population genetics and a global network of scientific research have provided further details into the mechanisms of evolution. Scientists now have a good understanding of the origin of new species (speciation) and have observed the speciation process in the laboratory and in the wild. Evolution is the principal scientific theory that biologists use to understand life and is used in many disciplines, including medicine, psychology, conservation biology, anthropology, forensics, agriculture and other social-cultural applications."
Introduction to genetics	"Genetics is the study of genes — what they are, what they do, and how they work. Genes are made up of molecules inside the nucleus of a cell that are strung together in such a way that the sequence carries information: that information determines how living organisms inherit phenotypic traits, (features) determined by the genes they received from their parents and thereby going back through the generations. For example, offspring produced by sexual reproduction usually look similar to each of their parents because they have inherited some of each of their parents' genes. Genetics identifies which features are inherited, and explains how these features pass from generation to generation. In addition to inheritance, genetics studies how genes are turned on and off to control what substances are made in a cell - gene expression; and how a cell divides - mitosis or meiosis.
Some phenotypic traits can be seen, such as eye color while others can only be detected, such as blood type or intelligence. Traits determined by genes can be modified by the animal's surroundings (environment): for example, the general design of a tiger's stripes is inherited, but the specific stripe pattern is determined by the tiger's surroundings. Another example is a person's height: it is determined by both genetics and nutrition.
Genes are made of DNA, which is divided into separate pieces called chromosomes. Humans have 46: 23 pairs, though this number varies between species, for example many primates have 24 pairs. Meiosis creates special cells, sperm in males and eggs in females, which only have 23 chromosomes. These two cells merge into one during the fertilization stage of sexual reproduction, creating a zygote in which a nucleic acid double helix divides, with each single helix occupying one of the daughter cells, resulting in half the normal number of genes. The zygote then divides into four daughter cells by which time genetic recombination has created a new embryo with 23 pairs of chromosomes, half from each parent. Mating and resultant mate choice result in sexual selection. In normal cell division (mitosis) is possible when the double helix separates, and a complement of each separated half is made, resulting in two identical double helices in one cell, with each occupying one of the two new daughter cells created when the cell divides.
Chromosomes all contain four nucleotides, abbreviated C (cytosine), G (guanine), A (adenine), or T (thymine), which line up in a particular sequence and make a long string. There are two strings of nucleotides coiled around one another in each chromosome: a double helix. C on one string is always opposite from G on the other string; A is always opposite T. There are about 3.2 billion nucleotide pairs on all the human chromosomes: this is the human genome. The order of the nucleotides carries genetic information, whose rules are defined by the genetic code, similar to how the order of letters on a page of text carries information. Three nucleotides in a row - a triplet - carry one unit of information: a codon.
The genetic code not only controls inheritance: it also controls gene expression, which occurs when a portion of the double helix is uncoiled, exposing a series of the nucleotides, which are within the interior of the DNA. This series of exposed triplets (codons) carries the information to allow machinery in the cell to ""read"" the codons on the exposed DNA, which results in the making of RNA molecules. RNA in turn makes either amino acids or microRNA, which are responsible for all of the structure and function of a living organism; i.e. they determine all the features of the cell and thus the entire individual. Closing the uncoiled segment turns off the gene.
Heritability means the information in a given gene is not always exactly the same in every individual in that species, so the same gene in different individuals does not give exactly the same instructions. Each unique form of a single gene is called an allele; different forms are collectively called polymorphisms. As an example, one allele for the gene for hair color and skin cell pigmentation could instruct the body to produce black pigment, producing black hair and pigmented skin; while a different allele of the same gene in a different individual could give garbled instructions that would result in a failure to produce any pigment, giving white hair and no pigmented skin: albinism. Mutations are random changes in genes creating new alleles, which in turn produce new traits, which could help, harm, or have no new effect on the individual's likelihood of survival; thus, mutations are the basis for evolution."
Introduction to quantum mechanics	"Quantum mechanics is the science of the very small: the body of scientific principles that explains the behaviour of matter and its interactions with energy on the scale of atoms and subatomic particles.
Classical physics explains matter and energy on a scale familiar to human experience, including the behaviour of astronomical bodies. It remains the key to measurement for much of modern science and technology. However, towards the end of the 19th century, scientists discovered phenomena in both the large (macro) and the small (micro) worlds that classical physics could not explain. As Thomas Kuhn explains in his analysis of the philosophy of science, The Structure of Scientific Revolutions, coming to terms with these limitations led to two major revolutions in physics which created a shift in the original scientific paradigm: the theory of relativity and the development of quantum mechanics. This article describes how physicists discovered the limitations of classical physics and developed the main concepts of the quantum theory that replaced it in the early decades of the 20th century. These concepts are described in roughly the order in which they were first discovered. For a more complete history of the subject, see History of quantum mechanics.
In this sense, the word quantum means the minimum amount of any physical entity involved in an interaction. Certain characteristics of matter can take only discrete values.
Light behaves in some respects like particles and in other respects like waves. Matter—particles such as electrons and atoms—exhibits wavelike behaviour too. Some light sources, including neon lights, give off only certain discrete frequencies of light. Quantum mechanics shows that light, along with all other forms of electromagnetic radiation, comes in discrete units, called photons, and predicts its energies, colours, and spectral intensities.
Some aspects of quantum mechanics can seem counterintuitive or even paradoxical, because they describe behaviour quite different from that seen at larger length scales. In the words of Richard Feynman, quantum mechanics deals with ""nature as She is – absurd"". For example, the uncertainty principle of quantum mechanics means that the more closely one pins down one measurement (such as the position of a particle), the less precise another measurement pertaining to the same particle (such as its momentum) must become."
Iraq	"Iraq (/ɪˈræk/, /ɪˈrɑːk/, or /aɪˈræk/; Arabic: العراق‎ al-‘Irāq, Kurdish: Êraq), officially the Republic of Iraq (Arabic:  جمهورية العراق  Jumhūrīyat al-‘Irāq; Kurdish: كۆماری عێراق‎ Komar-i ‘Êraq), is a country in Western Asia. The country is bordered by Turkey to the north, Iran to the east, Kuwait to the southeast, Saudi Arabia to the south, Jordan to the southwest, and Syria to the west. The southern part of Iraq is within the Arabian Peninsula. The capital, Baghdad, is in the centre of the country and its largest city. The largest ethnic groups in Iraq are Arabs and Kurds. Other ethnic groups include Assyrians, Turkmen, Shabakis, Yazidis, Armenians, Mandeans, Circassians, and Kawliya. Around 95% of the country's 36 million citizens are Shia or Sunni Muslims, with Christianity, Yarsan, Yezidism, and Mandeanism also present.
Iraq has a narrow section of coastline measuring 58 km (36 miles) on the northern Persian Gulf and its territory encompasses the Mesopotamian Alluvial Plain, the northwestern end of the Zagros mountain range, and the eastern part of the Syrian Desert. Two major rivers, the Tigris and Euphrates, run south through the centre of Iraq and flow into the Shatt al-Arab near the Persian Gulf. These rivers provide Iraq with significant amounts of fertile land.
The region between the Tigris and Euphrates rivers, historically known as Mesopotamia, is most often referred to as humanity's cradle of civilisation. It was here that mankind first began to read, write, create laws, and live in cities under an organised government—notably Uruk, from which Iraq was derived. The area has been home to continuous successive civilisations since the 6th millennium BC. At different periods in its history, Iraq was the centre of the indigenous Akkadian, Sumerian, Assyrian, and Babylonian empires. It was also part of the Median, Achaemenid, Hellenistic, Parthian, Sassanid, Roman, Rashidun, Umayyad, Abbasid, Ayyubid, Mongol, Safavid, Afsharid, and Ottoman empires, and under British control as a League of Nations mandate.
Iraq's modern borders were mostly demarcated in 1920 by the League of Nations when the Ottoman Empire was divided by the Treaty of Sèvres. Iraq was placed under the authority of the United Kingdom as the British Mandate of Mesopotamia. A monarchy was established in 1921 and the Kingdom of Iraq gained independence from Britain in 1932. In 1958, the monarchy was overthrown and the Iraqi Republic was created. Iraq was controlled by the Arab Socialist Ba'ath Party from 1968 until 2003. After an invasion by the United States and its allies in 2003, Saddam Hussein's Ba'ath Party was removed from power and multi-party parliamentary elections were held in 2005. The American presence in Iraq ended in 2011, but the Iraqi insurgency continued and intensified as fighters from the Syrian Civil War spilled into the country."
Isaac Newton	"Sir Isaac Newton PRS (/ˈnjuːtən/; 25 December 1642 – 20 March 1726/27) was an English physicist and mathematician (described in his own day as a ""natural philosopher"") who is widely recognised as one of the most influential scientists of all time and a key figure in the scientific revolution. His book Philosophiæ Naturalis Principia Mathematica (""Mathematical Principles of Natural Philosophy""), first published in 1687, laid the foundations for classical mechanics. Newton made seminal contributions to optics, and he shares credit with Gottfried Wilhelm Leibniz for the development of calculus.
Newton's Principia formulated the laws of motion and universal gravitation, which dominated scientists' view of the physical universe for the next three centuries. By deriving Kepler's laws of planetary motion from his mathematical description of gravity, and then using the same principles to account for the trajectories of comets, the tides, the precession of the equinoxes, and other phenomena, Newton removed the last doubts about the validity of the heliocentric model of the Solar System. This work also demonstrated that the motion of objects on Earth and of celestial bodies could be described by the same principles. His prediction that Earth should be shaped as an oblate spheroid was later vindicated by the measurements of Maupertuis, La Condamine, and others, which helped convince most Continental European scientists of the superiority of Newtonian mechanics over the earlier system of Descartes.
Newton built the first practical reflecting telescope and developed a theory of colour based on the observation that a prism decomposes white light into the many colours of the visible spectrum. He formulated an empirical law of cooling, studied the speed of sound, and introduced the notion of a Newtonian fluid. In addition to his work on calculus, as a mathematician Newton contributed to the study of power series, generalised the binomial theorem to non-integer exponents, developed a method for approximating the roots of a function, and classified most of the cubic plane curves.
Newton was a fellow of Trinity College and the second Lucasian Professor of Mathematics at the University of Cambridge. He was a devout but unorthodox Christian, and, unusually for a member of the Cambridge faculty of the day, he refused to take holy orders in the Church of England, perhaps because he privately rejected the doctrine of the Trinity. Beyond his work on the mathematical sciences, Newton dedicated much of his time to the study of biblical chronology and alchemy, but most of his work in those areas remained unpublished until long after his death. In his later life, Newton became president of the Royal Society. Newton served the British government as Warden and Master of the Royal Mint."
Johannes Kepler	"Johannes Kepler (German: [ˈkɛplɐ]; December 27, 1571 – November 15, 1630) was a German mathematician, astronomer, and astrologer. A key figure in the 17th century scientific revolution, he is best known for his laws of planetary motion, based on his works Astronomia nova, Harmonices Mundi, and Epitome of Copernican Astronomy. These works also provided one of the foundations for Isaac Newton's theory of universal gravitation.
During his career, Kepler was a mathematics teacher at a seminary school in Graz, Austria, where he became an associate of Prince Hans Ulrich von Eggenberg. Later he became an assistant to astronomer Tycho Brahe, and eventually the imperial mathematician to Emperor Rudolf II and his two successors Matthias and Ferdinand II. He was also a mathematics teacher in Linz, Austria, and an adviser to General Wallenstein. Additionally, he did fundamental work in the field of optics, invented an improved version of the refracting telescope (the Keplerian Telescope), and mentioned the telescopic discoveries of his contemporary Galileo Galilei.
Kepler lived in an era when there was no clear distinction between astronomy and astrology, but there was a strong division between astronomy (a branch of mathematics within the liberal arts) and physics (a branch of natural philosophy). Kepler also incorporated religious arguments and reasoning into his work, motivated by the religious conviction and belief that God had created the world according to an intelligible plan that is accessible through the natural light of reason. Kepler described his new astronomy as ""celestial physics"", as ""an excursion into Aristotle's Metaphysics"", and as ""a supplement to Aristotle's On the Heavens"", transforming the ancient tradition of physical cosmology by treating astronomy as part of a universal mathematical physics."
Large Hadron Collider	"The Large Hadron Collider (LHC) is the world's largest and most powerful particle collider, the largest, most complex experimental facility ever built, and the largest single machine in the world. It was built by the European Organization for Nuclear Research (CERN) between 1998 and 2008 in collaboration with over 10,000 scientists and engineers from over 100 countries, as well as hundreds of universities and laboratories. It lies in a tunnel 27 kilometres (17 mi) in circumference, as deep as 175 metres (574 ft) beneath the France–Switzerland border near Geneva, Switzerland. Its first research run took place from 30 March 2010 to 13 February 2013 at an initial energy of 3.5 teraelectronvolts (TeV) per beam (7 TeV total), almost 4 times more than the previous world record for a collider, rising to 4 TeV per beam (8 TeV total) from 2012. On 13 February 2013 the LHC's first run officially ended, and it was shut down for planned upgrades. 'Test' collisions restarted in the upgraded collider on 5 April 2015, reaching 6.5 TeV per beam on 20 May 2015 (13 TeV total, the current world record). Its second research run commenced on schedule, on 3 June 2015.
The LHC's aim is to allow physicists to test the predictions of different theories of particle physics, high-energy physics and in particular, to further test the properties of the Higgs boson and the large family of new particles predicted by supersymmetric theories, and other unsolved questions of physics, advancing human understanding of physical laws. It contains seven detectors, each designed for certain kinds of research. The proton-proton collision is the primary operation method, but the LHC has also collided protons with lead nuclei for two months in 2013 and used lead–lead collisions for about one month each in 2010, 2011, 2013 and 2015 for other investigations.
The LHC's computing grid was (and currently is) a world record holder. Data from collisions was produced at an unprecedented rate for the time of first collisions, tens of petabytes per year, a major challenge at the time, to be analysed by a grid-based computer network infrastructure connecting 140 computing centers in 35 countries – by 2012 the Worldwide LHC Computing Grid was also the world's largest distributed computing grid, comprising over 170 computing facilities in a worldwide network across 36 countries."
Late antiquity	"Late Antiquity is a periodization used by historians to describe the time of transition from classical antiquity to the Middle Ages in mainland Europe, the Mediterranean world, and the Middle East. The development of the periodization has generally been accredited to historian Peter Brown, after the publication of his seminal work The World of Late Antiquity (1971). Precise boundaries for the period are a matter of debate, but Brown proposes a period between the 2nd and 8th centuries AD. Generally, it can be thought of as from the end of the Roman Empire's Crisis of the Third Century (c. 235 – 284) to, in the East, the period of early Islam (7th – 9th centuries), following the Muslim conquests in the mid-7th century. In the West the end was earlier, with the start of the Early Medieval period typically placed in the 6th century, or earlier on the Western edges of the empire.
The Roman Empire underwent considerable social, cultural and organizational changes starting with the reign of Diocletian, who began the custom of splitting the Empire into Eastern and Western halves ruled by multiple emperors. Beginning with Constantine the Great the Empire was Christianized, and a new capital founded at Constantinople. Migrations of Germanic tribes disrupted Roman rule from the late 4th century onwards, culminating in the eventual collapse of the Empire in the West in 476, replaced by the so-called barbarian kingdoms. The resultant cultural fusion of Greco-Roman, Germanic and Christian traditions formed the foundations of the subsequent culture of Europe.
The general decline of population, technological knowledge and standards of living in Europe during this period became the archetypal example of societal collapse for writers from the Renaissance until recent times. As a result of this decline, and the relative paucity of historical records from Europe in particular, the period between the fall of the Empire and the Middle Ages became known as the Dark Ages, a term displaced in most current periodisations by the introduction of ""Late Antiquity""."
Law	"Law is a system of rules that are enforced through social institutions to govern behavior. Laws can be made by a collective legislature or by a single legislator, resulting in statutes, by the executive through decrees and regulations, or by judges through binding precedent, normally in common law jurisdictions. Private individuals can create legally binding contracts, including arbitration agreements that may elect to accept alternative arbitration to the normal court process. The formation of laws themselves may be influenced by a constitution, written or tacit, and the rights encoded therein. The law shapes politics, economics, history and society in various ways and serves as a mediator of relations between people.
A general distinction can be made between (a) civil law jurisdictions (including Catholic canon law and socialist law), in which the legislature or other central body codifies and consolidates their laws, and (b) common law systems, where judge-made precedent is accepted as binding law. Historically, religious laws played a significant role even in settling of secular matters, which is still the case in some religious communities, particularly Jewish, and some countries, particularly Islamic. Islamic Sharia law is the world's most widely used religious law.
The adjudication of the law is generally divided into two main areas referred to as (i) Criminal law and (ii) Civil law. Criminal law deals with conduct that is considered harmful to social order and in which the guilty party may be imprisoned or fined. Civil law (not to be confused with civil law jurisdictions above) deals with the resolution of lawsuits (disputes) between individuals or organizations. These resolutions seek to provide a legal remedy (often monetary damages) to the winning litigant. Under civil law, the following specialties, among others, exist: Contract law regulates everything from buying a bus ticket to trading on derivatives markets. Property law regulates the transfer and title of personal property and real property. Trust law applies to assets held for investment and financial security. Tort law allows claims for compensation if a person's property is harmed. Constitutional law provides a framework for the creation of law, the protection of human rights and the election of political representatives. Administrative law governs what executive branch agencies may and may not do, procedures that they must follow to do it, and judicial review when a member of the public is harmed by an agency action. International law governs affairs between sovereign states in activities ranging from trade to military action. To implement and enforce the law and provide services to the public by public servants, a government's bureaucracy, military, and police are vital. While all these organs of the state are creatures created and bound by law, an independent legal profession and a vibrant civil society inform and support their progress.
Law provides a rich source of scholarly inquiry into legal history, philosophy, economic analysis and sociology. Law also raises important and complex issues concerning equality, fairness, and justice. There is an old saying that 'all are equal before the law', although Jonathan Swift argued that 'Laws are like cobwebs, which may catch small flies, but let wasps and hornets break through.' In 1894, the author Anatole France said sarcastically, ""In its majestic equality, the law forbids rich and poor alike to sleep under bridges, beg in the streets, and steal loaves of bread."" Writing in 350 BC, the Greek philosopher Aristotle declared, ""The rule of law is better than the rule of any individual."" Mikhail Bakunin said: ""All law has for its object to confirm and exalt into a system the exploitation of the workers by a ruling class"". Cicero said ""more law, less justice"". Marxist doctrine asserts that law will not be required once the state has withered away. Regardless of one's view of the law, it remains today a completely central institution."
Library science	"Library science (often termed library studies, library and information science, bibliothecography) is an interdisciplinary or multidisciplinary field that applies the practices, perspectives, and tools of management, information technology, education, and other areas to libraries; the collection, organization, preservation, and dissemination of information resources; and the political economy of information. Martin Schrettinger, a Bavarian librarian, coined the discipline within his work (1808-1828) Versuch eines vollständigen Lehrbuchs der Bibliothek-Wissenschaft oder Anleitung zur vollkommenen Geschäftsführung eines Bibliothekars. Rather than classifying information based on nature-oriented elements, as was previously done in his Bavarian library, Schrettinger organized books in alphabetical order. The first American school for library science was founded by Melvil Dewey at Columbia University in 1887. It is an aspect of the broader field of librarianship.
Historically, library science has also included archival science. This includes how information resources are organized to serve the needs of select user group, how people interact with classification systems and technology, how information is acquired, evaluated and applied by people in and outside of libraries as well as cross-culturally, how people are trained and educated for careers in libraries, the ethics that guide library service and organization, the legal status of libraries and information resources, and the applied science of computer technology used in documentation and records management.
There is no generally agreed-upon distinction between the terms library science, librarianship, and library and information science, and to a certain extent they are interchangeable, perhaps differing most significantly in connotation. The term library and information science (LIS) is most often used; most librarians consider it as only a terminological variation, intended to emphasize the scientific and technical foundations of the subject and its relationship with information science. LIS should not be confused with information theory, the mathematical study of the concept of information. Library and information science can also be seen as an integration of the two fields library science and information science, which were separate at one point. Library philosophy has been contrasted with library science as the study of the aims and justifications of librarianship as opposed to the development and refinement of techniques."
Linguistics	"Linguistics is the scientific study of language. There are three aspects to this study: language form, language meaning, and language in context. The earliest activities in the description of language have been attributed to the 4th century BCE Indian grammarian Pāṇini, who was an early student of linguistics and wrote a formal description of the Sanskrit language in his Aṣṭādhyāyī.
Linguistics analyzes human language as a system for relating sounds (or signs in signed languages) and meaning. Phonetics studies acoustic and articulatory properties of the production and perception of speech sounds and non-speech sounds. The study of language meaning, on the other hand, deals with how languages encode relations between entities, properties, and other aspects of the world to convey, process, and assign meaning, as well as to manage and resolve ambiguity. While the study of semantics typically concerns itself with truth conditions, pragmatics deals with how context influences meanings.
Grammar is a system of rules which govern the form of the utterances in a given language. It encompasses both sound and meaning, and includes phonology (how sounds and gestures function together), morphology (the formation and composition of words), and syntax (the formation and composition of phrases and sentences from words).
In the early 20th century, Ferdinand de Saussure distinguished between the notions of langue and parole in his formulation of structural linguistics. According to him, parole is the specific utterance of speech, whereas langue refers to an abstract phenomenon that theoretically defines the principles and system of rules that govern a language. This distinction resembles the one made by Noam Chomsky between competence and performance, where competence is individual's ideal knowledge of a language, while performance is the specific way in which it is used.
The formal study of language has also led to the growth of fields like psycholinguistics, which explores the representation and function of language in the mind; neurolinguistics, which studies language processing in the brain; and language acquisition, which investigates how children and adults acquire a particular language.
Linguistics also includes nonformal approaches to the study of other aspects of human language, such as social, cultural, historical and political factors. The study of cultural discourses and dialects is the domain of sociolinguistics, which looks at the relation between linguistic variation and social structures, as well as that of discourse analysis, which examines the structure of texts and conversations. Research on language through historical and evolutionary linguistics focuses on how languages change, and on the origin and growth of languages, particularly over an extended period of time.
Corpus linguistics takes naturally occurring texts or films (in signed languages) as its primary object of analysis, and studies the variation of grammatical and other features based on such corpora. Stylistics involves the study of patterns of style: within written, signed, or spoken discourse. Language documentation combines anthropological inquiry with linguistic inquiry to describe languages and their grammars. Lexicography covers the study and construction of dictionaries. Computational linguistics applies computer technology to address questions in theoretical linguistics, as well as to create applications for use in parsing, data retrieval, machine translation, and other areas. People can apply actual knowledge of a language in translation and interpreting, as well as in language education – the teaching of a second or foreign language. Policy makers work with governments to implement new plans in education and teaching which are based on linguistic research.
Areas of study related to linguistics include semiotics (the study of signs and symbols both within language and without), literary criticism, translation, and speech-language pathology."
Long Island, New York	"Long Island is an island located just off the northeast coast of the United States and a region within the U.S. state of New York. Stretching east-northeast from New York Harbor into the Atlantic Ocean, the island comprises four counties: Kings and Queens (these form the New York City boroughs of Brooklyn and Queens, respectively) to the west; then Nassau and Suffolk to the east. However, many people in the New York metropolitan area (even those living in Queens and Brooklyn) colloquially use the term ""Long Island"" (or ""The Island"") exclusively to refer to the Nassau-Suffolk county area collectively, which is mainly suburban in character. North of the island is Long Island Sound, across from which lie the states of Connecticut and a small part of Rhode Island.
With a Census-estimated population of 7,838,722 in 2015, constituting nearly 40% of New York State's population, Long Island is the most populated island in any U.S. state or territory, and the 18th-most populous island in the world (ahead of Ireland, Jamaica, and Hokkaidō). Its population density is 5,571 inhabitants per square mile (2,151/km2). If Long Island geographically constituted an independent metropolitan statistical area, it would rank fourth most populous in the United States; while if it were a U.S. state, Long Island would rank 13th in population and first in population density.
Both the longest and the largest island in the contiguous United States, Long Island extends 118 miles (190 km) eastward from New York Harbor to Montauk Point, with a maximum north-to-south distance of 23 miles (37 km) between Long Island Sound and the Atlantic coast. With a land area of 1,401 square miles (3,629 km2), Long Island is the 11th-largest island in the United States and the 149th-largest island in the world — larger than the 1,214 square miles (3,140 km2) of the smallest state, Rhode Island.
Two of the New York City metropolitan area's three busiest airports, JFK International Airport and LaGuardia Airport, as well as two major air traffic control radar facilities, the New York TRACON and the New York ARTCC, are located on the Island. Nine bridges and 13 tunnels (including railroad tunnels) connect Brooklyn and Queens (and thus Long Island) to the three other boroughs of New York City. Ferries connect Suffolk County northward across Long Island Sound to the state of Connecticut. In addition, the Long Island Railroad is the busiest commuter railroad in North America and operates 24/7."
Loudspeaker	"A loudspeaker (or loud-speaker or speaker) is a device containing one or more electroacoustic transducers; which convert an electrical audio signal into a corresponding sound. The first primitive loudspeakers were invented during the development of telephone systems in the late 1800s, but electronic amplification by vacuum tube beginning around 1912 made loudspeakers truly practical. By the 1920s they were used in radios, phonographs, public address systems and theatre sound systems for talking motion pictures.
The most widely used type of speaker today is the dynamic speaker, invented in 1925 by Edward W. Kellogg and Chester W. Rice. The dynamic speaker operates on the same basic principle as a dynamic microphone, but in reverse, to produce sound from an electrical signal. When an alternating current electrical audio signal is applied to its voice coil, a coil of wire suspended in a circular gap between the poles of a permanent magnet, the coil is forced to move rapidly back and forth due to Faraday's law of induction, which causes a diaphragm (usually conically shaped) attached to the coil to move back and forth, pushing on the air to create sound waves. Besides this most common method, there are several alternative technologies that can be used to convert an electrical signal into sound. The sound source (e.g., a sound recording or a microphone) must be amplified with an amplifier before the signal is sent to the speaker.
Speakers are typically housed in an enclosure which is often a rectangular or square box made of wood or sometimes plastic, and the enclosure plays an important role in the quality of the sound. Where high fidelity reproduction of sound is required, multiple loudspeaker transducers are often mounted in the same enclosure, each reproducing a part of the audible frequency range (picture at right). In this case the individual speakers are referred to as ""drivers"" and the entire unit is called a loudspeaker. Drivers made for reproducing high audio frequencies are called tweeters, those for middle frequencies are called mid-range drivers, and those for low frequencies are called woofers. Miniature loudspeakers are found in devices such as radio and TV receivers, and many forms of music players. Larger loudspeaker systems are used for music, sound reinforcement in theatres and concerts, and in public address systems."
Ludwig Wittgenstein	"Ludwig Josef Johann Wittgenstein (/ˈvɪtɡənˌstaɪn/; German: [ˈvɪtgənˌʃtaɪn]; 26 April 1889 – 29 April 1951) was an Austrian-British philosopher who worked primarily in logic, the philosophy of mathematics, the philosophy of mind, and the philosophy of language. From 1929 to 1947, Wittgenstein taught at the University of Cambridge. During his lifetime he published just one slim book, the 75-page Tractatus Logico-Philosophicus (1921), one article, one book review and a children's dictionary. His voluminous manuscripts were edited and published posthumously. Philosophical Investigations appeared as a book in 1953, and has since come to be recognised as one of the most important works of philosophy in the twentieth century. His teacher Bertrand Russell described Wittgenstein as ""the most perfect example I have ever known of genius as traditionally conceived; passionate, profound, intense, and dominating.""
Born in Vienna into one of Europe's richest families, he inherited a large fortune from his father in 1913. He gave some considerable sums to poor artists. In a period of severe personal depression after the first World War, he then gave away his entire fortune to his brothers and sisters. Three of his brothers committed suicide, with Wittgenstein contemplating it too. He left academia several times—serving as an officer on the front line during World War I, where he was decorated a number of times for his courage; teaching in schools in remote Austrian villages where he encountered controversy for hitting children when they made mistakes in mathematics; and working as a hospital porter during World War II in London where he told patients not to take the drugs they were prescribed while largely managing to keep secret the fact that he was one of the world's most famous philosophers. He described philosophy, however, as ""the only work that gives me real satisfaction.""
His philosophy is often divided into an early period, exemplified by the Tractatus, and a later period, articulated in the Philosophical Investigations. The early Wittgenstein was concerned with the logical relationship between propositions and the world and believed that by providing an account of the logic underlying this relationship, he had solved all philosophical problems. The later Wittgenstein rejected many of the assumptions of the Tractatus, arguing that the meaning of words is best understood as their use within a given language-game.
Wittgenstein's influence has been felt in nearly every field of the humanities and social sciences, yet there are diverging interpretations of his thought. In the words of his friend and colleague Georg Henrik von Wright:

He was of the opinion... that his ideas were generally misunderstood and distorted even by those who professed to be his disciples. He doubted he would be better understood in the future. He once said he felt as though he was writing for people who would think in a different way, breathe a different air of life, from that of present-day men."
Magic (paranormal)	"Magic or sorcery is the use of rituals, symbols, actions, gestures and language with the aim of exploiting supernatural forces. Belief in and practice of magic has been present since the earliest human cultures and continues to have an important spiritual, religious, and medicinal role in many cultures today.
Magic is sometimes practiced in isolation and secrecy and often viewed with suspicion by the wider community. In non-scientific societies, perceived magical attack is sometimes employed to explain personal or societal misfortune.
The concept of magic, as distinct from religion was first widely recognized in Judaism, which defined the practices of pagan worship designed to appease and receive benefits from gods other than Yahweh as magic. Wouter Hanegraaff argues that magic is in fact ""a largely polemical concept that has been used by various religious interest groups either to describe their own religious beliefs and practices or – more frequently – to discredit those of others.""
The foremost perspectives on magic in anthropology are functionalism, symbolism, and intellectualism.
The term ""magical thinking"" in anthropology, psychology, and cognitive science refers to causal reasoning often involving associative thinking, such as the perceived ability of the mind to affect the physical world (see the philosophical problem of mental causation) or correlation mistaken for materialist causation.
Psychological theories consider magic a personal phenomenon intended to meet individual needs as opposed to a social phenomenon serving a collective purpose. The belief that one can influence supernatural powers, by prayer, sacrifice or invocation dates back to prehistoric religions and it can be found in early records such as the Egyptian pyramid texts and the Indian Vedas.
Magic and religion are categories of beliefs and systems of knowledge used within societies. Some forms of shamanic contact with the spirit world seem to be nearly universal in the early development of human communities. They appear in various tribal peoples from Aboriginal Australia and Māori people of New Zealand to the Amazon, African savannah, and pagan Europe.
In general, the 20th century saw a sharp rise in public interest in various forms of magical practice and the foundation of traditions and organizations that can be regarded as religious or philosophies.
Modern Western magicians generally state magic's primary purpose to be personal spiritual growth."
Magnetic resonance imaging	"Magnetic resonance imaging (MRI), nuclear magnetic resonance imaging (NMRI), or magnetic resonance tomography (MRT) is a medical imaging technique used in radiology to image the anatomy and the physiological processes of the body in both health and disease. MRI scanners use strong magnetic fields, radio waves, and field gradients to form images of the body.
Many atomic nuclei have a property called ""spin"", which is associated with a magnetic dipole moment (analogous to a compass needle). All hydrogen atoms have nuclear spin, and are thus detectable by MRI. Water, having molecular formula H2O, contains two hydrogen atoms per molecule. The human body is roughly 70-percent water by mass, and most MRI scans essentially measure the spatial distribution of water in the object being imaged. The large tube into which the subject is placed is surrounded by a superconducting solenoid that produces a strong magnetic field down the length of the bore. This magnetic field aligns the nuclear spins and generates an energy difference between spins aligned with or against the field. At any feasible field strength (typical values are 1.5 or 3.0 tesla), the energy difference is in the radio frequency range of the electromagnetic spectrum. To generate an image, pulses of radio-frequency energy are emitted by antennas that excite the nuclear spin energy transition. As the spins return to equilibrium (i.e. ""relax""), they emit radio-waves with a frequency dependent on the strength of the magnetic field. This RF emission is very faint (on the order of 10−12 watts), and is received by antennas close to the anatomy being imaged. By creating a precise and known gradient in the main magnetic field (with additional RF coils), nuclei at different positions will have different frequencies. The Fourier transform can then be computed, extracting the contribution of these many different frequencies from the signal. A particular frequency corresponds to the signal from water at a particular location (voxel) and an image can be reconstructed. While the hydrogen protons of water are the most often imaged nuclei, phosphorus, sodium, and carbon are sometimes used in specialty applications. There is also a wide variety of techniques that can be used while still measuring the hydrogen nuclei, including diffusion weighted MRI (DWI), contrast enhanced MRI (DCE-MRI), and functional MRI (fMRI).
MRI is widely used in hospitals and clinics for medical diagnosis, staging of disease and follow-up without exposing the body to ionizing radiation."
Marie Curie	"Marie Skłodowska Curie (/ˈkjʊri, kjʊˈriː/; French: [kyʁi]; Polish: [kʲiˈri]; 7 November 1867 – 4 July 1934), born Maria Salomea Skłodowska [ˈmarja salɔˈmɛa skwɔˈdɔfska], was a Polish and naturalized-French physicist and chemist who conducted pioneering research on radioactivity. She was the first woman to win a Nobel Prize, the first person and only woman to win twice, the only person to win twice in multiple sciences, and was part of the Curie family legacy of five Nobel Prizes. She was also the first woman to become a professor at the University of Paris, and in 1995 became the first woman to be entombed on her own merits in the Panthéon in Paris.
She was born in Warsaw, in what was then the Kingdom of Poland, part of the Russian Empire. She studied at Warsaw's clandestine Floating University and began her practical scientific training in Warsaw. In 1891, aged 24, she followed her older sister Bronisława to study in Paris, where she earned her higher degrees and conducted her subsequent scientific work. She shared the 1903 Nobel Prize in Physics with her husband Pierre Curie and with physicist Henri Becquerel. She won the 1911 Nobel Prize in Chemistry.
Her achievements included the development of the theory of radioactivity (a term that she coined), techniques for isolating radioactive isotopes, and the discovery of two elements, polonium and radium. Under her direction, the world's first studies were conducted into the treatment of neoplasms, using radioactive isotopes. She founded the Curie Institutes in Paris and in Warsaw, which remain major centres of medical research today. During World War I, she established the first military field radiological centres.
While a French citizen, Marie Skłodowska Curie (she used both surnames) never lost her sense of Polish identity. She taught her daughters the Polish language and took them on visits to Poland. She named the first chemical element that she discovered‍—‌polonium, which she isolated in 1898‍—‌after her native country.
Curie died in 1934, aged 66, at a sanatorium in Sancellemoz (Haute-Savoie), France, due to aplastic anemia brought on by exposure to radiation while carrying test tubes of radium in her pockets during research, and in the course of her service in World War I mobile X-ray units that she had set up."
Marine biology	"Marine biology is the scientific study of organisms in the ocean or other marine bodies of water. Given that in biology many phyla, families and genera have some species that live in the sea and others that live on land, marine biology classifies species based on the environment rather than on taxonomy. Marine biology differs from marine ecology as marine ecology is focused on how organisms interact with each other and the environment, while biology is the study of the organisms themselves.
A large proportion of all life on Earth lives in the ocean. Exactly how large the proportion is unknown, since many ocean species are still to be discovered. The ocean is a complex three-dimensional world covering approximately 71% of the Earth's surface. The habitats studied in marine biology include everything from the tiny layers of surface water in which organisms and abiotic items may be trapped in surface tension between the ocean and atmosphere, to the depths of the oceanic trenches, sometimes 10,000 meters or more beneath the surface of the ocean. Specific habitats include coral reefs, kelp forests, seagrass meadows, the surrounds of seamounts and thermal vents, tidepools, muddy, sandy and rocky bottoms, and the open ocean (pelagic) zone, where solid objects are rare and the surface of the water is the only visible boundary. The organisms studied range from microscopic phytoplankton and zooplankton to huge cetaceans (whales) 30 meters (98 feet) in length.
Marine life is a vast resource, providing food, medicine, and raw materials, in addition to helping to support recreation and tourism all over the world. At a fundamental level, marine life helps determine the very nature of our planet. Marine organisms contribute significantly to the oxygen cycle, and are involved in the regulation of the Earth's climate. Shorelines are in part shaped and protected by marine life, and some marine organisms even help create new land.
Many species are economically important to humans, including both finfish and shellfish. It is also becoming understood that the well-being of marine organisms and other organisms are linked in fundamental ways. The human body of knowledge regarding the relationship between life in the sea and important cycles is rapidly growing, with new discoveries being made nearly every day. These cycles include those of matter (such as the carbon cycle) and of air (such as Earth's respiration, and movement of energy through ecosystems including the ocean). Large areas beneath the ocean surface still remain effectively unexplored."
Mathematics	"Mathematics (from Greek μάθημα máthēma, “knowledge, study, learning”) is the study of topics such as quantity (numbers), structure, space, and change. There is a range of views among mathematicians and philosophers as to the exact scope and definition of mathematics.
Mathematicians seek out patterns and use them to formulate new conjectures. Mathematicians resolve the truth or falsity of conjectures by mathematical proof. When mathematical structures are good models of real phenomena, then mathematical reasoning can provide insight or predictions about nature. Through the use of abstraction and logic, mathematics developed from counting, calculation, measurement, and the systematic study of the shapes and motions of physical objects. Practical mathematics has been a human activity for as far back as written records exist. The research required to solve mathematical problems can take years or even centuries of sustained inquiry.
Rigorous arguments first appeared in Greek mathematics, most notably in Euclid's Elements. Since the pioneering work of Giuseppe Peano (1858–1932), David Hilbert (1862–1943), and others on axiomatic systems in the late 19th century, it has become customary to view mathematical research as establishing truth by rigorous deduction from appropriately chosen axioms and definitions. Mathematics developed at a relatively slow pace until the Renaissance, when mathematical innovations interacting with new scientific discoveries led to a rapid increase in the rate of mathematical discovery that has continued to the present day.
Galileo Galilei (1564–1642) said, ""The universe cannot be read until we have learned the language and become familiar with the characters in which it is written. It is written in mathematical language, and the letters are triangles, circles and other geometrical figures, without which means it is humanly impossible to comprehend a single word. Without these, one is wandering about in a dark labyrinth."" Carl Friedrich Gauss (1777–1855) referred to mathematics as ""the Queen of the Sciences"". Benjamin Peirce (1809–1880) called mathematics ""the science that draws necessary conclusions"". David Hilbert said of mathematics: ""We are not speaking here of arbitrariness in any sense. Mathematics is not like a game whose tasks are determined by arbitrarily stipulated rules. Rather, it is a conceptual system possessing internal necessity that can only be so and by no means otherwise."" Albert Einstein (1879–1955) stated that ""as far as the laws of mathematics refer to reality, they are not certain; and as far as they are certain, they do not refer to reality.""
Mathematics is essential in many fields, including natural science, engineering, medicine, finance and the social sciences. Applied mathematics has led to entirely new mathematical disciplines, such as statistics and game theory. Mathematicians also engage in pure mathematics, or mathematics for its own sake, without having any application in mind. There is no clear line separating pure and applied mathematics, and practical applications for what began as pure mathematics are often discovered."
Max Born	"Max Born (German: [bɔɐ̯n]; 11 December 1882 – 5 January 1970) was a German physicist and mathematician who was instrumental in the development of quantum mechanics. He also made contributions to solid-state physics and optics and supervised the work of a number of notable physicists in the 1920s and 30s. Born won the 1954 Nobel Prize in Physics for his ""fundamental research in Quantum Mechanics, especially in the statistical interpretation of the wave function"".
Born was born in 1882 in Breslau, then in Germany, now in Poland and known as Wrocław. He entered the University of Göttingen in 1904, where he found the three renowned mathematicians, Felix Klein, David Hilbert and Hermann Minkowski. He wrote his Ph.D. thesis on the subject of ""Stability of Elastica in a Plane and Space"", winning the University's Philosophy Faculty Prize. In 1905, he began researching special relativity with Minkowski, and subsequently wrote his habilitation thesis on the Thomson model of the atom. A chance meeting with Fritz Haber in Berlin in 1918 led to discussion of the manner in which an ionic compound is formed when a metal reacts with a halogen, which is today known as the Born–Haber cycle.
In the First World War, after originally being placed as a radio operator, he was moved to research duties regarding sound ranging due to his specialist knowledge. In 1921, Born returned to Göttingen, arranging another chair for his long-time friend and colleague James Franck. Under Born, Göttingen became one of the world's foremost centres for physics. In 1925, Born and Werner Heisenberg formulated the matrix mechanics representation of quantum mechanics. The following year, he formulated the now-standard interpretation of the probability density function for ψ*ψ in the Schrödinger equation, for which he was awarded the Nobel Prize in 1954. His influence extended far beyond his own research. Max Delbrück, Siegfried Flügge, Friedrich Hund, Pascual Jordan, Maria Goeppert-Mayer, Lothar Wolfgang Nordheim, Robert Oppenheimer, and Victor Weisskopf all received their Ph.D. degrees under Born at Göttingen, and his assistants included Enrico Fermi, Werner Heisenberg, Gerhard Herzberg, Friedrich Hund, Pascual Jordan, Wolfgang Pauli, Léon Rosenfeld, Edward Teller, and Eugene Wigner.
In January 1933, the Nazi Party came to power in Germany, and Born, who was Jewish, was suspended. He emigrated to Britain, where he took a job at St John's College, Cambridge, and wrote a popular science book, The Restless Universe, as well as Atomic Physics, which soon became a standard textbook. In October 1936, he became the Tait Professor of Natural Philosophy at the University of Edinburgh, where, working with German-born assistants E. Walter Kellermann and Klaus Fuchs, he continued his research into physics. Max Born became a naturalised British subject on 31 August 1939, one day before World War II broke out in Europe. He remained at Edinburgh until 1952. He retired to Bad Pyrmont, in West Germany, and died in a hospital in Göttingen on 5 January 1970."
Max Planck Society	"The Max Planck Society for the Advancement of Science (German: Max-Planck-Gesellschaft zur Förderung der Wissenschaften e. V.; abbreviated MPG) is a formally independent non-governmental and non-profit association of German research institutes founded in 1911 as the Kaiser Wilhelm Society and renamed the Max Planck Society in 1948 in honor of its former president, theoretical physicist Max Planck. The society is funded by the federal and state governments of Germany as well as other sources.
According to its primary goal Max Planck Society supports fundamental research in the natural, life and social sciences, the arts and humanities in its 83 (as of January 2014) Max Planck Institutes. The society has a total staff of approximately 17,000 permanent employees, including 5,470 scientists, plus around 4,600 non-tenured scientists and guests. Society budget for 2015 was about €1.7 billion.
The Max Planck Institutes focus on excellence in research. The Max Planck Society has a world-leading reputation as a science and technology research organization, with 33 Nobel Prizes awarded to their scientists, and are generally regarded as the foremost basic research organization in Europe and the world. In 2013, the Nature Publishing Index placed the Max Planck institutes fifth worldwide in terms of research published in Nature journals (after Harvard, MIT, Stanford and the US NIH). In terms of total research volume (unweighted by citations or impact), the Max Planck Society is only outranked by the Chinese Academy of Sciences, the Russian Academy of Sciences and Harvard University. The Thomson Reuters-Science Watch website placed the Max Planck Society as the second leading research organization worldwide following Harvard University, in terms of the impact of the produced research over science fields.
The Max Planck Society and its predecessor Kaiser Wilhelm Society hosted several renowned scientists in their fields, including Otto Hahn, Werner Heisenberg, and Albert Einstein, to name a few."
Mechanical engineering	"Mechanical engineering is the discipline that applies the principles of engineering, physics, and materials science for the design, analysis, manufacturing, and maintenance of mechanical systems. It is the branch of engineering that involves the design, production, and operation of machinery. It is one of the oldest and broadest of the engineering disciplines.
The engineering field requires an understanding of core concepts including mechanics, kinematics, thermodynamics, materials science, structural analysis, and electricity. Mechanical engineers use these core principles along with tools like computer-aided design, and product lifecycle management to design and analyze manufacturing plants, industrial equipment and machinery, heating and cooling systems, transport systems, aircraft, watercraft, robotics, medical devices, weapons, and others.
Mechanical engineering emerged as a field during the industrial revolution in Europe in the 18th century; however, its development can be traced back several thousand years around the world. Mechanical engineering science emerged in the 19th century as a result of developments in the field of physics. The field has continually evolved to incorporate advancements in technology, and mechanical engineers today are pursuing developments in such fields as composites, mechatronics, and nanotechnology. Mechanical engineering overlaps with aerospace engineering, metallurgical engineering, civil engineering, electrical engineering, manufacturing engineering, chemical engineering, industrial engineering, and other engineering disciplines to varying amounts. Mechanical engineers may also work in the field of biomedical engineering, specifically with biomechanics, transport phenomena, biomechatronics, bionanotechnology, and modeling of biological systems."
Medical imaging	"Medical imaging is the technique and process of creating visual representations of the interior of a body for clinical analysis and medical intervention, as well as visual representation of the function of some organs or tissues (physiology). Medical imaging seeks to reveal internal structures hidden by the skin and bones, as well as to diagnose and treat disease. Medical imaging also establishes a database of normal anatomy and physiology to make it possible to identify abnormalities. Although imaging of removed organs and tissues can be performed for medical reasons, such procedures are usually considered part of pathology instead of medical imaging.
As a discipline and in its widest sense, it is part of biological imaging and incorporates radiology which uses the imaging technologies of X-ray radiography, magnetic resonance imaging, medical ultrasonography or ultrasound, endoscopy, elastography, tactile imaging, thermography, medical photography and nuclear medicine functional imaging techniques as positron emission tomography (PET) and Single-photon emission computed tomography (SPECT).
Measurement and recording techniques which are not primarily designed to produce images, such as electroencephalography (EEG), magnetoencephalography (MEG), electrocardiography (ECG), and others represent other technologies which produce data susceptible to representation as a parameter graph vs. time or maps which contain data about the measurement locations. In a limited comparison these technologies can be considered as forms of medical imaging in another discipline.
Up until 2010, 5 billion medical imaging studies had been conducted worldwide. Radiation exposure from medical imaging in 2006 made up about 50% of total ionizing radiation exposure in the United States.
In the clinical context, ""invisible light"" medical imaging is generally equated to radiology or ""clinical imaging"" and the medical practitioner responsible for interpreting (and sometimes acquiring) the images is a radiologist. ""Visible light"" medical imaging involves digital video or still pictures that can be seen without special equipment. Dermatology and wound care are two modalities that use visible light imagery. Diagnostic radiography designates the technical aspects of medical imaging and in particular the acquisition of medical images. The radiographer or radiologic technologist is usually responsible for acquiring medical images of diagnostic quality, although some radiological interventions are performed by radiologists.
As a field of scientific investigation, medical imaging constitutes a sub-discipline of biomedical engineering, medical physics or medicine depending on the context: Research and development in the area of instrumentation, image acquisition (e.g. radiography), modeling and quantification are usually the preserve of biomedical engineering, medical physics, and computer science; Research into the application and interpretation of medical images is usually the preserve of radiology and the medical sub-discipline relevant to medical condition or area of medical science (neuroscience, cardiology, psychiatry, psychology, etc.) under investigation. Many of the techniques developed for medical imaging also have scientific and industrial applications.
Medical imaging is often perceived to designate the set of techniques that noninvasively produce images of the internal aspect of the body. In this restricted sense, medical imaging can be seen as the solution of mathematical inverse problems. This means that cause (the properties of living tissue) is inferred from effect (the observed signal). In the case of medical ultrasonography, the probe consists of ultrasonic pressure waves and echoes that go inside the tissue to show the internal structure. In the case of projectional radiography, the probe uses X-ray radiation, which is absorbed at different rates by different tissue types such as bone, muscle and fat.
The term noninvasive is used to denote a procedure where no instrument is introduced into a patient's body which is the case for most imaging techniques used."
Medical research	"Biomedical research (or experimental medicine) is in general simply known as medical research. It is the basic research, applied research, or translational research conducted to aid and support the development body of knowledge in the field of medicine.
An important kind of medical research is clinical research, which is distinguished by the involvement of patients. Other kinds of medical research include pre-clinical research, for example on animals, and basic medical research, for example in genetics.
Both clinical and pre-clinical research phases exist in the pharmaceutical industry's drug pipelines, where the clinical phase is denoted by the term clinical trial. However, only part of the whole of clinical or pre-clinical research is oriented towards a specific pharmaceutical purpose. The need for understanding, diagnostics, medical devices and non-pharmaceutical therapies means that medical research is much bigger than just trying to make new drugs.
The most basic medical research is a rapidly evolving area that owes much to basic biology and is given names such as Human Biosciences by universities.
A new paradigm to biomedical research is being termed translational research, which focuses on iterative feedback loops between the basic and clinical research domains to accelerate knowledge translation from the bedside to the bench, and back again. Medical research may involve doing research into public health, biochemistry, clinical research, microbiology, physiology, oncology, surgery and research into many other non-communicable diseases such as diabetes and cardiovascular diseases.
The increased longevity of humans over the past century can be significantly attributed to advances resulting from medical research. Among the major benefits of medical research have been vaccines for measles and polio, insulin treatment for diabetes, classes of antibiotics for treating a host of maladies, medication for high blood pressure, improved treatments for AIDS, statins and other treatments for atherosclerosis, new surgical techniques such as microsurgery, and increasingly successful treatments for cancer. New, beneficial tests and treatments are expected as a result of the Human Genome Project. Many challenges remain, however, including the appearance of antibiotic resistance and the obesity epidemic.
Most of the research in the field is pursued by biomedical scientists, however significant contributions are made by other biologists, as well as chemists and physicists. Medical research, done on humans, has to strictly follow the medical ethics as sanctioned in the Declaration of Helsinki and elsewhere. In all cases, the research ethics has to be respected."
Medicine	"Medicine (British English /ˈmɛdsᵻn/; American English /ˈmɛdᵻsᵻn/) is the science and practice of the diagnosis, treatment, and prevention of disease. The word medicine is derived from Latin medicus, meaning ""a physician"". Medicine encompasses a variety of health care practices evolved to maintain and restore health by the prevention and treatment of illness. Contemporary medicine applies biomedical sciences, biomedical research, genetics, and medical technology to diagnose, treat, and prevent injury and disease, typically through pharmaceuticals or surgery, but also through therapies as diverse as psychotherapy, external splints and traction, medical devices, biologics, and ionizing radiation, amongst others.
Medicine has existed for thousands of years, during most of which it was an art (an area of skill and knowledge) frequently having connections to the religious and philosophical beliefs of local culture. For example, a medicine man would apply herbs and say prayers for healing, or an ancient philosopher and physician would apply bloodletting according to the theories of humorism. In recent centuries, since the advent of science, most medicine has become a combination of art and science (both basic and applied, under the umbrella of medical science). While stitching technique for sutures is an art learned through practice, the knowledge of what happens at the cellular and molecular level in the tissues being stitched arises through science.
Prescientific forms of medicine are now known as traditional medicine and folk medicine. They remain commonly used with or instead of scientific medicine and are thus called alternative medicine. For example, evidence on the effectiveness of acupuncture is ""variable and inconsistent"" for any condition, but is generally safe when done by an appropriately trained practitioner. In contrast, treatments outside the bounds of safety and efficacy are termed quackery."
Mercury (planet)	"Mercury is the smallest planet in the Solar System and the one closest to the Sun, with an orbital period of about 88 Earth days, which is much faster than any other planet in the Solar System. Seen from Earth, it appears to move around its orbit in about 116 days. It has no known natural satellites. It is named after the Roman deity Mercury, the messenger to the gods.
Partly because it has almost no atmosphere to retain heat, Mercury's surface temperature varies diurnally more than any other planet in the Solar System, ranging from 100 K (−173 °C; −280 °F) at night to 700 K (427 °C; 800 °F) during the day in some equatorial regions. The poles are constantly below 180 K (−93 °C; −136 °F). Mercury's axis has the smallest tilt of any of the Solar System's planets (about 1⁄30 of a degree). However, Mercury's orbital eccentricity is the largest of all known planets in the Solar System. At aphelion, Mercury is about 1.5 times as far from the Sun as it is at perihelion. Mercury's surface is heavily cratered and similar in appearance to the Moon, indicating that it has been geologically inactive for billions of years.
Mercury is tidally or gravitationally locked with the Sun in a 3:2 resonance, and rotates in a way that is unique in the Solar System. As seen relative to the fixed stars, it rotates on its axis exactly three times for every two revolutions it makes around the Sun. As seen from the Sun, in a frame of reference that rotates with the orbital motion, it appears to rotate only once every two Mercurian years. An observer on Mercury would therefore see only one day every two years.
Because Mercury orbits the Sun within Earth's orbit (as does Venus), it can appear in Earth's sky in the morning or the evening, but not in the middle of the night. Also, like Venus and the Moon, it displays a complete range of phases as it moves around its orbit relative to Earth. Although Mercury can appear as a bright object when viewed from Earth, its proximity to the Sun makes it more difficult to see than Venus. Two spacecraft have visited Mercury: Mariner 10 flew by in the 1970s; and MESSENGER, launched in 2004, orbited Mercury over 4,000 times in four years, before exhausting its fuel and crashing into the planet's surface on April 30, 2015."
Mesoamerica	"Mesoamerica is a region and cultural area in the Americas, extending approximately from central Mexico to Belize, Guatemala, El Salvador, Honduras, Nicaragua, and northern Costa Rica, within which pre-Columbian societies flourished before the Spanish colonization of the Americas in the 15th and 16th centuries. It is one of six areas in the world where ancient civilization arose independently, and the second in the Americas along with Norte Chico (Caral-Supe) in present-day northern coastal Peru.
As a cultural area, Mesoamerica is defined by a mosaic of cultural traits developed and shared by its indigenous cultures. Beginning as early as 7000 BC, the domestication of cacao, maize, beans, tomato, squash and chili, as well as the turkey and dog, caused a transition from paleo-Indian hunter-gatherer tribal grouping to the organization of sedentary agricultural villages. In the subsequent Formative period, agriculture and cultural traits such as a complex mythological and religious tradition, a vigesimal numeric system, and a complex calendric system, a tradition of ball playing, and a distinct architectural style, were diffused through the area. Also in this period, villages began to become socially stratified and develop into chiefdoms with the development of large ceremonial centers, interconnected by a network of trade routes for the exchange of luxury goods, such as obsidian, jade, cacao, cinnabar, Spondylus shells, hematite, and ceramics. While Mesoamerican civilization did know of the wheel and basic metallurgy, neither of these technologies became culturally important.
Among the earliest complex civilizations was the Olmec culture, which inhabited the Gulf coast of Mexico and extended inland and southwards across the Isthmus of Tehuantepec. Frequent contact and cultural interchange between the early Olmec and other cultures in Chiapas, Guatemala and Oaxaca laid the basis for the Mesoamerican cultural area. All this was facilitated by considerable regional communications in ancient Mesoamerica, especially along the Pacific coast.
This Formative period saw the spread of distinct religious and symbolic traditions, as well as artistic and architectural complexes. In the subsequent Preclassic period, complex urban polities began to develop among the Maya, with the rise of centers such as El Mirador, Calakmul and Tikal, and the Zapotec at Monte Albán. During this period, the first true Mesoamerican writing systems were developed in the Epi-Olmec and the Zapotec cultures, and the Mesoamerican writing tradition reached its height in the Classic Maya hieroglyphic script.
Mesoamerica is one of only five regions of the world where writing was independently developed. In Central Mexico, the height of the Classic period saw the ascendancy of the city of Teotihuacan, which formed a military and commercial empire whose political influence stretched south into the Maya area and northward. Upon the collapse of Teotihuacán around AD 600, competition between several important political centers in central Mexico, such as Xochicalco and Cholula, ensued. At this time during the Epi-Classic period, the Nahua peoples began moving south into Mesoamerica from the North, and became politically and culturally dominant in central Mexico, as they displaced speakers of Oto-Manguean languages. During the early post-Classic period, Central Mexico was dominated by the Toltec culture, Oaxaca by the Mixtec, and the lowland Maya area had important centers at Chichén Itzá and Mayapán. Towards the end of the post-Classic period, the Aztecs of Central Mexico built a tributary empire covering most of central Mesoamerica.
The distinct Mesoamerican cultural tradition ended with the Spanish conquest in the 16th century. Over the next centuries, Mesoamerican indigenous cultures were gradually subjected to Spanish colonial rule. Aspects of the Mesoamerican cultural heritage still survive among the indigenous peoples who inhabit Mesoamerica, many of whom continue to speak their ancestral languages, and maintain many practices harking back to their Mesoamerican roots."
Meteorology	"Not to be confused with Metrology. For other uses of the root word ""meteor"", see Meteor (disambiguation). For the work by Aristotle, see Meteorology (Aristotle).
Meteorology is the interdisciplinary scientific study of the atmosphere. The study of meteorology dates back millennia, though significant progress in meteorology did not occur until the 18th century. The 19th century saw modest progress in the field after weather observation networks were formed across broad regions. Prior attempts at prediction of weather depended on historical data. It wasn't until after the elucidation of the laws of physics and, more particularly, the development of the computer, allowing for the automated solution of the great many equations that model the weather, in the latter half of the 20th century that significant breakthroughs in weather forecasting were achieved.
Meteorological phenomena are observable weather events that are explained by the science of meteorology. Meteorological phenomena are described and quantified by the variables of Earth's atmosphere: temperature, air pressure, water vapor, mass flow, and the variations and interactions of those, and how they change over time. Different spatial scales are used to describe and predict weather on local, regional, and global levels.
Meteorology, climatology, atmospheric physics, and atmospheric chemistry are sub-disciplines of the atmospheric sciences. Meteorology and hydrology compose the interdisciplinary field of hydrometeorology. The interactions between Earth's atmosphere and its oceans are part of a coupled ocean-atmosphere system. Meteorology has application in many diverse fields such as the military, energy production, transport, agriculture, and construction.
The word ""meteorology"" is from Greek μετέωρος metéōros ""lofty; high (in the sky)"" (from μετα- meta- ""above"" and ἀείρω aeiro ""I lift up"") and -λογία -logia ""-(o)logy"", i.e. ""the study of things in the air""."
Methodological naturalism	"In philosophy, naturalism is the ""idea or belief that only natural (as opposed to supernatural or spiritual) laws and forces operate in the world."" Adherents of naturalism (i.e., naturalists) assert that natural laws are the rules that govern the structure and behavior of the natural universe, that the changing universe at every stage is a product of these laws.
""Naturalism can intuitively be separated into an ontological and a methodological component."" ""Ontological"" refers to the philosophical study of the nature of reality. Some philosophers equate naturalism with materialism. For example, philosopher Paul Kurtz argues that nature is best accounted for by reference to material principles. These principles include mass, energy, and other physical and chemical properties accepted by the scientific community. Further, this sense of naturalism holds that spirits, deities, and ghosts are not real and that there is no ""purpose"" in nature. Such an absolute belief in naturalism is commonly referred to as metaphysical naturalism.
Assuming naturalism in working methods is the current paradigm, without the unfounded consideration of naturalism as an absolute truth with philosophical entailment, called methodological naturalism. The subject matter here is a philosophy of acquiring knowledge based on an assumed paradigm.
With the exception of pantheists—who believe that Nature and God are one and the same thing—theists challenge the idea that nature contains all of reality. According to some theists, natural laws may be viewed as so-called secondary causes of god(s).
In the 20th century, Willard Van Orman Quine, George Santayana, and other philosophers argued that the success of naturalism in science meant that scientific methods should also be used in philosophy. Science and philosophy are said to form a continuum, according to this view."
Michael Faraday	"Michael Faraday /ˈfæ.rəˌdeɪ/ FRS (22 September 1791 – 25 August 1867) was an English scientist who contributed to the fields of electromagnetism and electrochemistry. His main discoveries include those of electromagnetic induction, diamagnetism and electrolysis.
Although Faraday received little formal education, he was one of the most influential scientists in history. It was by his research on the magnetic field around a conductor carrying a direct current that Faraday established the basis for the concept of the electromagnetic field in physics. Faraday also established that magnetism could affect rays of light and that there was an underlying relationship between the two phenomena. He similarly discovered the principle of electromagnetic induction, diamagnetism, and the laws of electrolysis. His inventions of electromagnetic rotary devices formed the foundation of electric motor technology, and it was largely due to his efforts that electricity became practical for use in technology.
As a chemist, Faraday discovered benzene, investigated the clathrate hydrate of chlorine, invented an early form of the Bunsen burner and the system of oxidation numbers, and popularised terminology such as anode, cathode, electrode, and ion. Faraday ultimately became the first and foremost Fullerian Professor of Chemistry at the Royal Institution of Great Britain, a lifetime position.
Faraday was an excellent experimentalist who conveyed his ideas in clear and simple language; his mathematical abilities, however, did not extend as far as trigonometry or any but the simplest algebra. James Clerk Maxwell took the work of Faraday and others, and summarized it in a set of equations that is accepted as the basis of all modern theories of electromagnetic phenomena. On Faraday's uses of the lines of force, Maxwell wrote that they show Faraday ""to have been in reality a mathematician of a very high order – one from whom the mathematicians of the future may derive valuable and fertile methods."" The SI unit of capacitance is named in his honour: the farad.
Albert Einstein kept a picture of Faraday on his study wall, alongside pictures of Isaac Newton and James Clerk Maxwell. Physicist Ernest Rutherford stated; ""When we consider the magnitude and extent of his discoveries and their influence on the progress of science and of industry, there is no honour too great to pay to the memory of Faraday, one of the greatest scientific discoverers of all time""."
Microwave	"Microwaves are a form of electromagnetic radiation with wavelengths ranging from one meter to one millimeter; with frequencies between 300 MHz (100 cm) and 300 GHz (0.1 cm). This broad definition includes both UHF and EHF (millimeter waves), and various sources use different boundaries. In all cases, microwave includes the entire SHF band (3 to 30 GHz, or 10 to 1 cm) at minimum, with RF engineering often restricting the range between 1 and 100 GHz (300 and 3 mm).
The prefix micro- in microwave is not meant to suggest a wavelength in the micrometer range. It indicates that microwaves are ""small"", compared to waves used in typical radio broadcasting, in that they have shorter wavelengths. The boundaries between far infrared, terahertz radiation, microwaves, and ultra-high-frequency radio waves are fairly arbitrary and are used variously between different fields of study.
Beginning at about 40 GHz, the atmosphere becomes less transparent to microwaves, at lower frequencies to absorption from water vapor and at higher frequencies from oxygen. A spectral band structure causes absorption peaks at specific frequencies (see graph at right). Above 100 GHz, the absorption of electromagnetic radiation by Earth's atmosphere is so great that it is in effect opaque, until the atmosphere becomes transparent again in the so-called infrared and optical window frequency ranges.
The term microwave also has a more technical meaning in electromagnetics and circuit theory. Apparatus and techniques may be described qualitatively as ""microwave"" when the frequencies used are high enough that wavelengths of signals are roughly the same as the dimensions of the equipment, so that lumped-element circuit theory is inaccurate. As a consequence, practical microwave technique tends to move away from the discrete resistors, capacitors, and inductors used with lower-frequency radio waves. Instead, distributed circuit elements and transmission-line theory are more useful methods for design and analysis. Open-wire and coaxial transmission lines used at lower frequencies are replaced by waveguides and stripline, and lumped-element tuned circuits are replaced by cavity resonators or resonant lines. In turn, at even higher frequencies, where the wavelength of the electromagnetic waves becomes small in comparison to the size of the structures used to process them, microwave techniques become inadequate, and the methods of optics are used."
Middle ages	"In the history of Europe, the Middle Ages or medieval period lasted from the 5th to the 15th century. It began with the fall of the Western Roman Empire and merged into the Renaissance and the Age of Discovery. The Middle Ages is the middle period of the three traditional divisions of Western history: classical antiquity, the medieval period, and the modern period. The Medieval period is itself subdivided into the Early, High, and Late Middle Ages.
Depopulation, deurbanization, invasion, and movement of peoples, which had begun in Late Antiquity, continued in the Early Middle Ages. The barbarian invaders, including various Germanic peoples, formed new kingdoms in what remained of the Western Roman Empire. In the 7th century, North Africa and the Middle East—once part of the Eastern Roman Empire—came under the rule of the Umayyad Caliphate, an Islamic empire, after conquest by Muhammad's successors. Although there were substantial changes in society and political structures, the break with Antiquity was not complete. The still-sizeable Byzantine Empire survived in the east and remained a major power. The empire's law code, the Corpus Juris Civilis or ""Code of Justinian"", was rediscovered in Northern Italy in 1070 and became widely admired later in the Middle Ages.
In the West, most kingdoms incorporated the few extant Roman institutions. Monasteries were founded as campaigns to Christianise pagan Europe continued. The Franks, under the Carolingian dynasty, briefly established the Carolingian Empire during the later 8th and early 9th century. It covered much of Western Europe but later succumbed to the pressures of internal civil wars combined with external invasions—Vikings from the north, Hungarians from the east, and Saracens from the south.
During the High Middle Ages, which began after 1000, the population of Europe increased greatly as technological and agricultural innovations allowed trade to flourish and the Medieval Warm Period climate change allowed crop yields to increase. Manorialism, the organisation of peasants into villages that owed rent and labour services to the nobles, and feudalism, the political structure whereby knights and lower-status nobles owed military service to their overlords in return for the right to rent from lands and manors, were two of the ways society was organised in the High Middle Ages.
The Crusades, first preached in 1095, were military attempts by Western European Christians to regain control of the Holy Land from Muslims. Kings became the heads of centralised nation states, reducing crime and violence but making the ideal of a unified Christendom more distant. Intellectual life was marked by scholasticism, a philosophy that emphasised joining faith to reason, and by the founding of universities. The theology of Thomas Aquinas, the paintings of Giotto, the poetry of Dante and Chaucer, the travels of Marco Polo, and the Gothic architecture of cathedrals such as Chartres are among the outstanding achievements toward the end of this period and into the Late Middle Ages.
The Late Middle Ages was marked by difficulties and calamities including famine, plague, and war, which significantly diminished the population of Europe; between 1347 and 1350, the Black Death killed about a third of Europeans. Controversy, heresy, and the Western Schism within the Catholic Church paralleled the interstate conflict, civil strife, and peasant revolts that occurred in the kingdoms. Cultural and technological developments transformed European society, concluding the Late Middle Ages and beginning the early modern period."
Modern science	"The history of science is the study of the development of science and scientific knowledge, including both the natural sciences and social sciences. (The history of the arts and humanities is termed as the history of scholarship.) Science is a body of empirical, theoretical, and practical knowledge about the natural world, produced by scientists who emphasize the observation, explanation, and prediction of real world phenomena. Historiography of science, in contrast, often draws on the historical methods of both intellectual history and social history.
The English word scientist is relatively recent—first coined by William Whewell in the 19th century. Previously, people investigating nature called themselves natural philosophers. While empirical investigations of the natural world have been described since classical antiquity (for example, by Thales, Aristotle, and others), and scientific methods have been employed since the Middle Ages (for example, by Ibn al-Haytham, and Roger Bacon), the dawn of modern science is often traced back to the early modern period and in particular to the scientific revolution that took place in 16th- and 17th-century Europe. Scientific methods are considered to be so fundamental to modern science that some consider earlier inquiries into nature to be pre-scientific. Traditionally, historians of science have defined science sufficiently broadly to include those inquiries.
From the 18th century through late 20th century, the history of science, especially of the physical and biological sciences, was often presented in a progressive narrative in which true theories replaced false beliefs. More recent historical interpretations, such as those of Thomas Kuhn, tend to portray the history of science in different terms, such as that of competing paradigms or conceptual systems in a wider matrix that includes intellectual, cultural, economic and political themes outside of science."
Molecule	"A molecule (/ˈmɒlɪkjuːl/) is an electrically neutral group of two or more atoms held together by chemical bonds. Molecules are distinguished from ions by their lack of electrical charge. However, in quantum physics, organic chemistry, and biochemistry, the term molecule is often used less strictly, also being applied to polyatomic ions.
In the kinetic theory of gases, the term molecule is often used for any gaseous particle regardless of its composition. According to this definition, noble gas atoms are considered molecules as they are in fact monoatomic molecules.
A molecule may be homonuclear, that is, it consists of atoms of a single chemical element, as with oxygen (O2); or it may be heteronuclear, a chemical compound composed of more than one element, as with water (H2O). Atoms and complexes connected by non-covalent bonds such as hydrogen bonds or ionic bonds are generally not considered single molecules.
Molecules as components of matter are common in organic substances (and therefore biochemistry). They also make up most of the oceans and atmosphere. However, the majority of familiar solid substances on Earth, including most of the minerals that make up the crust, mantle, and core of the Earth, contain many chemical bonds, but are not made of identifiable molecules. Also, no typical molecule can be defined for ionic crystals (salts) and covalent crystals (network solids), although these are often composed of repeating unit cells that extend either in a plane (such as in graphene) or three-dimensionally (such as in diamond, quartz, or sodium chloride). The theme of repeated unit-cellular-structure also holds for most condensed phases with metallic bonding, which means that solid metals are also not made of molecules. In glasses (solids that exist in a vitreous disordered state), atoms may also be held together by chemical bonds without presence of any definable molecule, but also without any of the regularity of repeating units that characterizes crystals."
Natural science	"Natural science is a branch of science concerned with the description, prediction, and understanding of natural phenomena, based on observational and empirical evidence. Validity, accuracy, and social mechanisms ensuring quality control, such as peer review and repeatability of findings, are amongst the criteria and methods used for this purpose.
Natural science can be broken into two main branches: life science (or biological science) and physical science. Physical science is further broken down into branches, including physics, astronomy, chemistry, and Earth science. All of these branches of natural science are divided into many further specialized branches (also known as fields), and each of these is known as a ""natural science"".
In Western society's analytic tradition, the empirical and especially natural sciences use tools from formal sciences, such as mathematics and logic, converting information about nature into measurements which can be explained as clear statements about the ""laws of nature"". The social sciences also use such methods, but rely more on qualitative research, so that they are sometimes called ""soft science"", whereas natural sciences, insofar as emphasizing quantifiable data produced, tested, and confirmed through the scientific method are sometimes called ""hard science"".
Modern natural science succeeded more classical approaches to natural philosophy, usually traced to ancient Greece. Galileo, Descartes, Francis Bacon, and Newton debated the benefits of using approaches which were more mathematical and more experimental in a methodical way. Still, philosophical perspectives, conjectures, and presuppositions, often overlooked, remain requisite in natural science. Systematic data collection, including discovery science, succeed natural history, which emerged in the 16th century by describing and classifying plants, animals, minerals, and so on. Yet today, natural history suggests observational descriptions aimed at popular audiences."
Natural selection	"Natural selection is the differential survival and reproduction of individuals due to differences in phenotype. It is a key mechanism of evolution, the change in heritable traits of a population over time. Charles Darwin popularised the term ""natural selection""; he compared it with artificial selection (selective breeding).
Variation exists within all populations of organisms. This occurs partly because random mutations arise in the genome of an individual organism, and offspring can inherit such mutations. Throughout the lives of the individuals, their genomes interact with their environments to cause variations in traits. (The environment of a genome includes the molecular biology in the cell, other cells, other individuals, populations, species, as well as the abiotic environment.) Individuals with certain variants of the trait may survive and reproduce more than individuals with other, less successful, variants. Therefore, the population evolves. Factors that affect reproductive success are also important, an issue that Darwin developed in his ideas on sexual selection (which was redefined as being included in natural selection in the 1930s when biologists considered it relatively unimportant,) and on fecundity selection, for example.
Natural selection acts on the phenotype, or the observable characteristics of an organism, but the genetic (heritable) basis of any phenotype that gives a reproductive advantage may become more common in a population (see allele frequency). Over time, this process can result in populations that specialise for particular ecological niches (microevolution) and may eventually result in the emergence of new species (macroevolution). In other words, natural selection is an important process (though not the only process) by which evolution takes place within a population of organisms. Natural selection can be contrasted with artificial selection, in which humans intentionally choose specific traits (although they may not always get what they want). In natural selection there is no intentional choice. In other words, artificial selection is teleological and natural selection is not teleological.
Natural selection is one of the cornerstones of modern biology. The concept, published by Darwin and Alfred Russel Wallace in a joint presentation of papers in 1858, was elaborated in Darwin's influential 1859 book On the Origin of Species, which described natural selection as analogous to artificial selection, a process by which animals and plants with traits considered desirable by human breeders are systematically favoured for reproduction. The concept of natural selection originally developed in the absence of a valid theory of heredity; at the time of Darwin's writing, science had yet to develop modern theories of genetics. The union of traditional Darwinian evolution with subsequent discoveries in classical and molecular genetics is termed the modern evolutionary synthesis. Natural selection remains the primary explanation for adaptive evolution."
Nature	"Nature, in the broadest sense, is the natural, physical, or material world or universe. ""Nature"" can refer to the phenomena of the physical world, and also to life in general. The study of nature is a large part of science. Although humans are part of nature, human activity is often understood as a separate category from other natural phenomena.
The word nature is derived from the Latin word natura, or ""essential qualities, innate disposition"", and in ancient times, literally meant ""birth"". Natura is a Latin translation of the Greek word physis (φύσις), which originally related to the intrinsic characteristics that plants, animals, and other features of the world develop of their own accord. The concept of nature as a whole, the physical universe, is one of several expansions of the original notion; it began with certain core applications of the word φύσις by pre-Socratic philosophers, and has steadily gained currency ever since. This usage continued during the advent of modern scientific method in the last several centuries.
Within the various uses of the word today, ""nature"" often refers to geology and wildlife. Nature can refer to the general realm of living plants and animals, and in some cases to the processes associated with inanimate objects – the way that particular types of things exist and change of their own accord, such as the weather and geology of the Earth. It is often taken to mean the ""natural environment"" or wilderness–wild animals, rocks, forest, and in general those things that have not been substantially altered by human intervention, or which persist despite human intervention. For example, manufactured objects and human interaction generally are not considered part of nature, unless qualified as, for example, ""human nature"" or ""the whole of nature"". This more traditional concept of natural things which can still be found today implies a distinction between the natural and the artificial, with the artificial being understood as that which has been brought into being by a human consciousness or a human mind. Depending on the particular context, the term ""natural"" might also be distinguished from the unnatural or the supernatural."
Newtonian physics	"In physics, classical mechanics and quantum mechanics are the two major sub-fields of mechanics. Classical mechanics is concerned with the set of physical laws describing the motion of bodies under the influence of a system of forces. The study of the motion of bodies is an ancient one, making classical mechanics one of the oldest and largest subjects in science, engineering and technology. It is also widely known as Newtonian mechanics.
Classical mechanics describes the motion of macroscopic objects, from projectiles to parts of machinery, as well as astronomical objects, such as spacecraft, planets, stars, and galaxies. Within classical mechanics are fields of study that describe the behavior of solids, liquids and gases and other specific sub-topics. Classical mechanics also provides extremely accurate results as long as the domain of study is restricted to large objects and the speeds involved do not approach the speed of light. When the objects being examined are sufficiently small, it becomes necessary to introduce the other major sub-field of mechanics, quantum mechanics, which adjusts the laws of physics of macroscopic objects for the atomic nature of matter by including the wave–particle duality of atoms and molecules. When both quantum mechanics and classical mechanics cannot apply, such as at the quantum level with high speeds, quantum field theory (QFT) becomes applicable.
The term classical mechanics was coined in the early 20th century to describe the system of physics begun by Isaac Newton and many contemporary 17th century natural philosophers, and is built upon the earlier astronomical theories of Johannes Kepler, which in turn were based on the precise observations of Tycho Brahe and the studies of terrestrial projectile motion of Galileo. Since these aspects of physics were developed long before the emergence of quantum physics and relativity, some sources exclude Einstein's theory of relativity from this category. However, a number of modern sources do include relativistic mechanics, which in their view represents classical mechanics in its most developed and most accurate form.
The earliest development of classical mechanics is often referred to as Newtonian mechanics, and is associated with the physical concepts employed by and the mathematical methods invented by Newton, Leibniz, and others. Later, more abstract and general methods were developed, leading to reformulations of classical mechanics known as Lagrangian mechanics and Hamiltonian mechanics. These advances were largely made in the 18th and 19th centuries, and they extend substantially beyond Newton's work, particularly through their use of analytical mechanics."
Nobel Prize	"The Nobel Prize (/ˈnoʊbɛl/, Swedish pronunciation: [nʊˈbɛl]; Swedish definite form, singular: Nobelpriset; Norwegian: Nobelprisen) is a set of annual international awards bestowed in a number of categories by Swedish and Norwegian committees in recognition of academic, cultural and/or scientific advances.
The will of the Swedish inventor Alfred Nobel established the prizes in 1895. The prizes in Chemistry, Literature, Peace, Physics, and Physiology or Medicine were first awarded in 1901. The related Nobel Memorial Prize in Economic Sciences was established by Sweden's central bank in 1968. Medals made before 1980 were struck in 23 carat gold, and later from 18 carat green gold plated with a 24 carat gold coating. Between 1901 and 2015, the Nobel Prizes and the Prize in Economic Sciences were awarded 573 times to 900 people and organizations. With some receiving the Nobel Prize more than once, this makes a total of 870 individuals (822 men and 48 women) and 23 organizations.
The prize ceremonies take place annually in Stockholm, Sweden, except for the peace prize which is held in Oslo, Norway and each recipient, or laureate, receives a gold medal, a diploma and a sum of money that has been decided by the Nobel Foundation. (As of 2012, each prize was worth SEK8 million or about US$1.2 million, €0.93 million or £0.6 million.) The Nobel Prize is widely regarded as the most prestigious award available in the fields of literature, medicine, physics, chemistry, peace, and economics.
The Royal Swedish Academy of Sciences awards the Nobel Prize in Physics, the Nobel Prize in Chemistry, and the Nobel Memorial Prize in Economic Sciences; the Nobel Assembly at Karolinska Institutet awards the Nobel Prize in Physiology or Medicine; the Swedish Academy grants the Nobel Prize in Literature; and the Nobel Peace Prize is awarded not by a Swedish organisation but by the Norwegian Nobel Committee.
The prize is not awarded posthumously; however, if a person is awarded a prize and dies before receiving it, the prize may still be presented. Though the average number of laureates per prize increased substantially during the 20th century, a prize may not be shared among more than three people."
Nuclear chemistry	"Nuclear chemistry is the subfield of chemistry dealing with radioactivity, nuclear processes, such as nuclear transmutation, and nuclear properties.
It is the chemistry of radioactive elements such as the actinides, radium and radon together with the chemistry associated with equipment (such as nuclear reactors) which are designed to perform nuclear processes. This includes the corrosion of surfaces and the behavior under conditions of both normal and abnormal operation (such as during an accident). An important area is the behavior of objects and materials after being placed into a nuclear waste storage or disposal site.
It includes the study of the chemical effects resulting from the absorption of radiation within living animals, plants, and other materials. The radiation chemistry controls much of radiation biology as radiation has an effect on living things at the molecular scale, to explain it another way the radiation alters the biochemicals within an organism, the alteration of the biomolecules then changes the chemistry which occurs within the organism, this change in chemistry then can lead to a biological outcome. As a result, nuclear chemistry greatly assists the understanding of medical treatments (such as cancer radiotherapy) and has enabled these treatments to improve.
It includes the study of the production and use of radioactive sources for a range of processes. These include radiotherapy in medical applications; the use of radioactive tracers within industry, science and the environment; and the use of radiation to modify materials such as polymers.
It also includes the study and use of nuclear processes in non-radioactive areas of human activity. For instance, nuclear magnetic resonance (NMR) spectroscopy is commonly used in synthetic organic chemistry and physical chemistry and for structural analysis in macromolecular chemistry."
Nuclear fusion	"In nuclear physics, nuclear fusion is a nuclear reaction in which two or more atomic nuclei come very close and then collide at a very high speed and join to form a new nucleus. During this process, matter is not conserved because some of the matter of the fusing nuclei is converted to photons (energy). Fusion is the process that powers active or ""main sequence"" stars, or other high magnitude stars.
The fusion of two nuclei with lower masses than iron-56 (which, along with nickel-62, has the largest binding energy per nucleon) generally releases energy, while the fusion of nuclei heavier than iron absorbs energy. The opposite is true for the reverse process, nuclear fission. This means that generally only lighter elements are fusable, such as hydrogen and helium, and likewise, that generally only heavier elements are fissionable, such as uranium and plutonium. There are extreme astrophysical events that can lead to short periods of fusion with heavier nuclei. This is the process that gives rise to nucleosynthesis, the creation of the heavy elements during events such as a supernova.
Following the discovery of quantum tunneling by physicist Friedrich Hund, in 1929 Robert Atkinson and Fritz Houtermans used the measured masses of light elements to predict that large amounts of energy could be released by fusing small nuclei. Building upon the nuclear transmutation experiments by Ernest Rutherford, carried out several years earlier, the laboratory fusion of hydrogen isotopes was first accomplished by Mark Oliphant in 1932. During the remainder of that decade the steps of the main cycle of nuclear fusion in stars were worked out by Hans Bethe. Research into fusion for military purposes began in the early 1940s as part of the Manhattan Project. Fusion was accomplished in 1951 with the Greenhouse Item nuclear test. Nuclear fusion on a large scale in an explosion was first carried out on November 1, 1952, in the Ivy Mike hydrogen bomb test.
Research into developing controlled thermonuclear fusion for civil purposes also began in earnest in the 1950s, and it continues to this day."
Nuclear magnetic resonance	"Nuclear magnetic resonance (NMR) is a physical phenomenon in which nuclei in a magnetic field absorb and re-emit electromagnetic radiation. This energy is at a specific resonance frequency which depends on the strength of the magnetic field and the magnetic properties of the isotope of the atoms; in practical applications, the frequency is similar to VHF and UHF television broadcasts (60–1000 MHz). NMR allows the observation of specific quantum mechanical magnetic properties of the atomic nucleus. Many scientific techniques exploit NMR phenomena to study molecular physics, crystals, and non-crystalline materials through nuclear magnetic resonance spectroscopy. NMR is also routinely used in advanced medical imaging techniques, such as in magnetic resonance imaging (MRI).
All isotopes that contain an odd number of protons and/or of neutrons (see Isotope) have an intrinsic magnetic moment and angular momentum, in other words a nonzero spin, while all nuclides with even numbers of both have a total spin of zero. The most commonly studied nuclei are 1H and 13C, although nuclei from isotopes of many other elements (e.g. 2H, 6Li, 10B, 11B, 14N, 15N, 17O, 19F, 23Na, 29Si, 31P, 35Cl, 113Cd, 129Xe, 195Pt) have been studied by high-field NMR spectroscopy as well.
A key feature of NMR is that the resonance frequency of a particular substance is directly proportional to the strength of the applied magnetic field. It is this feature that is exploited in imaging techniques; if a sample is placed in a non-uniform magnetic field then the resonance frequencies of the sample's nuclei depend on where in the field they are located. Since the resolution of the imaging technique depends on the magnitude of magnetic field gradient, many efforts are made to develop increased field strength, often using superconductors. The effectiveness of NMR can also be improved using hyperpolarization, and/or using two-dimensional, three-dimensional and higher-dimensional multi-frequency techniques.
The principle of NMR usually involves two sequential steps:
The alignment (polarization) of the magnetic nuclear spins in an applied, constant magnetic field B0.
The perturbation of this alignment of the nuclear spins by employing an electro-magnetic, usually radio frequency (RF) pulse. The required perturbing frequency is dependent upon the static magnetic field (H0) and the nuclei of observation.
The two fields are usually chosen to be perpendicular to each other as this maximizes the NMR signal strength. The resulting response by the total magnetization (M) of the nuclear spins is the phenomenon that is exploited in NMR spectroscopy and magnetic resonance imaging. Both use intense applied magnetic fields (H0) in order to achieve dispersion and very high stability to deliver spectral resolution, the details of which are described by chemical shifts, the Zeeman effect, and Knight shifts (in metals).
NMR phenomena are also utilized in low-field NMR, NMR spectroscopy and MRI in the Earth's magnetic field (referred to as Earth's field NMR), and in several types of magnetometers."
Nuclear magnetic resonance spectroscopy	"Nuclear magnetic resonance spectroscopy, most commonly known as NMR spectroscopy, is a research technique that exploits the magnetic properties of certain atomic nuclei. It determines the physical and chemical properties of atoms or the molecules in which they are contained. It relies on the phenomenon of nuclear magnetic resonance and can provide detailed information about the structure, dynamics, reaction state, and chemical environment of molecules. The intramolecular magnetic field around an atom in a molecule changes the resonance frequency, thus giving access to details of the electronic structure of a molecule.
Most frequently, NMR spectroscopy is used by chemists and biochemists to investigate the properties of organic molecules, although it is applicable to any kind of sample that contains nuclei possessing spin. Suitable samples range from small compounds analyzed with 1-dimensional proton or carbon-13 NMR spectroscopy to large proteins or nucleic acids using 3 or 4-dimensional techniques. The impact of NMR spectroscopy on the sciences has been substantial because of the range of information and the diversity of samples, including solutions and solids.
NMR spectra are unique, well-resolved, analytically tractable and often highly predictable for small molecules. Thus, in organic chemistry practice, NMR analysis is used to confirm the identity of a substance. Different functional groups are obviously distinguishable, and identical functional groups with differing neighboring substituents still give distinguishable signals. NMR has largely replaced traditional wet chemistry tests such as color reagents for identification. A disadvantage is that a relatively large amount, 2–50 mg, of a purified substance is required, although it may be recovered. Preferably, the sample should be dissolved in a solvent, because NMR analysis of solids requires a dedicated MAS machine and may not give equally well-resolved spectra. The timescale of NMR is relatively long, and thus it is not suitable for observing fast phenomena, producing only an averaged spectrum. Although large amounts of impurities do show on an NMR spectrum, better methods exist for detecting impurities, as NMR is inherently not very sensitive.
NMR spectrometers are relatively expensive; universities usually have them, but they are less common in private companies. Modern NMR spectrometers have a very strong, large and expensive liquid helium-cooled superconducting magnet, because resolution directly depends on magnetic field strength. Less expensive machines using permanent magnets and lower resolution are also available, which still give sufficient performance for certain application such as reaction monitoring and quick checking of samples. There are even benchtop NMR spectrometers."
Nuclear power	"Nuclear power is the use of nuclear reactions that release nuclear energy to generate heat, which most frequently is then used in steam turbines to produce electricity in a nuclear power plant. The term includes nuclear fission, nuclear decay and nuclear fusion. Presently, the nuclear fission of elements in the actinide series of the periodic table produce the vast majority of nuclear energy in the direct service of humankind, with nuclear decay processes, primarily in the form of geothermal energy, and radioisotope thermoelectric generators, in niche uses making up the rest.
In 2011 nuclear power provided 10% of the world's electricity In 2007, the IAEA reported there were 439 nuclear power reactors in operation in the world, operating in 31 countries. In Japan many reactors ceased operation in the wake of the Fukushima nuclear disaster while they are assessed for safety. In 2011 worldwide nuclear output fell by 4.3%, the largest decline on record, on the back of sharp declines in Japan (-44.3%) and Germany (-23.2%).
Along with sustainable energy sources, nuclear fission power is a low carbon power generation method of producing electricity, meaning that it is in the renewable energy family of low associated greenhouse gas emissions per unit of energy generated. As all electricity supplying technologies use cement etc., during construction, emissions are yet to be brought to zero. A 2014 analysis of the carbon footprint literature by the Intergovernmental Panel on Climate Change (IPCC) reported that fission electricities embodied total life-cycle emission intensity value of 12 g CO2 eq/kWh is the lowest out of all commercial baseload energy sources, and second lowest out of all commercial electricity technologies known, after wind power which is an Intermittent energy source with embodied greenhouse gas emissions, per unit of energy generated of 11 g CO2eq/kWh. Each result is contrasted with coal & fossil gas at 820 and 490 g CO2 eq/kWh. With this translating into, from the beginning of Fission-electric power station commercialization in the 1970s, having prevented the emission of about 64 billion tonnes of carbon dioxide equivalent, greenhouse gases that would have otherwise resulted from the burning of fossil fuels in thermal power stations.
There is a social debate about nuclear power. Proponents, such as the World Nuclear Association and Environmentalists for Nuclear Energy, contend that nuclear power is a safe, sustainable energy source that reduces carbon emissions. Opponents, such as Greenpeace International and NIRS, contend that nuclear power poses many threats to people and the environment.
Far reaching fission power reactor accidents, or accidents that resulted in medium to long-lived fission product contamination of inhabited areas, have occurred in Generation I & II reactor designs, blueprinted between 1950 and 1980. These include the Chernobyl disaster which occurred in 1986, the Fukushima Daiichi nuclear disaster (2011), and the more contained Three Mile Island accident (1979). There have also been some nuclear submarine accidents. In terms of lives lost per unit of energy generated, analysis has determined that fission-electric reactors have caused less fatalities per unit of energy generated than the other major sources of energy generation. Energy production from coal, petroleum, natural gas and hydroelectricity has caused a greater number of fatalities per unit of energy generated due to air pollution and energy accident effects. However, the economic costs of nuclear power accidents is high, and meltdowns can render areas uninhabitable for very long periods. The human costs of evacuations of affected populations and lost livelihoods is also significant."
Nuclear weapon	"A nuclear weapon is an explosive device that derives its destructive force from nuclear reactions, either fission (fission bomb) or a combination of fission and fusion (thermonuclear weapon). Both reactions release vast quantities of energy from relatively small amounts of matter. The first fission (""atomic"") bomb test released the same amount of energy as approximately 20,000 tons of TNT (see Trinity (nuclear test)). The first thermonuclear (""hydrogen"") bomb test released the same amount of energy as approximately 10,000,000 tons of TNT.
A thermonuclear weapon weighing little more than 2,400 pounds (1,100 kg) can produce an explosive force comparable to the detonation of more than 1.2 million tons (1.1 million tonnes) of TNT. A nuclear device no larger than traditional bombs can devastate an entire city by blast, fire, and radiation. Nuclear weapons are considered weapons of mass destruction, and their use and control have been a major focus of international relations policy since their debut.
Nuclear weapons have been used twice in nuclear warfare, both times by the United States against Japan near the end of World War II. On August 6, 1945, the U.S. Army Air Forces detonated a uranium gun-type fission bomb over the Japanese city of Hiroshima; three days later, on August 9, the U.S. Army Air Forces detonated a plutonium implosion-type fission bomb codenamed ""Fat Man"" over the Japanese city of Nagasaki. The bombings resulted in the deaths of approximately 200,000 civilians and military personnel from acute injuries sustained from the explosions. The ethics of the bombings and their role in Japan's surrender remain the subject of scholarly and popular debate.
Since the atomic bombings of Hiroshima and Nagasaki, nuclear weapons have been detonated on over two thousand occasions for the purposes of testing and demonstration. Only a few nations possess such weapons or are suspected of seeking them. The only countries known to have detonated nuclear weapons—and acknowledge possessing them—are (chronologically by date of first test) the United States, the Soviet Union (succeeded as a nuclear power by Russia), the United Kingdom, France, the People's Republic of China, India, Pakistan, and North Korea. Israel is also believed to possess nuclear weapons, though in a policy of deliberate ambiguity, it does not acknowledge having them. Germany, Italy, Turkey, Belgium and the Netherlands are nuclear weapons sharing states.
The nuclear non-proliferation treaty aimed to reduce the spread of nuclear weapons, but its effectiveness has been questioned, and political tensions remained high in the 1970s and 1980s. As of 2016, there are still more than enough nuclear weapons globally to render the planet uninhabitable. 16,000 nuclear weapons are stored at sites in 14 countries and many are ready for immediate use. Modernisation of weapons continues to occur."
On the Origin of Species	"On the Origin of Species, published on 24 November 1859, is a work of scientific literature by Charles Darwin which is considered to be the foundation of evolutionary biology. Darwin's book introduced the scientific theory that populations evolve over the course of generations through a process of natural selection. It presented a body of evidence that the diversity of life arose by common descent through a branching pattern of evolution. Darwin included evidence that he had gathered on the Beagle expedition in the 1830s and his subsequent findings from research, correspondence, and experimentation.
Various evolutionary ideas had already been proposed to explain new findings in biology. There was growing support for such ideas among dissident anatomists and the general public, but during the first half of the 19th century the English scientific establishment was closely tied to the Church of England, while science was part of natural theology. Ideas about the transmutation of species were controversial as they conflicted with the beliefs that species were unchanging parts of a designed hierarchy and that humans were unique, unrelated to other animals. The political and theological implications were intensely debated, but transmutation was not accepted by the scientific mainstream.
The book was written for non-specialist readers and attracted widespread interest upon its publication. As Darwin was an eminent scientist, his findings were taken seriously and the evidence he presented generated scientific, philosophical, and religious discussion. The debate over the book contributed to the campaign by T. H. Huxley and his fellow members of the X Club to secularise science by promoting scientific naturalism. Within two decades there was widespread scientific agreement that evolution, with a branching pattern of common descent, had occurred, but scientists were slow to give natural selection the significance that Darwin thought appropriate. During ""the eclipse of Darwinism"" from the 1880s to the 1930s, various other mechanisms of evolution were given more credit. With the development of the modern evolutionary synthesis in the 1930s and 1940s, Darwin's concept of evolutionary adaptation through natural selection became central to modern evolutionary theory, and it has now become the unifying concept of the life sciences."
Optics	"Optics is the branch of physics which involves the behaviour and properties of light, including its interactions with matter and the construction of instruments that use or detect it. Optics usually describes the behaviour of visible, ultraviolet, and infrared light. Because light is an electromagnetic wave, other forms of electromagnetic radiation such as X-rays, microwaves, and radio waves exhibit similar properties.
Most optical phenomena can be accounted for using the classical electromagnetic description of light. Complete electromagnetic descriptions of light are, however, often difficult to apply in practice. Practical optics is usually done using simplified models. The most common of these, geometric optics, treats light as a collection of rays that travel in straight lines and bend when they pass through or reflect from surfaces. Physical optics is a more comprehensive model of light, which includes wave effects such as diffraction and interference that cannot be accounted for in geometric optics. Historically, the ray-based model of light was developed first, followed by the wave model of light. Progress in electromagnetic theory in the 19th century led to the discovery that light waves were in fact electromagnetic radiation.
Some phenomena depend on the fact that light has both wave-like and particle-like properties. Explanation of these effects requires quantum mechanics. When considering light's particle-like properties, the light is modelled as a collection of particles called ""photons"". Quantum optics deals with the application of quantum mechanics to optical systems.
Optical science is relevant to and studied in many related disciplines including astronomy, various engineering fields, photography, and medicine (particularly ophthalmology and optometry). Practical applications of optics are found in a variety of technologies and everyday objects, including mirrors, lenses, telescopes, microscopes, lasers, and fibre optics."
Organic chemistry	"Organic chemistry is a chemistry subdiscipline involving the scientific study of the structure, properties, and reactions of organic compounds and organic materials, i.e., matter in its various forms that contain carbon atoms. Study of structure includes many physical and chemical methods to determine the chemical composition and the chemical constitution of organic compounds and materials. Study of properties includes both physical properties and chemical properties, and uses similar methods as well as methods to evaluate chemical reactivity, with the aim to understand the behavior of the organic matter in its pure form (when possible), but also in solutions, mixtures, and fabricated forms. The study of organic reactions includes probing their scope through use in preparation of target compounds (e.g., natural products, drugs, polymers, etc.) by chemical synthesis, as well as the focused study of the reactivities of individual organic molecules, both in the laboratory and via theoretical (in silico) study.
The range of chemicals studied in organic chemistry include hydrocarbons (compounds containing only carbon and hydrogen), as well as myriad compositions based always on carbon, but also containing other elements, especially oxygen, nitrogen, sulfur, phosphorus (these, included in many organic chemicals in biology) and the radiostable elements of the halogens.
In the modern era, the range extends further into the periodic table, with main group elements, including:
Group 1 and 2 organometallic compounds, i.e., involving alkali (e.g., lithium, sodium, and potassium) or alkaline earth metals (e.g., magnesium)
Metalloids (e.g., boron and silicon) or other metals (e.g., aluminium and tin)
In addition, much modern research focuses on organic chemistry involving further organometallics, including the lanthanides, but especially the transition metals; (e.g., zinc, copper, palladium, nickel, cobalt, titanium and chromium)

Finally, organic compounds form the basis of all earthly life and constitute a significant part of human endeavors in chemistry. The bonding patterns open to carbon, with its valence of four—formal single, double, and triple bonds, as well as various structures with delocalized electrons—make the array of organic compounds structurally diverse, and their range of applications enormous. They either form the basis of, or are important constituents of, many commercial products including pharmaceuticals; petrochemicals and products made from them (including lubricants, solvents, etc.); plastics; fuels and explosives; etc. As indicated, the study of organic chemistry overlaps with organometallic chemistry and biochemistry, but also with medicinal chemistry, polymer chemistry, as well as many aspects of materials science."
Paleontology	"Paleontology or palaeontology (/ˌpeɪlɪɒnˈtɒlədʒi/, /ˌpeɪlɪənˈtɒlədʒi/ or /ˌpælɪɒnˈtɒlədʒi/, /ˌpælɪənˈtɒlədʒi/) is the scientific study of life existent prior to, and sometimes including, the start of the Holocene Epoch roughly 11,700 years before present. It includes the study of fossils to determine organisms' evolution and interactions with each other and their environments (their paleoecology). Paleontological observations have been documented as far back as the 5th century BC. The science became established in the 18th century as a result of Georges Cuvier's work on comparative anatomy, and developed rapidly in the 19th century. The term itself originates from Greek παλαιός, palaios, i.e. ""old, ancient"", ὄν, on (gen. ontos), i.e. ""being, creature"" and λόγος, logos, i.e. ""speech, thought, study"".
Paleontology lies on the border between biology and geology, but differs from archaeology in that it excludes the study of anatomically modern humans. It now uses techniques drawn from a wide range of sciences, including biochemistry, mathematics and engineering. Use of all these techniques has enabled paleontologists to discover much of the evolutionary history of life, almost all the way back to when Earth became capable of supporting life, about 3,800 million years ago. As knowledge has increased, paleontology has developed specialised sub-divisions, some of which focus on different types of fossil organisms while others study ecology and environmental history, such as ancient climates.
Body fossils and trace fossils are the principal types of evidence about ancient life, and geochemical evidence has helped to decipher the evolution of life before there were organisms large enough to leave body fossils. Estimating the dates of these remains is essential but difficult: sometimes adjacent rock layers allow radiometric dating, which provides absolute dates that are accurate to within 0.5%, but more often paleontologists have to rely on relative dating by solving the ""jigsaw puzzles"" of biostratigraphy. Classifying ancient organisms is also difficult, as many do not fit well into the Linnean taxonomy that is commonly used for classifying living organisms, and paleontologists more often use cladistics to draw up evolutionary ""family trees"". The final quarter of the 20th century saw the development of molecular phylogenetics, which investigates how closely organisms are related by measuring how similar the DNA is in their genomes. Molecular phylogenetics has also been used to estimate the dates when species diverged, but there is controversy about the reliability of the molecular clock on which such estimates depend."
Pharmacy	"Pharmacy is the science and technique of preparing and dispensing drugs. It is a health profession that links health sciences with chemical sciences and aims to ensure the safe and effective use of pharmaceutical drugs.
The scope of pharmacy practice includes more traditional roles such as compounding and dispensing medications, and it also includes more modern services related to health care, including clinical services, reviewing medications for safety and efficacy, and providing drug information. Pharmacists, therefore, are the experts on drug therapy and are the primary health professionals who optimize use of medication for the benefit of the patients.
An establishment in which pharmacy (in the first sense) is practiced is called a pharmacy (this term is more common in the United States) or a chemist's (which is more common in Great Britain). In the United States and Canada, drugstores commonly sell drugs, as well as miscellaneous items such as confectionery, cosmetics, office supplies, and magazines and occasionally refreshments and groceries.
The word pharmacy is derived from its root word pharma which was a term used since the 15th–17th centuries. However, the original Greek roots from pharmakos imply sorcery or even poison. In addition to pharma responsibilities, the pharma offered general medical advice and a range of services that are now performed solely by other specialist practitioners, such as surgery and midwifery. The pharma (as it was referred to) often operated through a retail shop which, in addition to ingredients for medicines, sold tobacco and patent medicines. Often the place that did this was called an apothecary and several languages have this as the dominant term, though their practices are more akin to a modern pharmacy, in English the term apothecary would today be seen as outdated or only approproriate if herbal remedies were on offer to a large extent. The pharmas also used many other herbs not listed. The Greek word Pharmakeia (Greek: φαρμακεία) derives from pharmakon (φάρμακον), meaning ""drug"", ""medicine"" (or ""poison"").
In its investigation of herbal and chemical ingredients, the work of the pharma may be regarded as a precursor of the modern sciences of chemistry and pharmacology, prior to the formulation of the scientific method."
Philadelphia	"Philadelphia (/ˌfɪləˈdɛlfiə/) is the largest city in the Commonwealth of Pennsylvania and the fifth-most populous in the United States, with an estimated population in 2014 of 1,560,297. In the Northeastern United States, at the confluence of the Delaware and Schuylkill rivers, Philadelphia is the economic and cultural anchor of the Delaware Valley, a metropolitan area home to 7.2 million people and the eighth-largest combined statistical area in the United States.
In 1682, William Penn founded the city to serve as capital of the Pennsylvania Colony. Philadelphia played an instrumental role in the American Revolution as a meeting place for the Founding Fathers of the United States, who signed the Declaration of Independence in 1776 and the Constitution in 1787. Philadelphia was one of the nation's capitals in the Revolutionary War, and served as temporary U.S. capital while Washington, D.C., was under construction. In the 19th century, Philadelphia became a major industrial center and railroad hub that grew from an influx of European immigrants. It became a prime destination for African-Americans in the Great Migration and surpassed two million occupants by 1950.
Based on the similar shifts underway the nation's economy after 1960, Philadelphia experienced a loss of manufacturing companies and jobs to lower taxed regions of the USA and often overseas. As a result, the economic base of Philadelphia, which had historically been manufacturing, declined significantly. In addition, consolidation in several American industries (retailing, financial services and health care in particular) reduced the number of companies headquartered in Philadelphia. The economic impact of these changes would reduce Philadelphia's tax base and the resources of local government. Philadelphia struggled through a long period of adjustment to these economic changes, coupled with significant demographic change as wealthier residents moved into the nearby suburbs and more immigrants moved into the city. The city in fact approached bankruptcy in the late 1980s. Revitalization began in the 1990s, with gentrification turning around many neighborhoods and reversing its decades-long trend of population loss.
The area's many universities and colleges make Philadelphia a top international study destination, as the city has evolved into an educational and economic hub. With a gross domestic product of $388 billion, Philadelphia ranks ninth among world cities and fourth in the nation. Philadelphia is the center of economic activity in Pennsylvania and is home to seven Fortune 1000 companies. The Philadelphia skyline is growing, with several nationally prominent skyscrapers. The city is known for its arts, culture, and history, attracting over 39 million domestic tourists in 2013. Philadelphia has more outdoor sculptures and murals than any other American city, and Fairmount Park is the largest landscaped urban park in the world. The 67 National Historic Landmarks in the city helped account for the $10 billion generated by tourism. Philadelphia is the birthplace of the United States Marine Corps, and is also the home of many U.S. firsts, including the first library (1731), first hospital (1751) and medical school (1765), first Capitol (1777), first stock exchange (1790), first zoo (1874), and first business school (1881). Philadelphia is the only World Heritage City in the United States."
Philosophiae Naturalis Principia Mathematica	"Philosophiæ Naturalis Principia Mathematica (Latin for ""Mathematical Principles of Natural Philosophy""), often referred to as simply the Principia, is a work in three books by Isaac Newton, in Latin, first published 5 July 1687. After annotating and correcting his personal copy of the first edition, Newton also published two further editions, in 1713 and 1726. The Principia states Newton's laws of motion, forming the foundation of classical mechanics, also Newton's law of universal gravitation, and a derivation of Kepler's laws of planetary motion (which Kepler first obtained empirically). The Principia is ""justly regarded as one of the most important works in the history of science"".
The French mathematical physicist Alexis Clairaut assessed it in 1747: ""The famous book of mathematical Principles of natural Philosophy marked the epoch of a great revolution in physics. The method followed by its illustrious author Sir Newton ... spread the light of mathematics on a science which up to then had remained in the darkness of conjectures and hypotheses."" A more recent assessment has been that while acceptance of Newton's theories was not immediate, by the end of a century after publication in 1687, ""no one could deny that"" (out of the Principia) ""a science had emerged that, at least in certain respects, so far exceeded anything that had ever gone before that it stood alone as the ultimate exemplar of science generally.""
In formulating his physical theories, Newton developed and used mathematical methods now included in the field of calculus. But the language of calculus as we know it was largely absent from the Principia; Newton gave many of his proofs in a geometric form of infinitesimal calculus, based on limits of ratios of vanishing small geometric quantities. In a revised conclusion to the Principia (see General Scholium), Newton used his expression that became famous, Hypotheses non fingo (""I contrive no hypotheses"")."
Philosophy of science	"Philosophy of science is a branch of philosophy concerned with the foundations, methods, and implications of science. The central questions of this study concern what qualifies as science, the reliability of scientific theories, and the ultimate purpose of science. This discipline overlaps with metaphysics, ontology, and epistemology, for example, when it explores the relationship between science and truth.
There is no consensus among philosophers about many of the central problems concerned with the philosophy of science, including whether science can reveal the truth about unobservable things and whether scientific reasoning can be justified at all. In addition to these general questions about science as a whole, philosophers of science consider problems that apply to particular sciences (such as biology or physics). Some philosophers of science also use contemporary results in science to reach conclusions about philosophy itself.
While philosophical thought pertaining to science dates back at least to the time of Aristotle, philosophy of science emerged as a distinct discipline only in the middle of the 20th century in the wake of the logical positivism movement, which aimed to formulate criteria for ensuring all philosophical statements' meaningfulness and objectively assessing them. Thomas Kuhn's landmark 1962 book The Structure of Scientific Revolutions was also formative, challenging the view of scientific progress as steady, cumulative acquisition of knowledge based on a fixed method of systematic experimentation and instead arguing that any progress is relative to a ""paradigm,"" the set of questions, concepts, and practices that define a scientific discipline in a particular historial period.
Subsequently, the coherentist approach to science, in which a theory is validated if it makes sense of observations as part of a coherent whole, became prominent due to W. V. Quine and others. Some thinkers such as Stephen Jay Gould seek to ground science in axiomatic assumptions, such as the uniformity of nature. A vocal minority of philosophers, and Paul Feyerabend (1924–1994) in particular, argue that there is no such thing as the ""scientific method"", so all approaches to science should be allowed, including explicitly supernatural ones. Another approach to thinking about science involves studying how knowledge is created from a sociological perspective, an approach represented by scholars like David Bloor and Barry Barnes. Finally, a tradition in continental philosophy approaches science from the perspective of a rigorous analysis of human experience.
Philosophies of the particular sciences range from questions about the nature of time raised by Einstein's general relativity, to the implications of economics for public policy. A central theme is whether one scientific discipline can be reduced to the terms of another. That is, can chemistry be reduced to physics, or can sociology be reduced to individual psychology? The general questions of philosophy of science also arise with greater specificity in some particular sciences. For instance, the question of the validity of scientific reasoning is seen in a different guise in the foundations of statistics. The question of what counts as science and what should be excluded arises as a life-or-death matter in the philosophy of medicine. Additionally, the philosophies of biology, of psychology, and of the social sciences explore whether the scientific studies of human nature can achieve objectivity or are inevitably shaped by values and by social relations."
Photovoltaic effect	"The photovoltaic effect is the creation of voltage or electric current in a material upon exposure to light and is a physical and chemical phenomenon.
The standard and obvious photovoltaic effect is directly related to the photoelectric effect, though they are different processes. When the sunlight or any other light is incident upon a material surface, the electrons present in the valence band absorb energy and, being excited, jump to the conduction band and become free. The chemical bonds of the material are vital for the process to work, as crystallized atoms are ionized and create a chemical electric imbalance, driving the electrons. These highly excited, non-thermal electrons diffuse, and some reach a junction where they are accelerated into a different material by a built-in potential (Galvani potential). This generates an electromotive force, and thus some of the light energy is converted into electric energy. The photovoltaic effect can also occur when two photons are absorbed simultaneously in a process called two-photon photovoltaic effect.
Due to the importance of the chemical structure of the absorbing material, silicon is often used, either bonded with boron or phosphorus. This is due to the semi-conducting ability of the metalloid and its bonding-potential, which is almost identical to carbon.
The photovoltaic effect was first observed by French physicist A. E. Becquerel in 1839. He explained his discovery in Les Comptes Rendus de l'Academie des Sciences, ""the production of an electric current when two plates of platinum or gold diving in an acid, neutral, or alkaline solution are exposed in an uneven way to solar radiation.""
In the photoelectric effect, by contrast, electrons are ejected from a material's surface into vacuum, upon exposure to light. This also generates some electric energy (as the ejected electron is eventually captured on another electrode), though there is typically a high photon energy threshold. The photovoltaic effect differs in that the excited electrons pass directly from one material to another, avoiding the difficult step of passing through the vacuum in between.
Besides the direct excitation of free electrons, a photovoltaic effect can also arise simply due to the heating caused by absorption of the light. The heating leads to an increase in temperature, which is accompanied by temperature gradients. These thermal gradients in turn may generate a voltage through the Seebeck effect. Whether direct excitation or thermal effects dominate the photovoltaic effect will depend on many material parameters.
In most photovoltaic applications the radiation is sunlight, and the devices are called solar cells. In the case of a p-n junction solar cell, illuminating the material creates an electric current as excited electrons and the remaining holes are swept in different directions by the built-in electric field of the depletion region."
Physical world	"The Universe is all of time and space and its contents. The Universe includes planets, stars, galaxies, the contents of intergalactic space, the smallest subatomic particles, and all matter and energy. The observable universe is about 28 billion parsecs (91 billion light-years) in diameter at the present time. The size of the whole Universe is not known and may be either finite or infinite. Observations and the development of physical theories have led to inferences about the composition and evolution of the Universe.
Throughout recorded history, cosmologies and cosmogonies, including scientific models, have been proposed to explain observations of the Universe. The earliest quantitative geocentric models were developed by ancient Greek philosophers and Indian philosophers. Over the centuries, more precise astronomical observations led to Nicolaus Copernicus's heliocentric model of the Solar System and, based on observations by Tycho Brahe, Johannes Kepler's improvement on that model with elliptical orbits, which was eventually explained by Isaac Newton's theory of gravity. Further observational improvements led to the realization that the Solar System is located in a galaxy composed of billions of stars, the Milky Way. It was subsequently discovered that our galaxy is just one of many. On the largest scales, it is assumed that the distribution of galaxies is uniform and the same in all directions, meaning that the Universe has neither an edge nor a center. Observations of the distribution of these galaxies and their spectral lines have led to many of the theories of modern physical cosmology. The discovery in the early 20th century that galaxies are systematically redshifted suggested that the Universe is expanding, and the discovery of the cosmic microwave background radiation suggested that the Universe had a beginning. Finally, observations in the late 1990s indicated the rate of the expansion of the Universe is increasing indicating that the majority of energy is most likely in an unknown form called dark energy. The majority of mass in the universe also appears to exist in an unknown form, called dark matter.
The Big Bang theory is the prevailing cosmological model describing the development of the Universe. Space and time were created in the Big Bang, and these were imbued with a fixed amount of energy and matter; as space expands, the density of that matter and energy decreases. After the initial expansion, the Universe cooled sufficiently to allow the formation first of subatomic particles and later of simple atoms. Giant clouds of these primordial elements later coalesced through gravity to form stars. Assuming that the prevailing model is correct, the age of the Universe is measured to be 7001137990000000000♠13.799±0.021 billion years.
There are many competing hypotheses about the ultimate fate of the Universe. Physicists and philosophers remain unsure about what, if anything, preceded the Big Bang. Many refuse to speculate, doubting that any information from any such prior state could ever be accessible. There are various multiverse hypotheses, in which some physicists have suggested that the Universe might be one among many universes that likewise exist."
Plastics	"Plastic is a material consisting of any of a wide range of synthetic or semi-synthetic organics that are malleable and can be molded into solid objects of diverse shapes. Plastics are typically organic polymers of high molecular mass, but they often contain other substances. They are usually synthetic, most commonly derived from petrochemicals, but many are partially natural. Plasticity is the general property of all materials that are able to irreversibly deform without breaking, but this occurs to such a degree with this class of moldable polymers that their name is an emphasis on this ability.
Due to their relatively low cost, ease of manufacture, versatility, and imperviousness to water, plastics are used in an enormous and expanding range of products, from paper clips to spaceships. They have already displaced many traditional materials, such as wood, stone, horn and bone, leather, paper, metal, glass, and ceramic, in most of their former uses. In developed countries, about a third of plastic is used in packaging and another third in buildings such as piping used in plumbing or vinyl siding. Other uses include automobiles (up to 20% plastic), furniture, and toys. In the developing world, the ratios may be different - for example, reportedly 42% of India's consumption is used in packaging. Plastics have many uses in the medical field as well, to include polymer implants, however the field of plastic surgery is not named for use of plastic material, but rather the more generic meaning of the word plasticity in regards to the reshaping of flesh.
The world's first fully synthetic plastic was bakelite, invented in New York in 1907 by Leo Baekeland who coined the term 'plastics'. Many chemists contributed to the materials science of plastics, including Nobel laureate Hermann Staudinger who has been called ""the father of polymer chemistry"" and Herman Mark, known as ""the father of polymer physics"". The success and dominance of plastics starting in the early 20th century led to environmental concerns regarding its slow decomposition rate after being discarded as trash due to its composition of very large molecules. Toward the end of the century, one approach to this problem was met with wide efforts toward recycling."
Plato	"Plato (/ˈpleɪtoʊ/; Greek: Πλάτων Plátōn pronounced [plá.tɔːn] in Classical Attic; 428/427 or 424/423 – 348/347 BC) was a philosopher in Classical Greece and the founder of the Academy in Athens, the first institution of higher learning in the Western world. He is widely considered the most pivotal figure in the development of philosophy, especially the Western tradition. Unlike nearly all of his philosophical contemporaries, Plato's entire œuvre is believed to have survived intact for over 2,400 years.
Along with his teacher, Socrates, and his most famous student, Aristotle, Plato laid the very foundations of Western philosophy and science. Alfred North Whitehead once noted: ""the safest general characterization of the European philosophical tradition is that it consists of a series of footnotes to Plato."" In addition to being a foundational figure for Western science, philosophy, and mathematics, Plato has also often been cited as one of the founders of Western religion and spirituality, particularly Christianity, which Friedrich Nietzsche, amongst other scholars, called ""Platonism for the people."" Plato's influence on Christian thought is often thought to be mediated by his major influence on Saint Augustine of Hippo, one of the most important philosophers and theologians in the history of Christianity.
Plato was the innovator of the dialogue and dialectic forms in philosophy, which originate with him. Plato appears to have been the founder of Western political philosophy, with his Republic, and Laws among other dialogues, providing some of the earliest extant treatments of political questions from a philosophical perspective. Plato's own most decisive philosophical influences are usually thought to have been Socrates, Parmenides, Heraclitus and Pythagoras, although few of his predecessors' works remain extant and much of what we know about these figures today derives from Plato himself.
The Stanford Encyclopedia of Philosophy describes Plato as ""...one of the most dazzling writers in the Western literary tradition and one of the most penetrating, wide-ranging, and influential authors in the history of philosophy. ... He was not the first thinker or writer to whom the word “philosopher” should be applied. But he was so self-conscious about how philosophy should be conceived, and what its scope and ambitions properly are, and he so transformed the intellectual currents with which he grappled, that the subject of philosophy, as it is often conceived—a rigorous and systematic examination of ethical, political, metaphysical, and epistemological issues, armed with a distinctive method—can be called his invention. Few other authors in the history of Western philosophy approximate him in depth and range: perhaps only Aristotle (who studied with him), Aquinas and Kant would be generally agreed to be of the same rank."""
Policy	"is a statement of intent, and is implemented as a procedure or protocol.   Policies are generally adopted by the Board of or senior governance body within an organization whereas procedures or protocols would be developed and adopted by senior executive officers. Policies can assist in both subjective and objective decision making. Policies to assist in subjective decision making would usually assist senior management with decisions that must consider the relative merits of a number of factors before making decisions and as a result are often hard to objectively test e.g. work-life balance policy. In contrast policies to assist in objective decision making are usually operational in nature and can be objectively tested e.g. password policy.
The term may apply to government, private sector organizations and groups, as well as individuals. Presidential executive orders, corporate privacy policies, and parliamentary rules of order are all examples of policy. Policy differs from rules or law. While law can compel or prohibit behaviors (e.g. a law requiring the payment of taxes on income), policy merely guides actions toward those that are most likely to achieve a desired outcome.
Policy or policy study may also refer to the process of making important organizational decisions, including the identification of different alternatives such as programs or spending priorities, and choosing among them on the basis of the impact they will have. Policies can be understood as political, managerial, financial, and administrative mechanisms arranged to reach explicit goals. In public corporate finance, a critical accounting policy is a policy for a firm/company or an industry which is considered to have a notably high subjective element, and that has a material impact on the financial statements."
Political science	"Political science is a social science discipline that deals with systems of government and the analysis of political activity and political behavior. It deals extensively with the theory and practice of politics which is commonly thought of as the determining of the distribution of power and resources. Political scientists ""see themselves engaged in revealing the relationships underlying political events and conditions, and from these revelations they attempt to construct general principles about the way the world of politics works.""
Political science is related to and draws upon the fields of economics, law, sociology, history, philosophy, geography, psychology, and anthropology.
Although it was codified in the 19th century, when the contemporary form of the academic social sciences was established, the study of political science has ancient roots that can be traced back to the works of Aristotle, Plato, and Chanakya which were written nearly 2,500 years ago. Political science is commonly divided into distinct sub-disciplines which together constitute the field:
Comparative politics
International political economy
International relations
Political theory
Public administration
Public law
Political methodology
Comparative politics is the science of comparison and teaching of different types of constitutions, political actors, legislature and associated fields, all of them from an intrastate perspective. International relations deals with the interaction between nation-states as well as intergovernmental and transnational organizations. Political theory is more concerned with contributions of various classical and contemporary thinkers and philosophers.
Political science is methodologically diverse and appropriates many methods originating in social research. Approaches include positivism, interpretivism, rational choice theory, behavioralism, structuralism, post-structuralism, realism, institutionalism, and pluralism. Political science, as one of the social sciences, uses methods and techniques that relate to the kinds of inquiries sought: primary sources such as historical documents and official records, secondary sources such as scholarly journal articles, survey research, statistical analysis, case studies, experimental research and model building."
Pre-Socratic philosopher	"Pre-Socratic philosophy is Greek ancient philosophy before Socrates (and includes schools contemporary to Socrates that were not influenced by him). In Classical antiquity, the Presocratic philosophers were called physiologoi (Greek: φυσιόλογοι; in English, physical or natural philosophers). Aristotle called them physikoi (""physicists"", after physis, ""nature"") because they sought natural explanations for phenomena, as opposed to the earlier theologoi (theologians), whose philosophical basis was supernatural. Diogenes Laërtius divides the physiologoi into two groups, Ionian and Italiote, led by Anaximander and Pythagoras, respectively.
Hermann Diels popularized the term pre-socratic in Die Fragmente der Vorsokratiker (The Fragments of the Pre-Socratics) in 1903. However, the term pre-Sokratic was in use as early as George Grote's Plato and the Other Companions of Sokrates in 1865. Edouard Zeller was also important in dividing thought before and after Socrates. Major analyses of pre-Socratic thought have been made by Gregory Vlastos, Jonathan Barnes, and Friedrich Nietzsche in his Philosophy in the Tragic Age of the Greeks.
It may sometimes be difficult to determine the actual line of argument some Presocratics used in supporting their particular views. While most of them produced significant texts, none of the texts has survived in complete form. All that is available are quotations by later philosophers (often biased) and historians, and the occasional textual fragment.
The Presocratic philosophers rejected traditional mythological explanations of the phenomena they saw around them in favor of more rational explanations. These philosophers asked questions about ""the essence of things"":
From where does everything come?
From what is everything created?
How do we explain the plurality of things found in nature?
How might we describe nature mathematically?
Others concentrated on defining problems and paradoxes that became the basis for later mathematical, scientific and philosophic study.
Later philosophers rejected many of the answers the early Greek philosophers provided, but continued to place importance on their questions. Furthermore, the cosmologies proposed by them have been updated by later developments in science."
Printing press	"A printing press is a device for applying pressure to an inked surface resting upon a print medium (such as paper or cloth), thereby transferring the ink. Typically used for texts, the invention and spread of the printing press are widely regarded as the most influential events in the second millennium revolutionizing the way people conceive and describe the world they live in, and ushering in the period of modernity.
The printing press was invented in the Holy Roman Empire by the German Johannes Gutenberg around 1440, based on existing screw presses. Gutenberg, a goldsmith by profession, developed a complete printing system, which perfected the printing process through all of its stages by adapting existing technologies to the printing purposes, as well as making groundbreaking inventions of his own. His newly devised hand mould made for the first time possible the precise and rapid creation of metal movable type in large quantities, a key element in the profitability of the whole printing enterprise.
The mechanization of bookmaking led to the first mass production of books in history in assembly line-style. A single Renaissance printing press could produce 3,600 pages per workday, compared to forty by typographic hand-printing and a few by hand-copying. Books of bestselling authors like Luther or Erasmus were sold by the hundreds of thousands in their lifetime.
From a single point of origin, Mainz, Germany, printing spread within several decades to over two hundred cities in a dozen European countries. By 1500, printing presses in operation throughout Western Europe had already produced more than twenty million volumes. In the 16th century, with presses spreading further afield, their output rose tenfold to an estimated 150 to 200 million copies. The operation of a press became so synonymous with the enterprise of printing that it lent its name to an entire new branch of media, the press. As early as 1620, the English statesman and philosopher Francis Bacon could write that typographical printing has ""changed the whole face and state of things throughout the world"".
From its beginnings, printing was practiced also as a true art form, setting a high aesthetic and artistic standard, such as in the famous 42-line Bible. Today, incunables, that is books printed before 1501, are among the most prized possessions of modern libraries.
The unprecedented impact of Gutenberg-style printing on the long-term development of modern European and then world history is difficult to capture in its entirety. Attempts at analysing its manifold effects include the notion of a proper Printing Revolution and the creation of the Gutenberg Galaxy. The ready availability and affordability of the printed word to the general public boosted the democratization of knowledge and laid the material basis for the modern knowledge-based economy.
In Renaissance Europe, the arrival of mechanical movable type printing introduced the era of mass communication which permanently altered the structure of society: The relatively unrestricted circulation of information and (revolutionary) ideas transcended borders, captured the masses in the Reformation and threatened the power of political and religious authorities; the sharp increase in literacy broke the monopoly of the literate elite on education and learning and bolstered the emerging middle class. Across Europe, the increasing cultural self-awareness of its peoples led to the rise of proto-nationalism, accelerated by the flowering of the European vernacular languages to the detriment of Latin's status as lingua franca.
In the 19th century, the replacement of the hand-operated Gutenberg-style press by steam-powered rotary presses allowed printing on an industrial scale, while Western-style printing was adopted all over the world, becoming practically the sole medium for modern bulk printing."
Protoscience	"In the philosophy of science, there are several definitions of protoscience. Its simplest meaning (most closely reflecting its roots of proto- + science) involves the earliest eras of the history of science, when the scientific method was embryonic. Thus, in the late 17th century and early 18th century, Isaac Newton contributed to the dawning sciences of chemistry and physics even though he was also an alchemist who sought chrysopoeia in various ways, some of which were unscientific. Our era views his as one of protoscience. Another meaning extends this idea into the present, involving the distinction between hard and soft sciences, in which various sciences (or branches thereof) are ranked according to methodological rigor. In this sense, the physical sciences may be posited as science whereas psychoanalysis may be labeled as protoscience because not all of its theoretical foundation is based on empirical evidence. Protoscience in this sense is sometimes distinguished from pseudoscience by a genuine willingness to be changed through new evidence, as opposed to having theory that can always find a way to rationalize a predetermined belief. Compare fringe science, which is considered highly speculative or even strongly refuted. Some protosciences go on to become an accepted part of mainstream science.
Philosopher of chemistry Jaap Brakel defines protoscience as ""the study of normative criteria for the use of experimental technology in science."" Thomas Kuhn said that protosciences ""generate testable conclusions but ... nevertheless resemble philosophy and the arts rather than the established sciences in their developmental patterns. I think, for example, of fields like chemistry and electricity before the mid-18th century, of the study of heredity and phylogeny before the mid-nineteenth, or of many of the social sciences today."" While noting that they meet the demarcation criteria of falsifiability from Popper, he questions whether the discussion in protoscience fields ""result[s] in clear-cut progress"". Kuhn concluded that protoscience, ""like the arts and philosophy, lack some element which, in the mature sciences, permits the more obvious forms of progress. It is not, however, anything that a methodological prescription can provide. ... I claim no therapy to assist the transformation of a proto-science to a science, nor do I suppose anything of this sort is to be had"".
The term prescientific means at root ""relating to an era before science existed"". For example, traditional medicine existed for thousands of years before medical science did, and thus many aspects of it can be described as prescientific. In a related but somewhat different sense, protoscientific topics (such as the alchemy of Newton's day) can be called prescientific, in which case the proto- and pre- labels can function more or less synonymously (the latter focusing more sharply on the idea that nothing but science is science)."
Pseudoscience	"Pseudoscience is a claim, belief, or practice presented as scientific, but which does not adhere to the scientific method. A field, practice, or body of knowledge can reasonably be called pseudoscientific when it is presented as consistent with the norms of scientific research, but it demonstrably fails to meet these norms.
Pseudoscience is often characterized by the following: contradictory, exaggerated or unprovable claims; over-reliance on confirmation rather than rigorous attempts at refutation; lack of openness to evaluation by other experts in the field; and absence of systematic practices when rationally developing theories. The term pseudoscience is often considered pejorative because it suggests something is being inaccurately or even deceptively portrayed as science. Accordingly, those labeled as practicing or advocating pseudoscience often dispute the characterization.
Science is distinguishable from revelation, theology, or spirituality in that it offers insight into the physical world obtained by empirical research and testing. Commonly held beliefs in popular science may not meet the criteria of science. ""Pop science"" may blur the divide between science and pseudoscience among the general public, and may also involve science fiction. Pseudoscientific beliefs are widespread, even among science teachers and newspaper editors.
The demarcation between science and pseudoscience has philosophical and scientific implications. Differentiating science from pseudoscience has practical implications in the case of health care, expert testimony, environmental policies, and science education. Distinguishing scientific facts and theories from pseudoscientific beliefs such as those found in astrology, alchemy, medical quackery, occult beliefs, and creation science combined with scientific concepts, is part of science education and scientific literacy."
Psychology	"Psychology is the study of behavior and mind, embracing all aspects of human experience. It is an academic discipline and an applied science which seeks to understand individuals and groups by establishing general principles and researching specific cases. In this field, a professional practitioner or researcher is called a psychologist and can be classified as a social, behavioral, or cognitive scientist. Psychologists attempt to understand the role of mental functions in individual and social behavior, while also exploring the physiological and biological processes that underlie cognitive functions and behaviors.
Psychologists explore concepts such as perception, cognition, attention, emotion, intelligence, phenomenology, motivation, brain functioning, personality, behavior, and interpersonal relationships, including psychological resilience, family resilience, and other areas. Psychologists of diverse orientations also consider the unconscious mind. Psychologists employ empirical methods to infer causal and correlational relationships between psychosocial variables. In addition, or in opposition, to employing empirical and deductive methods, some—especially clinical and counseling psychologists—at times rely upon symbolic interpretation and other inductive techniques. Psychology has been described as a ""hub science"", with psychological findings linking to research and perspectives from the social sciences, natural sciences, medicine, humanities, and philosophy.
While psychological knowledge is often applied to the assessment and treatment of mental health problems, it is also directed towards understanding and solving problems in several spheres of human activity. By many accounts psychology ultimately aims to benefit society. The majority of psychologists are involved in some kind of therapeutic role, practicing in clinical, counseling, or school settings. Many do scientific research on a wide range of topics related to mental processes and behavior, and typically work in university psychology departments or teach in other academic settings (e.g., medical schools, hospitals). Some are employed in industrial and organizational settings, or in other areas such as human development and aging, sports, health, and the media, as well as in forensic investigation and other aspects of law."
Public science	"Public science is an increasingly popular term for research that is conducted amongst, or includes, the public. Two traditions of public science have emerged, one based on participatory action research and another based on science outreach.
The participatory action research approach seeks to develop a critical framework for making systematic inquiry and analysis a public enterprise. It is committed to valuing knowledges that have been historically marginalized and delegitimized (i.e., youth, prisoner, immigrant, farmer) alongside traditionally recognized knowledges (i.e., scholarly). Through the formation of research collectives, it aims to share the various knowledges and resources held by its individual members so members can participate as equally as possible. The choice of appropriate research questions, design, methods and analysis as well as useful research products are decided collectively. Centres for this form of public science include the Public Science Project and the Society for Participation, Engagement, Action and Knowledge Sharing.
Examples of public science projects in the participatory action research tradition include the Morris Justice Project and Our Food.
The science outreach approach has some similarities to citizen science but typically describes projects that are conducted outdoors or in another type of public or accessible space such as a public park, metro stop, library, university campus, etc. Similar to public art, there are aspects of collaboration, community support and involvement, and even site specificity involved.
Public science efforts in the science outreach tradition include Science on the Buses, in which city buses in many major European Union cities were decorated with large informational science posters in November 2002. Likewise, a project in Toronto placed “advertisements” with science facts on [1] buses in Toronto during July 2009.
""Science City"" is another example of a public science initiative that ran from June 1994 through May 1995. Created by staff and consultants from the New York Hall of Science, ""Science City"" was an outdoor exhibition that utilized the street, fences, buildings and other public structures in New York City to attract the ""non-museum-going"" public to the science in everyday life. The exhibition asked questions such as ""Why is it warmer in the city?"", ""What pulses under the street?"" and ""What's under the sidewalk?"" to help increase public awareness about the science and technology that runs invisibly underneath modern urban life.
Science Cafes, founded by the public science pioneer Duncan Dallas are a further public science effort that initiates a discussion on a science topic in pubs or cafes, usually with a local researcher in attendance to answer questions and present information.
Science festivals can also be grouped into this category of public science efforts, with modern incarnations of festivals including a range of learner-centered activities and events conducted in public spaces.
Public science initiatives often attempt to reach new audiences (particularly, non-experts who might not actively seek out science), in addition to existing science outreach audiences, by hosting events in alternative informal learning environments. By definition, such public science projects are outside the walls of the science center or science museum, where the main focus of the particular space is not typically science outreach.
An example of a specific public science initiative in astronomy is “From Earth to the Universe” (FETTU), a project of the International Year of Astronomy 2009 (IYA2009). FETTU displayed large-scale images of astronomical objects with contextual information and supplementary materials and activities in non-traditional and mostly public locations such as parks, airports, art festivals, shopping malls, and others (see examples at http://www.fromearthtotheuniverse.org/event_photos.php). By 2011, FETTU had been exhibited at about 1000 sites worldwide, with 50 sites in the United States. One result from FETTU demonstrated a trend towards more non-self-selective audiences for science communications in these public spaces."
R. P. Feynman	"Richard Phillips Feynman, (/ˈfaɪnmən/; May 11, 1918 – February 15, 1988) was an American theoretical physicist known for his work in the path integral formulation of quantum mechanics, the theory of quantum electrodynamics, and the physics of the superfluidity of supercooled liquid helium, as well as in particle physics for which he proposed the parton model. For his contributions to the development of quantum electrodynamics, Feynman, jointly with Julian Schwinger and Sin-Itiro Tomonaga, received the Nobel Prize in Physics in 1965. He developed a widely used pictorial representation scheme for the mathematical expressions governing the behavior of subatomic particles, which later became known as Feynman diagrams. During his lifetime, Feynman became one of the best-known scientists in the world. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World he was ranked as one of the ten greatest physicists of all time.
He assisted in the development of the atomic bomb during World War II and became known to a wide public in the 1980s as a member of the Rogers Commission, the panel that investigated the Space Shuttle Challenger disaster. In addition to his work in theoretical physics, Feynman has been credited with pioneering the field of quantum computing, and introducing the concept of nanotechnology. He held the Richard C. Tolman professorship in theoretical physics at the California Institute of Technology.
Feynman was a keen popularizer of physics through both books and lectures, including a 1959 talk on top-down nanotechnology called There's Plenty of Room at the Bottom, and the three-volume publication of his undergraduate lectures, The Feynman Lectures on Physics. Feynman also became known through his semi-autobiographical books Surely You're Joking, Mr. Feynman! and What Do You Care What Other People Think? and books written about him, such as Tuva or Bust! and Genius: The Life and Science of Richard Feynman by James Gleick."
Radioactivity	"Radioactive decay, also known as nuclear decay or radioactivity, is the process by which the nucleus of an unstable atom loses energy by emitting radiation, including alpha particles, beta particles, gamma rays and conversion electrons. A material that spontaneously emits such radiation is considered radioactive.
Radioactive decay is a stochastic (i.e. random) process at the level of single atoms, in that, according to quantum theory, it is impossible to predict when a particular atom will decay. The chance that a given atom will decay never changes, that is, it does not matter how long the atom has existed. The decay rate for a large collection of atoms, however, can be calculated from their measured decay constants or half-lives. This is the basis of radiometric dating. The half-lives of radioactive atoms have no known lower or upper limit, spanning a time range of over 55 orders of magnitude, from nearly instantaneous to far longer than the age of the universe. A radioactive source emits its decay products isotropically.
There are many different types of radioactive decay (see table below). A decay, or loss of energy from the nucleus, results when an atom with one type of nucleus, called the parent radionuclide (or parent radioisotope), transforms into an atom with a nucleus in a different state, or with a nucleus containing a different number of protons and neutrons. The product is called the daughter nuclide. In some decays, the parent and the daughter nuclides are different chemical elements, and thus the decay process results in the creation of an atom of a different element. This is known as a nuclear transmutation.
The first decay processes to be discovered were alpha decay, beta decay, and gamma decay. Alpha decay occurs when the nucleus ejects an alpha particle (helium nucleus). This is the most common process of emitting nucleons, but in rarer types of decays, nuclei can eject protons, or in the case of cluster decay specific nuclei of other elements. Beta decay occurs when the nucleus emits an electron or positron and a neutrino, in a process that changes a proton to a neutron or the other way about. The nucleus may capture an orbiting electron, causing a proton to convert into a neutron in a process called electron capture. All of these processes result in a well-defined nuclear transmutation.
By contrast, there are radioactive decay processes that do not result in a nuclear transmutation. The energy of an excited nucleus may be emitted as a gamma ray in a process called gamma decay, or be used to eject an orbital electron by its interaction with the excited nucleus, in a process called internal conversion. Highly excited neutron-rich nuclei, formed as the product of other types of decay, occasionally lose energy by way of neutron emission, resulting in a change of an element from one isotope to another.
Another type of radioactive decay results in products that are not defined, but appear in a range of ""pieces"" of the original nucleus. This decay, called spontaneous fission, happens when a large unstable nucleus spontaneously splits into two (and occasionally three) smaller daughter nuclei, and generally leads to the emission of gamma rays, neutrons, or other particles from those products.
For a summary table showing the number of stable and radioactive nuclides in each category, see radionuclide. There exist twenty-nine chemical elements on Earth that are radioactive. They are those that contain thirty-four radionuclides that date before the time of formation of the solar system, and are known as primordial nuclides. Well-known examples are uranium and thorium, but also included are naturally occurring long-lived radioisotopes such as potassium-40. Another fifty or so shorter-lived radionuclides, such as radium and radon, found on Earth, are the products of decay chains that began with the primordial nuclides, and ongoing cosmogenic processes, such as the production of carbon-14 from nitrogen-14 by cosmic rays. Radionuclides may also be produced artificially in particle accelerators or nuclear reactors, resulting in 650 of these with half-lives of over an hour, and several thousand more with even shorter half-lives. See this list of nuclides for a list of these, sorted by half life."
Rationalism	"In epistemology, rationalism is the view that ""regards reason as the chief source and test of knowledge"" or ""any view appealing to reason as a source of knowledge or justification"". More formally, rationalism is defined as a methodology or a theory ""in which the criterion of the truth is not sensory but intellectual and deductive"". Rationalists believe reality has an intrinsically logical structure. Because of this, rationalists argue that certain truths exist and that the intellect can directly grasp these truths. That is to say, rationalists assert that certain rational principles exist in logic, mathematics, ethics, and metaphysics that are so fundamentally true that denying them causes one to fall into contradiction. Rationalists have such a high confidence in reason that empirical proof and physical evidence are unnecessary to ascertain truth – in other words, ""there are significant ways in which our concepts and knowledge are gained independently of sense experience"". Because of this belief, empiricism is one of rationalism's greatest rivals.
Different degrees of emphasis on this method or theory lead to a range of rationalist standpoints, from the moderate position ""that reason has precedence over other ways of acquiring knowledge"" to the more extreme position that reason is ""the unique path to knowledge"". Given a pre-modern understanding of reason, rationalism is identical to philosophy, the Socratic life of inquiry, or the zetetic (skeptical) clear interpretation of authority (open to the underlying or essential cause of things as they appear to our sense of certainty). In recent decades, Leo Strauss sought to revive ""Classical Political Rationalism"" as a discipline that understands the task of reasoning, not as foundational, but as maieutic.
In politics, Rationalism, since the Enlightenment, historically emphasized a ""politics of reason"" centered upon rational choice, utilitarianism, secularism, and irreligion – the latter aspect's antitheism later ameliorated by utilitarian adoption of pluralistic rationalist methods practicable regardless of religious or irreligious ideology.
In this regard, the philosopher John Cottingham noted how rationalism, a methodology, became socially conflated with atheism, a worldview: In the past, particularly in the 17th and 18th centuries, the term 'rationalist' was often used to refer to free thinkers of an anti-clerical and anti-religious outlook, and for a time the word acquired a distinctly pejorative force (thus in 1670 Sanderson spoke disparagingly of 'a mere rationalist, that is to say in plain English an atheist of the late edition...'). The use of the label 'rationalist' to characterize a world outlook which has no place for the supernatural is becoming less popular today; terms like 'humanist' or 'materialist' seem largely to have taken its place. But the old usage still survives."
Religion	"Religion is a cultural system of behaviors and practices, mythologies, world views, sacred texts, holy places, ethics, and societal organisation that relate humanity to what an anthropologist has called ""an order of existence"". Different religions may contain various elements, ranging from ""the belief in spiritual beings"", the ""divine"", ""sacred things"", ""faith"", a ""supernatural being or supernatural beings"" such as God or angels, or ""...some sort of ultimacy and transcendence that will provide norms and power for the rest of life.""
Religious practices may include rituals, sermons, commemoration or veneration (of a deity, gods, or goddesses), sacrifices, festivals, feasts, trances, initiations, funerary services, matrimonial services, meditation, prayer, music, art, dance, public service, or other aspects of human culture. Religions have sacred histories and narratives, which may be preserved in sacred scriptures, and symbols and holy places, that aim to explain the meaning of life, the origin of life, or the Universe. Traditionally, faith, in addition to reason, has been considered a source of religious beliefs. About 84% of the world's population is affiliated with one of the five largest religions, namely Christianity, Islam, Hinduism, Buddhism or forms of folk religion.
With the onset of the modernisation of and the scientific revolution in the western world, some aspects of religion have cumulatively been criticized. Though the religiously unaffliated, including atheism (the rejection of belief in the existence of deities) and agnosticism (the belief that the truth of certain claims – especially metaphysical and religious claims such as whether God, the divine or the supernatural exist – are unknown and perhaps unknowable), have grown globally, many of the unaffiliated still have various religious beliefs. About 16% of the world's population is religiously unaffiliated.
The study of religion encompasses a wide variety of academic disciplines, including theology, comparative religion and social scientific studies. Theories of religion offer various explanations for the origins and workings of religion."
Renaissance	"The Renaissance (UK /rᵻˈneɪsəns/, US /ˈrɛnᵻsɑːns/) is a period in Europe, from the 14th to the 17th century, considered the bridge between the Middle Ages and modern history. It started as a cultural movement in Italy in the Late Medieval period and later spread to the rest of Europe, marking the beginning of the Early Modern Age.
The Renaissance's intellectual basis was its own invented version of humanism, derived from the rediscovery of classical Greek philosophy, such as that of Protagoras, who said, that ""Man is the measure of all things."" This new thinking became manifest in art, architecture, politics, science and literature. Early examples were the development of perspective in oil painting and the recycled knowledge of how to make concrete. Although the invention of metal movable type sped the dissemination of ideas from the later 15th century, the changes of the Renaissance were not uniformly experienced across Europe.
As a cultural movement, it encompassed innovative flowering of Latin and vernacular literatures, beginning with the 14th century resurgence of learning based on classical sources, which contemporaries credited to Petrarch; the development of linear perspective and other techniques of rendering a more natural reality in painting; and gradual but widespread educational reform. In politics, the Renaissance contributed to the development of the customs and conventions of diplomacy, and in science to an increased reliance on observation and inductive reasoning. Although the Renaissance saw revolutions in many intellectual pursuits, as well as social and political upheaval, it is perhaps best known for its artistic developments and the contributions of such polymaths as Leonardo da Vinci and Michelangelo, who inspired the term ""Renaissance man"".
There is a consensus that the Renaissance began in Florence, in the 14th century. Various theories have been proposed to account for its origins and characteristics, focusing on a variety of factors including the social and civic peculiarities of Florence at the time; its political structure; the patronage of its dominant family, the Medici; and the migration of Greek scholars and texts to Italy following the Fall of Constantinople at the hands of the Ottoman Turks. Other major centres were northern Italian city-states such as Venice, Genoa, Milan; Bologna; and finally Rome during the Renaissance Papacy.
The Renaissance has a long and complex historiography, and, in line with general scepticism of discrete periodizations, there has been much debate among historians reacting to the 19th-century glorification of the ""Renaissance"" and individual culture heroes as ""Renaissance men"", questioning the usefulness of Renaissance as a term and as a historical delineation. The art historian Erwin Panofsky observed of this resistance to the concept of ""Renaissance"":

It is perhaps no accident that the factuality of the Italian Renaissance has been most vigorously questioned by those who are not obliged to take a professional interest in the aesthetic aspects of civilization—historians of economic and social developments, political and religious situations, and, most particularly, natural science—but only exceptionally by students of literature and hardly ever by historians of Art.

Some observers have called into question whether the Renaissance was a cultural ""advance"" from the Middle Ages, instead seeing it as a period of pessimism and nostalgia for classical antiquity, while social and economic historians, especially of the longue durée, have instead focused on the continuity between the two eras which are linked, as Panofsky observed, ""by a thousand ties"".
The word Renaissance, literally meaning ""Rebirth"" in French, first appears in English in the 1830s. The word occurs in Jules Michelet's 1855 work, Histoire de France. The word Renaissance has also been extended to other historical and cultural movements, such as the Carolingian Renaissance and the Renaissance of the 12th century."
René Descartes	"René Descartes (/ˈdeɪˌkɑːrt/; French: [ʁəne dekaʁt]; Latinized: Renatus Cartesius; adjectival form: ""Cartesian""; 31 March 1596 – 11 February 1650) was a French philosopher, mathematician, and scientist. Dubbed the father of modern western philosophy, much of subsequent Western philosophy is a response to his writings, which are studied closely to this day. He spent about 20 years of his life in the Dutch Republic.
Descartes's Meditations on First Philosophy continues to be a standard text at most university philosophy departments. Descartes's influence in mathematics is equally apparent; the Cartesian coordinate system — allowing reference to a point in space as a set of numbers, and allowing algebraic equations to be expressed as geometric shapes in a two- or three-dimensional coordinate system (and conversely, shapes to be described as equations) — was named after him. He is credited as the father of analytical geometry, the bridge between algebra and geometry, used in the discovery of infinitesimal calculus and analysis. Descartes was also one of the key figures in the scientific revolution.
Descartes refused to accept the authority of previous philosophers, and refused to trust his own senses. He frequently set his views apart from those of his predecessors. In the opening section of the Passions of the Soul, a treatise on the early modern version of what are now commonly called emotions, Descartes goes so far as to assert that he will write on this topic ""as if no one had written on these matters before"". Many elements of his philosophy have precedents in late Aristotelianism, the revived Stoicism of the 16th century, or in earlier philosophers like Augustine. In his natural philosophy, he differs from the schools on two major points: First, he rejects the splitting of corporeal substance into matter and form; second, he rejects any appeal to final ends—divine or natural—in explaining natural phenomena. In his theology, he insists on the absolute freedom of God's act of creation.
Descartes laid the foundation for 17th-century continental rationalism, later advocated by Baruch Spinoza and Gottfried Leibniz, and opposed by the empiricist school of thought consisting of Hobbes, Locke, Berkeley, and Hume. Leibniz, Spinoza and Descartes were all well-versed in mathematics as well as philosophy, and Descartes and Leibniz contributed greatly to science as well.
His best known philosophical statement is ""Cogito ergo sum"" (French: Je pense, donc je suis; I think, therefore I am), found in part IV of Discourse on the Method (1637; written in French but with inclusion of ""Cogito ergo sum"") and §7 of part I of Principles of Philosophy (1644; written in Latin)."
Research funding	"Research funding is a term generally covering any funding for scientific research, in the areas of both ""hard"" science and technology and social science. The term often connotes funding obtained through a competitive process, in which potential research projects are evaluated and only the most promising receive funding. Such processes, which are run by government, corporations or foundations, allocate scarce funds.
Most research funding comes from two major sources, corporations (through research and development departments) and government (primarily carried out through universities and specialized government agencies; often known as research councils). Some small amounts of scientific research are carried out (or funded) by charitable foundations, especially in relation to developing cures for diseases such as cancer, malaria and AIDS.
According to OECD, around two-thirds of research and development in scientific and technical fields is carried out by industries, and 20% and 10% respectively by universities and government. Comparatively, in countries with less GDP, such as Portugal and Mexico the industry contribution is significantly lower. The US government spends more than other countries on military R&D, although the proportion has fallen from around 30% in the 1980s to under 20. Government funding for medical research amounts to approximately 36% in the U.S. The government funding proportion in certain industries is higher, and it dominates research in social science and humanities. Similarly, with some exceptions (e.g. biotechnology) government provides the bulk of the funds for basic scientific research. In commercial research and development, all but the most research-oriented corporations focus more heavily on near-term commercialization possibilities rather than ""blue-sky"" ideas or technologies (such as nuclear fusion)."
Rheology	"Rheology (/riːˈɒlədʒi/; from Greek ῥέω rhéō, ""flow"" and -λoγία, -logia, ""study of"") is the study of the flow of matter, primarily in a liquid state, but also as 'soft solids' or solids under conditions in which they respond with plastic flow rather than deforming elastically in response to an applied force. It applies to substances which have a complex microstructure, such as muds, sludges, suspensions, polymers and other glass formers (e.g., silicates), as well as many foods and additives, bodily fluids (e.g., blood) and other biological materials or other materials which belong to the class of soft matter.
Newtonian fluids can be characterized by a single coefficient of viscosity for a specific temperature. Although this viscosity will change with temperature, it does not change with the strain rate. Only a small group of fluids exhibit such constant viscosity. The large class of fluids whose viscosity changes with the strain rate (the relative flow velocity) are called non-Newtonian fluids.
Rheology generally accounts for the behavior of non-Newtonian fluids, by characterizing the minimum number of functions that are needed to relate stresses with rate of change of strain or strain rates. For example, ketchup can have its viscosity reduced by shaking (or other forms of mechanical agitation, where the relative movement of different layers in the material actually causes the reduction in viscosity) but water cannot. Ketchup is a shear thinning material, like yoghurt and emulsion paint (US terminology latex paint or acrylic paint), exhibiting thixotropy, where an increase in relative flow velocity will cause a reduction in viscosity, for example, by stirring. Some other non-Newtonian materials show the opposite behavior, rheopecty: viscosity going up with relative deformation, and are called shear thickening or dilatant materials. Since Sir Isaac Newton originated the concept of viscosity, the study of liquids with strain rate dependent viscosity is also often called Non-Newtonian fluid mechanics.
The term rheology was coined by Eugene C. Bingham, a professor at Lafayette College, in 1920, from a suggestion by a colleague, Markus Reiner. The term was inspired by the aphorism of Simplicius (often attributed to Heraclitus), panta rhei, ""everything flows""
The experimental characterization of a material's rheological behaviour is known as rheometry, although the term rheology is frequently used synonymously with rheometry, particularly by experimentalists. Theoretical aspects of rheology are the relation of the flow/deformation behaviour of material and its internal structure (e.g., the orientation and elongation of polymer molecules), and the flow/deformation behaviour of materials that cannot be described by classical fluid mechanics or elasticity."
Richard Feynman	"Richard Phillips Feynman, (/ˈfaɪnmən/; May 11, 1918 – February 15, 1988) was an American theoretical physicist known for his work in the path integral formulation of quantum mechanics, the theory of quantum electrodynamics, and the physics of the superfluidity of supercooled liquid helium, as well as in particle physics for which he proposed the parton model. For his contributions to the development of quantum electrodynamics, Feynman, jointly with Julian Schwinger and Sin-Itiro Tomonaga, received the Nobel Prize in Physics in 1965. He developed a widely used pictorial representation scheme for the mathematical expressions governing the behavior of subatomic particles, which later became known as Feynman diagrams. During his lifetime, Feynman became one of the best-known scientists in the world. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World he was ranked as one of the ten greatest physicists of all time.
He assisted in the development of the atomic bomb during World War II and became known to a wide public in the 1980s as a member of the Rogers Commission, the panel that investigated the Space Shuttle Challenger disaster. In addition to his work in theoretical physics, Feynman has been credited with pioneering the field of quantum computing, and introducing the concept of nanotechnology. He held the Richard C. Tolman professorship in theoretical physics at the California Institute of Technology.
Feynman was a keen popularizer of physics through both books and lectures, including a 1959 talk on top-down nanotechnology called There's Plenty of Room at the Bottom, and the three-volume publication of his undergraduate lectures, The Feynman Lectures on Physics. Feynman also became known through his semi-autobiographical books Surely You're Joking, Mr. Feynman! and What Do You Care What Other People Think? and books written about him, such as Tuva or Bust! and Genius: The Life and Science of Richard Feynman by James Gleick."
Rosalind Franklin	"Rosalind Elsie Franklin (25 July 1920 – 16 April 1958) was an English chemist and X-ray crystallographer who made contributions to the understanding of the molecular structures of DNA (deoxyribonucleic acid), RNA (ribonucleic acid), viruses, coal, and graphite. Although her works on coal and viruses were appreciated in her lifetime, her contributions to the discovery of DNA were largely recognized posthumously.
Born to a prominent British Jewish family, Franklin was educated at a private day school at Norland Place in West London, Lindores School for Young Ladies in Sussex, and St Paul's Girls' School, London. Then she studied the Natural Sciences Tripos at Newnham College, Cambridge, from where she graduated in 1941. Earning a research fellowship, she joined the University of Cambridge physical chemistry laboratory under Ronald George Wreyford Norrish, who disappointed her for his lack of enthusiasm. Fortunately, the British Coal Utilisation Research Association (BCURA) offered her a research position in 1942, and started her work on coals. This helped her earn a PhD in 1945. She went to Paris in 1947 as a chercheur (post-doctoral researcher) under Jacques Mering at the Laboratoire Central des Services Chimiques de l'Etat, where she became an accomplished X-ray crystallographer. She became a research associate at King's College London, in 1951, but was compelled to move to Birkbeck College after two years, owing to disagreeable clashes with her director John Randall and more so with her colleague Maurice Wilkins. At Birkbeck, J. D. Bernal, chair of the physics department, offered her a separate research team. She died in 1958 at the age of 37 of ovarian cancer.
Franklin is best known for her work on the X-ray diffraction images of DNA while at King's College, London, which led to the discovery of the DNA double helix for which James Watson, Francis Crick and Maurice Wilkins shared the Nobel Prize in Physiology or Medicine in 1962. Watson suggested that Franklin would have ideally been awarded a Nobel Prize in Chemistry, along with Wilkins, but the Nobel Committee does not make posthumous nominations.
After finishing her work on DNA, Franklin led pioneering work at Birkbeck College, London, on the molecular structures of viruses. Her team member Aaron Klug continued her research, winning the Nobel Prize in Chemistry in 1982. Had she been alive, she would very likely have shared that prize as well."
Satellite communications	"A communications satellite is an artificial satellite that relays and amplifies radio telecommunications signals via a transponder; it creates a communication channel between a source transmitter and a receiver(s) at different locations on Earth. Communications satellites are used for television, telephone, radio, internet, and military applications. There are over 2,000 communications satellites in Earth’s orbit, used by both private and government organizations.
Wireless communication uses electromagnetic waves to carry signals. These waves require line-of-sight, and are thus obstructed by the curvature of the Earth. The purpose of communications satellites is to relay the signal around the curve of the Earth allowing communication between widely separated points. The electromagnetic signals that communication satellites work with, have a large spectrum of wavelengths and frequencies. To keep these waves from interfering with one another, international organizations have certain rules and regulations describing which wavelength a certain company or group can use. By separating out wavelengths, communication satellites will have minimal interference and be able to communicate effectively.
There are two major classes of communications satellites, passive and active. Passive satellites only reflect the signal coming from the source, toward the direction of the receiver. With passive satellites, the reflected signal is not amplified at the satellite, and only a very small amount of the transmitted energy reflects toward the receiver. Since the satellite is so far above Earth the radio signal is attenuated on its long journey due to free-space path loss, so the signal received on Earth is very weak. Active satellites, on the other hand, amplify the received signal before re-transmitting it to the receiver on the ground Passive satellites were the first communications satellites, but are little used now."
Scholasticism	"Scholasticism is a method of critical thought which dominated teaching by the academics (""scholastics,"" or ""schoolmen"") of medieval universities in Europe from about 1100 to 1700, and a program of employing that method in articulating and defending dogma in an increasingly pluralistic context. It originated as an outgrowth of, and a departure from, Christian monastic schools at the earliest European universities. The first institutions in the West to be considered universities were established in Italy, France, Spain, and England in the late 11th and the 12th centuries for the study of arts, law, medicine, and theology, such as Schola Medica Salernitana, the University of Bologna, and the University of Paris. It is difficult to define the date at which they became true universities, although the lists of studia generalia for higher education in Europe held by the Catholic Church and its various religious orders are a useful guide.
Not so much a philosophy or a theology as a method of learning, scholasticism places a strong emphasis on dialectical reasoning to extend knowledge by inference, and to resolve contradictions. Scholastic thought is also known for rigorous conceptual analysis and the careful drawing of distinctions. In the classroom and in writing, it often takes the form of explicit disputation: a topic drawn from the tradition is broached in the form of a question, opponents' responses are given, a counterproposal is argued and opponent's arguments rebutted. Because of its emphasis on rigorous dialectical method, scholasticism was eventually applied to many other fields of study.
As a program, scholasticism began as an attempt at harmonization on the part of medieval Christian thinkers: to harmonize the various authorities of their own tradition, and to reconcile Christian theology with classical and late antiquity philosophy, especially that of Aristotle but also of Neoplatonism. (See also Christian apologetics.)
Some of the main figures of scholasticism include Anselm of Canterbury, Peter Abelard, Alexander of Hales, Albertus Magnus, Duns Scotus, William of Ockham, Bonaventure, and Thomas Aquinas. Aquinas's masterwork Summa Theologica, considered to be the pinnacle of scholastic, medieval, and Christian philosophy, began while Aquinas was regent master at the studium provinciale of Santa Sabina in Rome, the forerunner of the Pontifical University of Saint Thomas Aquinas, Angelicum. Important work in the scholastic tradition has been carried on well past Aquinas's time, for instance by Francisco Suárez and Luis de Molina, and also among Lutheran and Reformed thinkers."
Science & Vie	"Science & Vie (French pronunciation: ​[sjɑ̃seˈvi]; French for Science and Life) is a monthly science magazine issued in France since 1913 when its name was La Science et la Vie. In 1982, a spinoff computer magazine, Science & Vie Micro (SVM) was launched. The first magazine was published at the end of 1983 and was such a success that the number of copies were insufficient on the market. Another spinoff for teenagers, Science & Vie Junior was started in 1986. It was first published by Excelsior Publications until the latter was bought by Emap Plc in 2003. Since 2006, it is published by Mondadori France.
Science & Vie was divided in three sections, Science (Sciences), Technologie (Technology), Vie Pratique (Daily life). While the Science section reported on recent scientific progress, the Technology section would report on recent technical advances. Science & Vie covered technical advances in industry, but also in military technology. In particular, it featured articles on explosives, firearms, chemical weapons and nuclear weapons. The Vie Pratique section was concerned with technology in daily life. It included articles on photography, personal computers, video recording equipment or television. Besides these three sections, Science & Vie contained a section on amateur electronics by Henri-Pierre Penel, a section on amateur astronomy La Calculette de l'Astronome, and two sections on computer programming in BASIC, one on video games (first for the Sinclair ZX 81, and then the ZX Spectrum) and another of elementary numerical analysis, Le Micro de l'Ingénieur (with listings for the Apple II). This made Science & Vie a more popular magazine (both in terms of circulation and in terms of the level of education of its readers) than La Recherche or Pour la Science which are only concerned with science, or Industries & Techniques which only deals with applications of technology in industry.
Another important distinctive feature of Science & Vie was its willingness to tackle the issue of pseudoscience. The magazine was very critical of astrology, homeopathy, and pseudoscience. With the help of magician Gérard Majax, it has exposed the tricks used by Uri Geller to bend spoons and make small objects fly. In 1989, it strongly criticized the claims of Jacques Benveniste of having observed water memory. The magazine also uncovered the fabrication of the autopsy of an alien body supposedly discovered in Roswell, New Mexico. The magazine was also very supportive of Henri Broch's debunking of paranormal claims. In general, articles on paranormal topics were marked as Blurgs, an acronym for Balivernes lamentables à l'usage réservé des gogos (deplorable nonsense to be used only by the gullible). Since being bought by Mondadori, the magazine has adopted a less skeptical line.
In 2010 the circulation of Science & Vie was 281,000 copies."
Scientific creationism	"Creation science or scientific creationism is a branch of creationism that attempts to provide scientific support for the creation myth in the Book of Genesis and disprove or reinterpret the scientific facts, theories and scientific paradigms about geology, cosmology, biological evolution, archeology, history, and even linguistics.
The overwhelming consensus of the scientific community is that creation science is a religious, not a scientific view. It fails to qualify as a science because it lacks empirical support, supplies no tentative hypotheses, and resolves to describe natural history in terms of scientifically untestable supernatural causes. Creation science is a pseudoscientific attempt to map the Bible into scientific facts, and is viewed by professional biologists as unscholarly and, even, as a dishonest and misguided sham, with extremely harmful educational consequences.
Creation science began in the 1960s as a fundamentalist Christian effort in the United States to prove Biblical inerrancy and nullify the scientific evidence for evolution. It has since developed a sizable religious following in the United States, with creation science ministries branching worldwide. The main ideas in creation science are: the belief in ""creation ex nihilo"" (Latin: out of nothing); the conviction that the Earth was created within the last 6,000–10,000 years; the belief that mankind and other life on Earth were created as distinct fixed ""baraminological"" kinds; and the idea that fossils found in geological strata were deposited during a cataclysmic flood which completely covered the entire Earth. As a result, creation science also challenges the commonly accepted geologic and astrophysical theories for the age and origins of the Earth and Universe, which creationists acknowledge are irreconcilable to the account in the Book of Genesis. Creation science proponents often refer to the theory of evolution as ""Darwinism"" or as ""Darwinian evolution.""
The creation science texts and curricula that first emerged in the 1960s focused upon concepts derived from a literal interpretation of the Bible and were overtly religious in nature, most notably linking Noah's flood in the Biblical Genesis account to the geological and fossil record in a system termed flood geology. These works attracted little notice beyond the schools and congregations of conservative fundamental and Evangelical Christians until the 1970s when its followers challenged the teaching of evolution in the public schools and other venues in the United States, bringing it to the attention of the public-at-large and the scientific community. Many school boards and lawmakers were persuaded to include the teaching of creation science alongside evolution in the science curriculum. Creation science texts and curricula used in churches and Christian schools were revised to eliminate their Biblical and theological references, and less explicitly sectarian versions of creation science education were introduced in public schools in Louisiana, Arkansas, and other regions in the United States.
The 1982 ruling in McLean v. Arkansas found that creation science fails to meet the essential characteristics of science and that its chief intent is to advance a particular religious view. The teaching of creation science in public schools in the United States effectively ended in 1987 following the United States Supreme Court decision in Edwards v. Aguillard. The court affirmed that a statute requiring the teaching of creation science alongside evolution when evolution is taught in Louisiana public schools was unconstitutional because its sole true purpose was to advance a particular religious belief. In response to this ruling, drafts of the creation science school textbook Of Pandas and People were edited to change references of creation to intelligent design before its publication in 1989. The intelligent design movement promoted this version, then teaching intelligent design in public school science classes was found to be unconstitutional in the 2005 Kitzmiller v. Dover Area School District federal court case."
Scientific journal	"In academic publishing, a scientific journal is a periodical publication intended to further the progress of science, usually by reporting new research. There are thousands of scientific journals in publication, and many more have been published at various points in the past (see list of scientific journals). Most journals are highly specialized, although some of the oldest journals such as Nature publish articles and scientific papers across a wide range of scientific fields. Scientific journals contain articles that have been peer reviewed, in an attempt to ensure that articles meet the journal's standards of quality, and scientific validity. Although scientific journals are superficially similar to professional magazines, they are actually quite different. Issues of a scientific journal are rarely read casually, as one would read a magazine. The publication of the results of research is an essential part of the scientific method. If they are describing experiments or calculations, they must supply enough details that an independent researcher could repeat the experiment or calculation to verify the results. Each such journal article becomes part of the permanent scientific record.
The history of scientific journals dates from 1665, when the French Journal des sçavans and the English Philosophical Transactions of the Royal Society first began systematically publishing research results. Over a thousand, mostly ephemeral, were founded in the 18th century, and the number has increased rapidly after that.
Articles in scientific journals can be used in research and higher education. Scientific articles allow researchers to keep up to date with the developments of their field and direct their own research. An essential part of a scientific article is citation of earlier work. The impact of articles and journals is often assessed by counting citations (citation impact). Some classes are partially devoted to the explication of classic articles, and seminar classes can consist of the presentation by each student of a classic or current paper. Schoolbooks and textbooks have been written usually only on established topics, while the latest research and more obscure topics are only accessible through scientific articles. In a scientific research group or academic department it is usual for the content of current scientific journals to be discussed in journal clubs. Academic credentials for promotion into academic ranks are established in large part by the number and impact of scientific articles published, and many doctoral programs allow for thesis by publication, where the candidate is required to publish a certain number of scientific articles.
The standards that a journal uses to determine publication can vary widely. Some journals, such as Nature, Science, PNAS, and Physical Review Letters, have a reputation of publishing articles that mark a fundamental breakthrough in their respective fields. In many fields, an informal hierarchy of scientific journals exists; the most prestigious journal in a field tends to be the most selective in terms of the articles it will select for publication, and will also have the highest impact factor. It is also common for journals to have a regional focus, specializing in publishing papers from a particular country or other geographic region, like African Invertebrates.
Articles tend to be highly technical, representing the latest theoretical research and experimental results in the field of science covered by the journal. They are often incomprehensible to anyone except for researchers in the field and advanced students. In some subjects this is inevitable given the nature of the content. Usually, rigorous rules of scientific writing are enforced by the editors; however, these rules may vary from journal to journal, especially between journals from different publishers. Articles are usually either original articles reporting completely new results or reviews of current literature. There are also scientific publications that bridge the gap between articles and books by publishing thematic volumes of chapters from different authors."
Scientific method	"The scientific method is a body of techniques for investigating phenomena, acquiring new knowledge, or correcting and integrating previous knowledge. To be termed scientific, a method of inquiry is commonly based on empirical or measurable evidence subject to specific principles of reasoning. The Oxford English Dictionary defines the scientific method as ""a method or procedure that has characterized natural science since the 17th century, consisting in systematic observation, measurement, and experiment, and the formulation, testing, and modification of hypotheses.""
The scientific method is an ongoing process, which usually begins with observations about the natural world. Human beings are naturally inquisitive, so they often come up with questions about things they see or hear and often develop ideas (hypotheses) about why things are the way they are. The best hypotheses lead to predictions that can be tested in various ways, including making further observations about nature. In general, the strongest tests of hypotheses come from carefully controlled and replicated experiments that gather empirical data. Depending on how well the tests match the predictions, the original hypothesis may require refinement, alteration, expansion or even rejection. If a particular hypothesis becomes very well supported a general theory may be developed.
Although procedures vary from one field of inquiry to another, identifiable features are frequently shared in common between them. The overall process of the scientific method involves making conjectures (hypotheses), deriving predictions from them as logical consequences, and then carrying out experiments based on those predictions. A hypothesis is a conjecture, based on knowledge obtained while formulating the question. The hypothesis might be very specific or it might be broad. Scientists then test hypotheses by conducting experiments. Under modern interpretations, a scientific hypothesis must be falsifiable, implying that it is possible to identify a possible outcome of an experiment that conflicts with predictions deduced from the hypothesis; otherwise, the hypothesis cannot be meaningfully tested.
The purpose of an experiment is to determine whether observations agree with or conflict with the predictions derived from a hypothesis. Experiments can take place in a college lab, on a kitchen table, at CERN's Large Hadron Collider, at the bottom of an ocean, on Mars, and so on. There are difficulties in a formulaic statement of method, however. Though the scientific method is often presented as a fixed sequence of steps, it represents rather a set of general principles. Not all steps take place in every scientific inquiry (or to the same degree), and are not always in the same order."
Semiconductor device	"Semiconductor devices are electronic components that exploit the electronic properties of semiconductor materials, principally silicon, germanium, and gallium arsenide, as well as organic semiconductors. Semiconductor devices have replaced thermionic devices (vacuum tubes) in most applications. They use electronic conduction in the solid state as opposed to the gaseous state or thermionic emission in a high vacuum.
Semiconductor devices are manufactured both as single discrete devices and as integrated circuits (ICs), which consist of a number—from a few (as low as two) to billions—of devices manufactured and interconnected on a single semiconductor substrate, or wafer.
Semiconductor materials are useful because their behavior can be easily manipulated by the addition of impurities, known as doping. Semiconductor conductivity can be controlled by the introduction of an electric or magnetic field, by exposure to light or heat, or by the mechanical deformation of a doped monocrystalline grid; thus, semiconductors can make excellent sensors. Current conduction in a semiconductor occurs via mobile or ""free"" electrons and holes, collectively known as charge carriers. Doping a semiconductor such as silicon with a small amount of impurity atoms, such as phosphorus or boron, greatly increases the number of free electrons or holes within the semiconductor. When a doped semiconductor contains excess holes it is called ""p-type"", and when it contains excess free electrons it is known as ""n-type"", where p (positive for holes) or n (negative for electrons) is the sign of the charge of the majority mobile charge carriers. The semiconductor material used in devices is doped under highly controlled conditions in a fabrication facility, or fab, to control precisely the location and concentration of p- and n-type dopants. The junctions which form where n-type and p-type semiconductors join together are called p–n junctions."
Semiotics	"Semiotics (also called semiotic studies; not to be confused with the Saussurean tradition called semiology which is a part of semiotics) is the study of meaning-making, the study of sign processes and meaningful communication. This includes the study of signs and sign processes (semiosis), indication, designation, likeness, analogy, metaphor, symbolism, signification, and communication.
Semiotics is closely related to the field of linguistics, which, for its part, studies the structure and meaning of language more specifically. The semiotic tradition explores the study of signs and symbols as a significant part of communications. As different from linguistics, however, semiotics also studies non-linguistic sign systems. Semiotics is often divided into three branches:
Semantics: relation between signs and the things to which they refer; their signified denotata, or meaning
Syntactics: relations among or between signs in formal structures
Pragmatics: relation between signs and sign-using agents or interpreters
Semiotics is frequently seen as having important anthropological dimensions; for example, the late Italian semiotician and novelist Umberto Eco proposed that every cultural phenomenon may be studied as communication. Some semioticians focus on the logical dimensions of the science, however. They examine areas belonging also to the life sciences—such as how organisms make predictions about, and adapt to, their semiotic niche in the world (see semiosis). In general, semiotic theories take signs or sign systems as their object of study: the communication of information in living organisms is covered in biosemiotics (including zoosemiotics).
Syntactics is the branch of semiotics that deals with the formal properties of signs and symbols. More precisely, syntactics deals with the ""rules that govern how words are combined to form phrases and sentences"". Charles Morris adds that semantics deals with the relation of signs to their designata and the objects that they may or do denote; and, pragmatics deals with the biotic aspects of semiosis, that is, with all the psychological, biological, and sociological phenomena that occur in the functioning of signs."
Smallpox	"Smallpox was an infectious disease caused by either of two virus variants, Variola major and Variola minor. The disease is also known by the Latin names Variola or Variola vera, derived from varius (""spotted"") or varus (""pimple""). The disease was originally known in English as the ""pox"" or ""red plague""; the term ""smallpox"" was first used in Britain in the 15th century to distinguish variola from the ""great pox"" (syphilis). The last naturally occurring case of smallpox (Variola minor) was diagnosed on 26 October 1977.
Infection with smallpox is focused in small blood vessels of the skin and in the mouth and throat before disseminating. In the skin it results in a characteristic maculopapular rash and, later, raised fluid-filled blisters. V. major produced a more serious disease and had an overall mortality rate of 30–35 percent. V. minor caused a milder form of disease (also known as alastrim, cottonpox, milkpox, whitepox, and Cuban itch) which killed about 1 percent of its victims. Long-term complications of V. major infection included characteristic scars, commonly on the face, which occur in 65–85 percent of survivors. Blindness resulting from corneal ulceration and scarring, and limb deformities due to arthritis and osteomyelitis were less common complications, seen in about 2–5 percent of cases.
Smallpox is believed to have emerged in human populations about 10,000 BC. The earliest physical evidence of it is probably the pustular rash on the mummified body of Pharaoh Ramses V of Egypt. The disease killed an estimated 400,000 Europeans annually during the closing years of the 18th century (including five reigning monarchs), and was responsible for a third of all blindness. Of all those infected, 20–60 percent—and over 80 percent of infected children—died from the disease. Smallpox was responsible for an estimated 300–500 million deaths during the 20th century. As recently as 1967, the World Health Organization (WHO) estimated that 15 million people contracted the disease and that two million died in that year.
After vaccination campaigns throughout the 19th and 20th centuries, the WHO certified the global eradication of smallpox in 1979. Smallpox is one of two infectious diseases to have been eradicated, the other being rinderpest, which was declared eradicated in 2011."
Sociology	"Sociology is the study of social behavior or society, including its origins, development, organization, networks, and institutions. It is a social science that uses various methods of empirical investigation and critical analysis to develop a body of knowledge about social order, disorder, and change. Many sociologists aim to conduct research that may be applied directly to social policy and welfare, while others focus primarily on refining the theoretical understanding of social processes. Subject matter ranges from the micro level of individual agency and interaction to the macro level of systems and the social structure.
The traditional focuses of sociology include social stratification, social class, social mobility, religion, secularization, law, sexuality and deviance. As all spheres of human activity are affected by the interplay between social structure and individual agency, sociology has gradually expanded its focus to further subjects, such as health, medical, military and penal institutions, the Internet, education, and the role of social activity in the development of scientific knowledge.
The range of social scientific methods has also expanded. Social researchers draw upon a variety of qualitative and quantitative techniques. The linguistic and cultural turns of the mid-twentieth century led to increasingly interpretative, hermeneutic, and philosophic approaches towards the analysis of society. Conversely, the end of the 1990s and the beginning of 2000s have seen the rise of new analytically, mathematically and computationally rigorous techniques, such as agent-based modelling and social network analysis.
Social research informs politicians and policy makers, educators, planners, lawmakers, administrators, developers, business magnates, managers, social workers, non-governmental organizations, non-profit organizations, and people interested in resolving social issues in general. There is often a great deal of crossover between social research, market research, and other statistical fields."
Space race	"The Space Race was a 20th-century competition between two Cold War rivals, the Soviet Union (USSR) and the United States (US), for supremacy in spaceflight capability. It had its origins in the missile-based nuclear arms race between the two nations that occurred following World War II, enabled by captured German rocket technology and personnel. The technological superiority required for such supremacy was seen as necessary for national security, and symbolic of ideological superiority. The Space Race spawned pioneering efforts to launch artificial satellites, unmanned space probes of the Moon, Venus, and Mars, and human spaceflight in low Earth orbit and to the Moon. The competition began on August 2, 1955, when the Soviet Union responded to the US announcement four days earlier of intent to launch artificial satellites for the International Geophysical Year, by declaring they would also launch a satellite ""in the near future"". The Soviet Union beat the US to this, with the October 4, 1957 orbiting of Sputnik 1, and later beat the US to the first human in space, Yuri Gagarin, on April 12, 1961. The Space Race peaked with the July 20, 1969 US landing of the first humans on the Moon with Apollo 11. The USSR tried but failed manned lunar missions, and eventually cancelled them and concentrated on Earth orbital space stations. A period of détente followed with the April 1972 agreement on a co-operative Apollo–Soyuz Test Project, resulting in the July 1975 rendezvous in Earth orbit of a US astronaut crew with a Soviet cosmonaut crew.
The Space Race has left a legacy of Earth communications and weather satellites, and continuing human space presence on the International Space Station. It has also sparked increases in spending on education and research and development, which led to beneficial spin-off technologies."
Special relativity	"In physics, special relativity (SR, also known as the special theory of relativity or STR) is the generally accepted and experimentally well confirmed physical theory regarding the relationship between space and time. In Einstein's original pedagogical treatment, it is based on two postulates:
that the laws of physics are invariant (i.e. identical) in all inertial systems (non-accelerating frames of reference).
that the speed of light in a vacuum is the same for all observers, regardless of the motion of the light source.
It was originally proposed in 1905 by Albert Einstein in the paper ""On the Electrodynamics of Moving Bodies"". The inconsistency of Newtonian mechanics with Maxwell’s equations of electromagnetism and the lack of experimental confirmation for a hypothesized luminiferous aether led to the development of special relativity, which corrects mechanics to handle situations involving motions nearing the speed of light. As of today, special relativity is the most accurate model of motion at any speed. Even so, the Newtonian mechanics model is still useful (due to its simplicity and high accuracy) as an approximation at small velocities relative to the speed of light.
Special relativity implies a wide range of consequences, which have been experimentally verified, including length contraction, time dilation, relativistic mass, mass–energy equivalence, a universal speed limit and relativity of simultaneity. It has replaced the conventional notion of an absolute universal time with the notion of a time that is dependent on reference frame and spatial position. Rather than an invariant time interval between two events, there is an invariant spacetime interval. Combined with other laws of physics, the two postulates of special relativity predict the equivalence of mass and energy, as expressed in the mass–energy equivalence formula E = mc2, where c is the speed of light in a vacuum.
A defining feature of special relativity is the replacement of the Galilean transformations of Newtonian mechanics with the Lorentz transformations. Time and space cannot be defined separately from each other. Rather space and time are interwoven into a single continuum known as spacetime. Events that occur at the same time for one observer can occur at different times for another.
The theory is ""special"" in that it only applies in the special case where the curvature of spacetime due to gravity is negligible. In order to include gravity, Einstein formulated general relativity in 1915. Special relativity, contrary to some outdated descriptions, is capable of handling accelerated frames of reference.
As Galilean relativity is now considered an approximation of special relativity that is valid for low speeds, special relativity is considered an approximation of general relativity that is valid for weak gravitational fields, i.e. at a sufficiently small scale and in conditions of free fall. Whereas general relativity incorporates noneuclidean geometry in order to represent gravitational effects as the geometric curvature of spacetime, special relativity is restricted to the flat spacetime known as Minkowski space. A locally Lorentz-invariant frame that abides by special relativity can be defined at sufficiently small scales, even in curved spacetime.
Galileo Galilei had already postulated that there is no absolute and well-defined state of rest (no privileged reference frames), a principle now called Galileo's principle of relativity. Einstein extended this principle so that it accounted for the constant speed of light, a phenomenon that had been recently observed in the Michelson–Morley experiment. He also postulated that it holds for all the laws of physics, including both the laws of mechanics and of electrodynamics."
Species	"In biology, a species (abbreviated sp., with the plural form species abbreviated spp.) is one of the basic units of biological classification and a taxonomic rank. A species is often defined as the largest group of organisms in which two individuals are capable of reproducing fertile offspring, typically using sexual reproduction. While in many cases this definition is adequate, the difficulty of defining species is known as the species problem. For example, a species complex is a group of closely related species that are very similar in appearance to the point that the boundaries between them are often unclear. Differentiating measures include similarity of DNA, morphology, or ecological niche. Presence of specific locally adapted traits may further subdivide species into ""infraspecific taxa"" such as subspecies (and in botany other taxa are used, such as varieties, subvarieties, and formae).
Species hypothesized to have the same ancestors are placed in one genus, based on similarities. The similarity of species is judged based on comparison of physical attributes, and where available, their DNA sequences. All species are given a two-part name, a ""binomial name"", or just ""binomial"". The first part of a binomial is the generic name, the genus to which the species belongs. The second part is either called the specific name (a term used only in zoology) or the specific epithet (the term used in botany, which can also be used in zoology). For example, Boa constrictor is one of four species of the Boa genus. While the genus gets capitalized, the specific epithet does not. The binomial is written in italics when printed and underlined when handwritten.

A usable definition of the word ""species"" and reliable methods of identifying particular species are essential for stating and testing biological theories and for measuring biodiversity, though other taxonomic levels such as families may be considered in broad-scale studies. Extinct species known only from fossils are generally difficult to assign precise taxonomic rankings, which is why higher taxonomic levels such as families are often used for fossil-based studies.
The total number of non-bacterial and non-archaeal species in the world has been estimated at 8.7 million, with previous estimates ranging from two million to 100 million."
Star	"A star is a luminous sphere of plasma held together by its own gravity. The nearest star to Earth is the Sun. Other stars are visible to the naked eye from Earth during the night, appearing as a multitude of fixed luminous points in the sky due to their immense distance from Earth. Historically, the most prominent stars were grouped into constellations and asterisms, and the brightest stars gained proper names. Extensive catalogues of stars have been assembled by astronomers, which provide standardized star designations.
For at least a portion of its life, a star shines due to thermonuclear fusion of hydrogen into helium in its core, releasing energy that traverses the star's interior and then radiates into outer space. When the hydrogen in the core of a star is nearly exhausted, almost all naturally occurring elements heavier than helium are created by stellar nucleosynthesis during the star's lifetime and, for some stars, by supernova nucleosynthesis when it explodes. Near the end of its life, a star can also contain degenerate matter. Astronomers can determine the mass, age, metallicity (chemical composition), and many other properties of a star by observing its motion through space, luminosity, and spectrum respectively. The total mass of a star is the principal determinant of its evolution and eventual fate. Other characteristics of a star, including diameter and temperature, change over its life, while the star's environment affects its rotation and movement. A plot of the temperature of many stars against their luminosities, known as a Hertzsprung–Russell diagram (H–R diagram), allows the age and evolutionary state of a star to be determined.
A star's life begins with the gravitational collapse of a gaseous nebula of material composed primarily of hydrogen, along with helium and trace amounts of heavier elements. When the stellar core is sufficiently dense, hydrogen becomes steadily converted into helium through nuclear fusion, releasing energy in the process. The remainder of the star's interior carries energy away from the core through a combination of radiative and convective processes. The star's internal pressure prevents it from collapsing further under its own gravity. When the hydrogen fuel at the core is exhausted, a star with at least 0.4 times the mass of the Sun expands to become a red giant, in some cases fusing heavier elements at the core or in shells around the core. The star then evolves into a degenerate form, recycling a portion of its matter into the interstellar environment, where it will contribute to the formation of a new generation of stars with a higher proportion of heavy elements. Meanwhile, the core becomes a stellar remnant: a white dwarf, a neutron star, or (if it is sufficiently massive) a black hole.
Binary and multi-star systems consist of two or more stars that are gravitationally bound, and generally move around each other in stable orbits. When two such stars have a relatively close orbit, their gravitational interaction can have a significant impact on their evolution. Stars can form part of a much larger gravitationally bound structure, such as a star cluster or a galaxy."
Statistics	"Statistics is the study of the collection, analysis, interpretation, presentation, and organization of data. In applying statistics to, e.g., a scientific, industrial, or societal problem, it is conventional to begin with a statistical population or a statistical model process to be studied. Populations can be diverse topics such as ""all people living in a country"" or ""every atom composing a crystal"". Statistics deals with all aspects of data including the planning of data collection in terms of the design of surveys and experiments.
When census data cannot be collected, statisticians collect data by developing specific experiment designs and survey samples. Representative sampling assures that inferences and conclusions can safely extend from the sample to the population as a whole. An experimental study involves taking measurements of the system under study, manipulating the system, and then taking additional measurements using the same procedure to determine if the manipulation has modified the values of the measurements. In contrast, an observational study does not involve experimental manipulation.
Two main statistical methodologies are used in data analysis: descriptive statistics, which summarizes data from a sample using indexes such as the mean or standard deviation, and inferential statistics, which draws conclusions from data that are subject to random variation (e.g., observational errors, sampling variation). Descriptive statistics are most often concerned with two sets of properties of a distribution (sample or population): central tendency (or location) seeks to characterize the distribution's central or typical value, while dispersion (or variability) characterizes the extent to which members of the distribution depart from its center and each other. Inferences on mathematical statistics are made under the framework of probability theory, which deals with the analysis of random phenomena.
A standard statistical procedure involves the test of the relationship between two statistical data sets, or a data set and a synthetic data drawn from idealized model. An hypothesis is proposed for the statistical relationship between the two data sets, and this is compared as an alternative to an idealized null hypothesis of no relationship between two data sets. Rejecting or disproving the null hypothesis is done using statistical tests that quantify the sense in which the null can be proven false, given the data that are used in the test. Working from a null hypothesis, two basic forms of error are recognized: Type I errors (null hypothesis is falsely rejected giving a ""false positive"") and Type II errors (null hypothesis fails to be rejected and an actual difference between populations is missed giving a ""false negative""). Multiple problems have come to be associated with this framework: ranging from obtaining a sufficient sample size to specifying an adequate null hypothesis.
Measurement processes that generate statistical data are also subject to error. Many of these errors are classified as random (noise) or systematic (bias), but other types of errors (e.g., blunder, such as when an analyst reports incorrect units) can also be important. The presence of missing data and/or censoring may result in biased estimates and specific techniques have been developed to address these problems.
Statistics can be said to have begun in ancient civilization, going back at least to the 5th century BC, but it was not until the 18th century that it started to draw more heavily from calculus and probability theory. Statistics continues to be an area of active research, for example on the problem of how to analyze Big data."
String theory	"In physics, string theory is a theoretical framework in which the point-like particles of particle physics are replaced by one-dimensional objects called strings. It describes how these strings propagate through space and interact with each other. On distance scales larger than the string scale, a string looks just like an ordinary particle, with its mass, charge, and other properties determined by the vibrational state of the string. In string theory, one of the many vibrational states of the string corresponds to the graviton, a quantum mechanical particle that carries gravitational force. Thus string theory is a theory of quantum gravity.
String theory is a broad and varied subject that attempts to address a number of deep questions of fundamental physics. String theory has been applied to a variety of problems in black hole physics, early universe cosmology, nuclear physics, and condensed matter physics, and it has stimulated a number of major developments in pure mathematics. Because string theory potentially provides a unified description of gravity and particle physics, it is a candidate for a theory of everything, a self-contained mathematical model that describes all fundamental forces and forms of matter. Despite much work on these problems, it is not known to what extent string theory describes the real world or how much freedom the theory allows to choose the details.
String theory was first studied in the late 1960s as a theory of the strong nuclear force, before being abandoned in favor of quantum chromodynamics. Subsequently, it was realized that the very properties that made string theory unsuitable as a theory of nuclear physics made it a promising candidate for a quantum theory of gravity. The earliest version of string theory, bosonic string theory, incorporated only the class of particles known as bosons. It later developed into superstring theory, which posits a connection called supersymmetry between bosons and the class of particles called fermions. Five consistent versions of superstring theory were developed before it was conjectured in the mid-1990s that they were all different limiting cases of a single theory in eleven dimensions known as M-theory. In late 1997, theorists discovered an important relationship called the AdS/CFT correspondence, which relates string theory to another type of physical theory called a quantum field theory.
One of the challenges of string theory is that the full theory does not yet have a satisfactory definition in all circumstances. Another issue is that the theory is thought to describe an enormous landscape of possible universes, and this has complicated efforts to develop theories of particle physics based on string theory. These issues have led some in the community to criticize these approaches to physics and question the value of continued research on string theory unification."
Syriac language	"Syriac /ˈsɪriæk/ (ܠܫܢܐ ܣܘܪܝܝܐ Leššānā Suryāyā), also known as Syriac Aramaic, is a dialect of Middle Aramaic that was once spoken across much of the Fertile Crescent and Eastern Arabia. Having first appeared in the early first century AD in Edessa, classical Syriac became a major literary language throughout the Middle East from the 4th to the 8th centuries, the classical language of Edessa, preserved in a large body of Syriac literature. Indeed, Syriac literature comprises roughly 90% of the extant Aramaic literature.
Old Aramaic was adopted by the Neo-Assyrian Empire (911-605 BC) when they conquered the various Aramean city-kingdoms to its west. The Achaemenid Empire, which rose after the fall of the Assyrian Empire, also adopted Old Aramaic as its official language and Old Aramaic quickly became the lingua franca of the region. During the course of the third and fourth centuries AD, the inhabitants of the region began to embrace Christianity.
Along with Latin and Greek, Syriac became one of ""the three most important Christian languages in the early centuries"" of the Christian Era. From the 1st century AD Syriac became the vehicle of Syriac Christianity and culture, and the liturgical language of the Syriac Orthodox Church and subsequently the Church of the East, along with its descendants: the Chaldean Catholic Church, the Assyrian Church of the East, the Ancient Church of the East, the Saint Thomas Christian Churches, and the Assyrian Pentecostal Church.
Syriac Christianity and language spread throughout Asia as far as the Indian Malabar Coast and Eastern China, and was the medium of communication and cultural dissemination for the later Arabs and, to a lesser extent, the Parthian Empire and Sassanid Empire Persians. Primarily a Christian medium of expression, Syriac had a fundamental cultural and literary influence on the development of Arabic, which largely replaced it towards the 14th century. Syriac remains the liturgical language of Syriac Christianity to this day.
Syriac is a Middle Aramaic language and, as such, a language of the Northwestern branch of the Semitic family. It is written in the Syriac alphabet, a derivation of the Aramaic alphabet."
Targeted therapy	"Targeted therapy or molecularly targeted therapy is one of the major modalities of medical treatment (pharmacotherapy) for cancer, others being hormonal therapy and cytotoxic chemotherapy. As a form of molecular medicine, targeted therapy blocks the growth of cancer cells by interfering with specific targeted molecules needed for carcinogenesis and tumor growth, rather than by simply interfering with all rapidly dividing cells (e.g. with traditional chemotherapy). Because most agents for targeted therapy are biopharmaceuticals, the term biologic therapy is sometimes synonymous with targeted therapy when used in the context of cancer therapy (and thus distinguished from chemotherapy, that is, cytotoxic therapy). However, the modalities can be combined; antibody-drug conjugates combine biologic and cytotoxic mechanisms into one targeted therapy.
Targeted cancer therapies are expected to be more effective than older forms of treatments and less harmful to normal cells. Many targeted therapies are examples of immunotherapy (using immune mechanisms for therapeutic goals) developed by the field of cancer immunology. Thus, as immunomodulators, they are one type of biological response modifiers.
The most successful targeted therapies are chemical entities that target or preferentially target a protein or enzyme that carries a mutation or other genetic alteration that is specific to cancer cells and not found in normal host tissue. One of the most successful molecular targeted therapeutic is Gleevec, which is a kinase inhibitor with exceptional affinity for the oncofusion protein BCR-Abl which is a strong driver of tumorigenesis in Chronic Myelogenous Leukemia. Although employed in other indications, Gleevec is most effective targeting BCR-Abl. Other examples of molecular targeted therapeutics targeting mutated oncogenes, include PLX27892 which targets mutant B-raf in melanoma.
There are targeted therapies for breast cancer, multiple myeloma, lymphoma, prostate cancer, melanoma and other cancers.
The definitive experiments that showed that targeted therapy would reverse the malignant phenotype of tumor cells involved treating Her2/neu transformed cells with monoclonal antibodies in vitro and in vivo by Mark Greene’s laboratory and reported from 1985.
Some have challenged the use of the term, stating that drugs usually associated with the term are insufficiently selective. The phrase occasionally appears in scare quotes: ""targeted therapy"". Targeted therapies may also be described as ""chemotherapy"" or ""non-cytotoxic chemotherapy"", as ""chemotherapy"" strictly means only ""treatment by chemicals"". But in typical medical and general usage ""chemotherapy"" is now mostly used specifically for ""traditional"" cytotoxic chemotherapy."
Technology	"Technology (""science of craft"", from Greek τέχνη, techne, ""art, skill, cunning of hand""; and -λογία, -logia) is the collection of techniques, skills, methods and processes used in the production of goods or services or in the accomplishment of objectives, such as scientific investigation. Technology can be the knowledge of techniques, processes, etc. or it can be embedded in machines, computers, devices and factories, which can be operated by individuals without detailed knowledge of the workings of such things.
The human species' use of technology began with the conversion of natural resources into simple tools. The prehistoric discovery of how to control fire and the later Neolithic Revolution increased the available sources of food and the invention of the wheel helped humans to travel in and control their environment. Developments in historic times, including the printing press, the telephone, and the Internet, have lessened physical barriers to communication and allowed humans to interact freely on a global scale. The steady progress of military technology has brought weapons of ever-increasing destructive power, from clubs to nuclear weapons.
Technology has many effects. It has helped develop more advanced economies (including today's global economy) and has allowed the rise of a leisure class. Many technological processes produce unwanted by-products, known as pollution, and deplete natural resources, to the detriment of Earth's environment. Various implementations of technology influence the values of a society and new technology often raises new ethical questions. Examples include the rise of the notion of efficiency in terms of human productivity, a term originally applied only to machines, and the challenge of traditional norms.
Philosophical debates have arisen over the use of technology, with disagreements over whether technology improves the human condition or worsens it. Neo-Luddism, anarcho-primitivism, and similar reactionary movements criticise the pervasiveness of technology in the modern world, arguing that it harms the environment and alienates people; proponents of ideologies such as transhumanism and techno-progressivism view continued technological progress as beneficial to society and the human condition.
Until recently, it was believed that the development of technology was restricted only to human beings, but 21st century scientific studies indicate that other primates and certain dolphin communities have developed simple tools and passed their knowledge to other generations."
Telecommunications	"Telecommunication is – according to Article 1.3 of the International Telecommunication Union's (ITU) Radio Regulations (RR) – defined as ""Any transmission, emission or reception of signs, signals, writings, images and sounds or intelligence of any nature by wire, radio, optical or other electromagnetic systems."" This definition is also identical to those contained in the Annex to the Constitution and Convention of the International Telecommunication Union (Geneva, 1992).
Telecommunication occurs when the exchange of information between two or more entities (communication) includes the use of technology. Communication technology uses channels to transmit information (as electrical signals), either over a physical medium (such as signal cables), or in the form of electromagnetic waves. The word is often used in its plural form, telecommunications, because it involves many different technologies.
Early means of communicating over a distance included visual signals, such as beacons, smoke signals, semaphore telegraphs, signal flags, and optical heliographs. Other examples of pre-modern long-distance communication included audio messages such as coded drumbeats, lung-blown horns, and loud whistles. Modern technologies for long-distance communication usually involve electrical and electromagnetic technologies, such as telegraph, telephone, and teleprinter, networks, radio, microwave transmission, fiber optics, and communications satellites.
A revolution in wireless communication began in the first decade of the 20th century with the pioneering developments in radio communications by Guglielmo Marconi, who won the Nobel Prize in Physics in 1909. Other highly notable pioneering inventors and developers in the field of electrical and electronic telecommunications include Charles Wheatstone and Samuel Morse (telegraph), Alexander Graham Bell (telephone), Edwin Armstrong, and Lee de Forest (radio), as well as Vladimir K. Zworykin, John Logie Baird and Philo Farnsworth (television)."
Television	"Television or TV is a telecommunication medium used for transmitting sound with moving images in monochrome (black-and-white), or in color, and in two or three dimensions. It can refer to a television set, a television program, or the medium of television transmission. Television is a mass medium, for entertainment, education, news and advertising.
Television became available in crude experimental forms in the late 1920s. After World War II, an improved form became popular in the United States and Britain, and television sets became commonplace in homes, businesses, and institutions. During the 1950s, television was the primary medium for influencing public opinion. In the mid-1960s, color broadcasting was introduced in the US and most other developed countries. The availability of storage media such as VHS tape (1976), DVDs (1997), and high-definition Blu-ray Discs (2006) enabled viewers to watch prerecorded material such as movies. At the end of the first decade of the 2000s, digital television transmissions greatly increased in popularity. Another development was the move from standard-definition television (SDTV) (576i, with 576 interlaced lines of resolution and 480i) to high-definition television (HDTV), which provides a resolution that is substantially higher. HDTV may be transmitted in various formats: 1080p, 1080i and 720p. Since 2010, with the invention of smart television, Internet television has increased the availability of television programs and movies via the Internet through services such as Netflix, iPlayer, Hulu, Roku and Chromecast.
In 2013, 79% of the world's households owned a television set. The replacement of early bulky, high-voltage cathode ray tube (CRT) screen displays with compact, energy-efficient, flat-panel alternative technologies such as plasma displays, LCDs (both fluorescent-backlit and LED), and OLED displays was a hardware revolution that began with computer monitors in the late 1990s. Most TV sets sold in the 2000s were flat-panel, mainly LEDs. Major manufacturers announced the discontinuation of CRT, DLP, plasma, and even fluorescent-backlit LCDs by the mid-2010s. LEDs are expected to be replaced gradually by OLEDs in the near future. Also, major manufacturers have announced that they will increasingly produce smart TV sets in the mid-2010s. Smart TVs with integrated Internet and Web 2.0 functions became the dominant form of television by the late 2010s.
Television signals were initially distributed only as terrestrial television using high-powered radio-frequency transmitters to broadcast the signal to individual television receivers. Alternatively television signals are distributed by coaxial cable or optical fibre, satellite systems and via the Internet. Until the early 2000s, these were transmitted as analog signals but countries started switching to digital, this transition is expected to be completed worldwide by late 2010s. A standard television set is composed of multiple internal electronic circuits, including a tuner for receiving and decoding broadcast signals. A visual display device which lacks a tuner is correctly called a video monitor rather than a television."
The Structure of Scientific Revolutions	"The Structure of Scientific Revolutions (1962; second edition 1970) is a book about the history of science by philosopher Thomas S. Kuhn. Its publication was a landmark event in the history, philosophy, and sociology of scientific knowledge and triggered an ongoing worldwide assessment and reaction in—and beyond—those scholarly communities. Kuhn challenged the then prevailing view of progress in ""normal science."" Normal scientific progress was viewed as ""development-by-accumulation"" of accepted facts and theories. Kuhn argued for an episodic model in which periods of such conceptual continuity in normal science were interrupted by periods of revolutionary science. The discovery of ""anomalies"" during revolutions in science leads to new paradigms. New paradigms then ask new questions of old data, move beyond the mere ""puzzle-solving"" of the previous paradigm, change the rules of the game and the ""map"" directing new research.
For example, Kuhn's analysis of the Copernican Revolution emphasized that, in its beginning, it did not offer more accurate predictions of celestial events, such as planetary positions, than the Ptolemaic system, but instead appealed to some practitioners based on a promise of better, simpler, solutions that might be developed at some point in the future. Kuhn called the core concepts of an ascendant revolution its ""paradigms"" and thereby launched this word into widespread analogical use in the second half of the 20th century. Kuhn's insistence that a paradigm shift was a mélange of sociology, enthusiasm and scientific promise, but not a logically determinate procedure, caused an uproar in reaction to his work. Kuhn addressed concerns in the 1969 postscript to the second edition. For some commentators Kuhn's book introduced a realistic humanism into the core of science while for others the nobility of science was tarnished by Kuhn's introduction of an irrational element into the heart of its greatest achievements."
Theorem	"In mathematics, a theorem is a statement that has been proven on the basis of previously established statements, such as other theorems—and generally accepted statements, such as axioms. A theorem is a logical consequence of the axioms. The proof of a mathematical theorem is a logical argument for the theorem statement given in accord with the rules of a deductive system. The proof of a theorem is often interpreted as justification of the truth of the theorem statement. In light of the requirement that theorems be proved, the concept of a theorem is fundamentally deductive, in contrast to the notion of a scientific law, which is experimental.
Many mathematical theorems are conditional statements. In this case, the proof deduces the conclusion from conditions called hypotheses or premises. In light of the interpretation of proof as justification of truth, the conclusion is often viewed as a necessary consequence of the hypotheses, namely, that the conclusion is true in case the hypotheses are true, without any further assumptions. However, the conditional could be interpreted differently in certain deductive systems, depending on the meanings assigned to the derivation rules and the conditional symbol.
Although they can be written in a completely symbolic form, for example, within the propositional calculus, theorems are often expressed in a natural language such as English. The same is true of proofs, which are often expressed as logically organized and clearly worded informal arguments, intended to convince readers of the truth of the statement of the theorem beyond any doubt, and from which a formal symbolic proof can in principle be constructed. Such arguments are typically easier to check than purely symbolic ones—indeed, many mathematicians would express a preference for a proof that not only demonstrates the validity of a theorem, but also explains in some way why it is obviously true. In some cases, a picture alone may be sufficient to prove a theorem. Because theorems lie at the core of mathematics, they are also central to its aesthetics. Theorems are often described as being ""trivial"", or ""difficult"", or ""deep"", or even ""beautiful"". These subjective judgments vary not only from person to person, but also with time: for example, as a proof is simplified or better understood, a theorem that was once difficult may become trivial. On the other hand, a deep theorem may be simply stated, but its proof may involve surprising and subtle connections between disparate areas of mathematics. Fermat's Last Theorem is a particularly well-known example of such a theorem."
Theory	"Theory is a contemplative and rational type of abstract or generalizing thinking, or the results of such thinking. Depending on the context, the results might for example include generalized explanations of how nature works. The word has its roots in ancient Greek, but in modern use it has taken on several different related meanings. A theory is not the same as a hypothesis. A theory provides an explanatory framework for some observation, and from the assumptions of the explanation follows a number of possible hypotheses that can be tested in order to provide support for, or challenge, the theory.
A theory can be normative (or prescriptive), meaning a postulation about what ought to be. It provides ""goals, norms, and standards"". A theory can be a body of knowledge, which may or may not be associated with particular explanatory models. To theorize is to develop this body of knowledge.
As already in Aristotle's definitions, theory is very often contrasted to ""practice"" (from Greek praxis, πρᾶξις) a Greek term for ""doing"", which is opposed to theory because pure theory involves no doing apart from itself. A classical example of the distinction between ""theoretical"" and ""practical"" uses the discipline of medicine: medical theory involves trying to understand the causes and nature of health and sickness, while the practical side of medicine is trying to make people healthy. These two things are related but can be independent, because it is possible to research health and sickness without curing specific patients, and it is possible to cure a patient without knowing how the cure worked.
In modern science, the term ""theory"" refers to scientific theories, a well-confirmed type of explanation of nature, made in a way consistent with scientific method, and fulfilling the criteria required by modern science. Such theories are described in such a way that any scientist in the field is in a position to understand and either provide empirical support (""verify"") or empirically contradict (""falsify"") it. Scientific theories are the most reliable, rigorous, and comprehensive form of scientific knowledge, in contrast to more common uses of the word ""theory"" that imply that something is unproven or speculative (which is better characterized by the word 'hypothesis'). Scientific theories are distinguished from hypotheses, which are individual empirically testable conjectures, and scientific laws, which are descriptive accounts of how nature will behave under certain conditions."
Theory (science)	"A scientific theory is a well-substantiated explanation of some aspect of the natural world that is acquired through the scientific method and repeatedly tested and confirmed through observation and experimentation. Scientific theories are the most reliable, rigorous, and comprehensive form of scientific knowledge.
It is important to note that the definition of a ""scientific theory"" (often ambiguously contracted to ""theory"" for the sake of brevity, including in this page) as used in the disciplines of science is significantly different from, and in contrast to, the common vernacular usage of the word ""theory"". As used in everyday non-scientific speech, ""theory"" implies that something is an unsubstantiated and speculative guess, conjecture, or hypothesis; such a usage is the opposite of a scientific theory. These different usages are comparable to the differing, and often opposing, usages of the term ""prediction"" in science (less ambiguously called a ""scientific prediction"") versus ""prediction"" in non-scientific vernacular speech, the latter of which may even imply a mere hope.
The strength of a scientific theory is related to the diversity of phenomena it can explain, and to its elegance and simplicity (see Occam's razor). As additional scientific evidence is gathered, a scientific theory may be rejected or modified if it does not fit the new empirical findings; in such circumstances, a more accurate theory is then desired. In certain cases, the less-accurate unmodified scientific theory can still be treated as a theory if it is useful (due to its sheer simplicity) as an approximation under specific conditions (e.g., Newton's laws of motion as an approximation to special relativity at velocities which are small relative to the speed of light).
Scientific theories are usually testable and make falsifiable predictions. They describe the causal elements responsible for a particular natural phenomenon, and are used to explain and predict aspects of the physical universe or specific areas of inquiry (e.g., electricity, chemistry, astronomy). Scientists use theories as a foundation to gain further scientific knowledge, as well as to accomplish goals such as inventing technology or curing disease.
As with most, if not all, forms of scientific knowledge, scientific theories are inductive in nature and aim for predictive power and explanatory capability."
Thermodynamics	"Thermodynamics is a branch of physics concerned with heat and temperature and their relation to energy and work. It defines macroscopic variables, such as internal energy, entropy, and pressure, that partly describe a body of matter or radiation. It states that the behavior of those variables is subject to general constraints, that are common to all materials, beyond the peculiar properties of particular materials. These general constraints are expressed in the four laws of thermodynamics. Thermodynamics describes the bulk behavior of the body, not the microscopic behaviors of the very large numbers of its microscopic constituents, such as molecules. The basic results of thermodynamics rely on the existence of idealized states of thermodynamic equilibrium. Its laws are explained by statistical mechanics, in terms of the microscopic constituents.
Thermodynamics applies to a wide variety of topics in science and engineering, especially physical chemistry, chemical engineering and mechanical engineering.
Historically, the distinction between heat and temperature was studied in the 1750s by Joseph Black. Characteristically thermodynamic thinking began in the work of Carnot (1824) who believed that the efficiency of heat engines was the key that could help France win the Napoleonic Wars. The Irish-born British physicist Lord Kelvin was the first to formulate a concise definition of thermodynamics in 1854:

Thermo-dynamics is the subject of the relation of heat to forces acting between contiguous parts of bodies, and the relation of heat to electrical agency.

Initially, thermodynamics, as applied to heat engines, was concerned with the thermal properties of their 'working materials', such as steam, in an effort to increase the efficiency and power output of engines. Thermodynamics was later expanded to the study of energy transfers in chemical processes, such as the investigation, published in 1840, of the heats of chemical reactions by Germain Hess, which was not originally explicitly concerned with the relation between energy exchanges by heat and work. From this evolved the study of chemical thermodynamics and the role of entropy in chemical reactions."
Topology	"In mathematics, topology (from the Greek τόπος, place, and λόγος, study) is concerned with the properties of space that are preserved under continuous deformations, such as stretching and bending, but not tearing or gluing. This can be studied by considering a collection of subsets, called open sets, that satisfy certain properties, turning the given set into what is known as a topological space. Important topological properties include connectedness and compactness.
Topology developed as a field of study out of geometry and set theory, through analysis of such concepts as space, dimension, and transformation. Such ideas go back to Gottfried Leibniz, who in the 17th century envisioned the geometria situs (Greek-Latin for ""geometry of place"") and analysis situs (Greek-Latin for ""picking apart of place""). Leonhard Euler's Seven Bridges of Königsberg Problem and Polyhedron Formula are arguably the field's first theorems. The term topology was introduced by Johann Benedict Listing in the 19th century, although it was not until the first decades of the 20th century that the idea of a topological space was developed. By the middle of the 20th century, topology had become a major branch of mathematics.
Topology has many subfields:
General topology establishes the foundational aspects of topology and investigates properties of topological spaces and concepts inherent to topological spaces. It includes point-set topology, which is the foundational topology used in all other branches (including topics like compactness and connectedness).
Algebraic topology tries to measure degrees of connectivity using algebraic constructs such as homology and homotopy groups.
Differential topology is the field dealing with differentiable functions on differentiable manifolds. It is closely related to differential geometry and together they make up the geometric theory of differentiable manifolds.
Geometric topology primarily studies manifolds and their embeddings (placements) in other manifolds. A particularly active area is low-dimensional topology, which studies manifolds of four or fewer dimensions. This includes knot theory, the study of mathematical knots."
Trial and error	"Trial and error is a fundamental method of solving problems. It is characterised by repeated, varied attempts which are continued until success, or until the agent stops trying.
According to W.H. Thorpe, the term was devised by C. Lloyd Morgan after trying out similar phrases ""trial and failure"" and ""trial and practice"". Under Morgan's Canon, animal behaviour should be explained in the simplest possible way. Where behaviour seems to imply higher mental processes, it might be explained by trial-and-error learning. An example is the skillful way in which his terrier Tony opened the garden gate, easily misunderstood as an insightful act by someone seeing the final behaviour. Lloyd Morgan, however, had watched and recorded the series of approximations by which the dog had gradually learned the response, and could demonstrate that no insight was required to explain it.
Edward Thorndike showed how to manage a trial-and-error experiment in the laboratory. In his famous experiment, a cat was placed in a series of puzzle boxes in order to study the law of effect in learning. He plotted learning curves which recorded the timing for each trial. Thorndike's key observation was that learning was promoted by positive results, which was later refined and extended by B.F. Skinner's operant conditioning.
Trial and error is also a heuristic method of problem solving, repair, tuning, or obtaining knowledge. In the field of computer science, the method is called generate and test. In elementary algebra, when solving equations, it is ""guess and check"".
This approach can be seen as one of the two basic approaches to problem solving, contrasted with an approach using insight and theory. However, there are intermediate methods which for example, use theory to guide the method, an approach known as guided empiricism."
Trigonometry	"Trigonometry (from Greek trigōnon, ""triangle"" and metron, ""measure"") is a branch of mathematics that studies relationships involving lengths and angles of triangles. The field emerged in the Hellenistic world during the 3rd century BC from applications of geometry to astronomical studies.
The 3rd-century astronomers first noted that the lengths of the sides of a right-angle triangle and the angles between those sides have fixed relationships: that is, if at least the length of one side and the value of one angle is known, then all other angles and lengths can be determined algorithmically. These calculations soon came to be defined as the trigonometric functions and today are pervasive in both pure and applied mathematics: fundamental methods of analysis such as the Fourier transform, for example, or the wave equation, use trigonometric functions to understand cyclical phenomena across many applications in fields as diverse as physics, mechanical and electrical engineering, music and acoustics, astronomy, ecology, and biology. Trigonometry is also the foundation of surveying.
Trigonometry is most simply associated with planar right-angle triangles (each of which is a two-dimensional triangle with one angle equal to 90 degrees). The applicability to non-right-angle triangles exists, but, since any non-right-angle triangle (on a flat plane) can be bisected to create two right-angle triangles, most problems can be reduced to calculations on right-angle triangles. Thus the majority of applications relate to right-angle triangles. One exception to this is spherical trigonometry, the study of triangles on spheres, surfaces of constant positive curvature, in elliptic geometry (a fundamental part of astronomy and navigation). Trigonometry on surfaces of negative curvature is part of hyperbolic geometry.
Trigonometry basics are often taught in schools, either as a separate course or as a part of a precalculus course."
Truth	"Truth is most often used to mean being in accord with fact or reality, or fidelity to an original or standard. Truth may also often be used in modern contexts to refer to an idea of ""truth to self,"" or authenticity.
The commonly understood opposite of truth is falsehood, which, correspondingly, can also take on a logical, factual, or ethical meaning. The concept of truth is discussed and debated in several contexts, including philosophy, art, and religion. Many human activities depend upon the concept, where its nature as a concept is assumed rather than being a subject of discussion; these include most (but not all) of the sciences, law, journalism, and everyday life. Some philosophers view the concept of truth as basic, and unable to be explained in any terms that are more easily understood than the concept of truth itself. Commonly, truth is viewed as the correspondence of language or thought to an independent reality, in what is sometimes called the correspondence theory of truth.
Other philosophers take this common meaning to be secondary and derivative. According to Martin Heidegger, the original meaning and essence of ""Truth"" in Ancient Greece was unconcealment, or the revealing or bringing of what was previously hidden into the open, as indicated by the original Greek term for truth, ""Aletheia."" On this view, the conception of truth as correctness is a later derivation from the concept's original essence, a development Heidegger traces to the Latin term ""Veritas.""
Pragmatists like C.S. Pierce take Truth to have some manner of essential relation to human practices for inquiring into and discovering Truth, with Pierce himself holding that Truth is what human inquiry would find out on a matter, if our practice of inquiry were taken as far as it could profitably go: ""The opinion which is fated to be ultimately agreed to by all who investigate, is what we mean by the truth...""
Various theories and views of truth continue to be debated among scholars, philosophers, and theologians. Language and words are a means by which humans convey information to one another and the method used to determine what is a ""truth"" is termed a criterion of truth. There are differing claims on such questions as what constitutes truth: what things are truthbearers capable of being true or false; how to define and identify truth; the roles that faith-based and empirically based knowledge play; and whether truth is subjective or objective, relative or absolute.
Friedrich Nietzsche famously suggested that an ancient, metaphysical belief in the divinity of Truth lies at the heart of and has served as the foundation for the entire subsequent Western intellectual tradition: ""But you will have gathered what I am getting at, namely, that it is still a metaphysical faith on which our faith in science rests--that even we knowers of today, we godless anti-metaphysicians still take our fire too, from the flame lit by the thousand-year old faith, the Christian faith which was also Plato's faith, that God is Truth; that Truth is 'Divine'..."""
Two New Sciences	"The Discourses and Mathematical Demonstrations Relating to Two New Sciences (Italian: Discorsi e Dimostrazioni Matematiche Intorno a Due Nuove Scienze, pronounced [diˈskorsi e dimostratˈtsjoːni mateˈmaːtike inˈtorno a ˈduːe ˈnwɔːve ˈʃɛntse]), published in 1638 was Galileo's final book and a scientific testament covering much of his work in physics over the preceding thirty years.
After his Dialogue Concerning the Two Chief World Systems, the Roman Inquisition had banned the publication of any of Galileo's works, including any he might write in the future. After the failure of his initial attempts to publish Two New Sciences in France, Germany, and Poland, it was published by Lodewijk Elzevir who was working in Leiden, South Holland, where the writ of the Inquisition was of less consequence (see House of Elzevir). Fra Fulgenzio Micanzio, the official theologian of the Republic of Venice, had initially offered to help Galileo publish in Venice the new work, but he pointed out that publishing the 'Two New Sciences' in Venice might cause Galileo unnecessary trouble; thus, the book was eventually published in Holland. Galileo did not seem to suffer any harm from the Inquisition for publishing this book since in January 1639, the book reached Rome's bookstores, and all available copies (about fifty) were quickly sold and everyone seemed to like it.
Discourses was written in a style similar to Dialogues, in which three men (Simplicio, Sagredo, and Salviati) discuss and debate the various questions Galileo is seeking to answer. There is a notable change in the men, however; Simplicio, in particular, is no longer quite as simple-minded and stubborn an Aristotelian as his name implies. His arguments are representative of Galileo's own early beliefs, as Sagredo represents his middle period, and Salviati proposes Galileo's newest models."
Tycho's observational astronomy	"Tycho Brahe (/ˌtaɪkoʊ ˈbrɑːhi, ˈbrɑːᵊ/), born Tyge Ottesen Brahe (Danish: [ˈtˢyːə ˈʌd̥əsn̩ ˈb̥ʁɑː]; 14 December 1546 – 24 October 1601), was a Danish nobleman known for his accurate and comprehensive astronomical and planetary observations. He was born in Scania, then part of Denmark, now part of Sweden. Tycho was well known in his lifetime as an astronomer, astrologer and alchemist, and has been described more recently as ""the first competent mind in modern astronomy to feel ardently the passion for exact empirical facts.""
In his De nova stella (On the New Star) of 1573, he refuted the Aristotelian belief in an unchanging celestial realm. His precise measurements indicated that ""new stars"" (stellae novae, now known as supernovae), in particular that of 1572, lacked the parallax expected in sublunar phenomena and were therefore not tailless comets in the atmosphere as previously believed but were above the atmosphere and beyond the moon. Using similar measurements he showed that comets were also not atmospheric phenomena, as previously thought, and must pass through the supposedly immutable celestial spheres.
As an astronomer, Tycho worked to combine what he saw as the geometrical benefits of the Copernican system with the philosophical benefits of the Ptolemaic system into his own model of the universe, the Tychonic system. Furthermore, he was the last of the major naked eye astronomers, working without telescopes for his observations.
Tycho was granted an estate on the island of Hven and the funding to build Uraniborg, an early research institute, where he built large astronomical instruments and took many careful measurements, and later Stjerneborg, underground, when he discovered that his instruments in Uraniborg were not sufficiently steady. On the island (where he behaved autocratically toward the residents) he founded manufactories, such as a paper mill, to provide material for printing his results.
After disagreements with the new Danish king, Christian IV, in 1597, he was invited by the Bohemian king and Holy Roman emperor Rudolph II to Prague, where he became the official imperial astronomer. He built an observatory at Benátky nad Jizerou. There, from 1600 until his death in 1601, he was assisted by Johannes Kepler, who later used Tycho's astronomical data to develop his three laws of planetary motion.
Tycho's body has been exhumed twice, in 1901 and 2010, to examine the circumstances of his death and to identify the material from which his artificial nose was made. The conclusion was that his death was likely caused by a burst bladder, as had been suggested, and that the artificial nose was more likely made of brass than silver or gold, as some had believed in his time."
Tycho Brahe	"Tycho Brahe (/ˌtaɪkoʊ ˈbrɑːhi, ˈbrɑːᵊ/), born Tyge Ottesen Brahe (Danish: [ˈtˢyːə ˈʌd̥əsn̩ ˈb̥ʁɑː]; 14 December 1546 – 24 October 1601), was a Danish nobleman known for his accurate and comprehensive astronomical and planetary observations. He was born in Scania, then part of Denmark, now part of Sweden. Tycho was well known in his lifetime as an astronomer, astrologer and alchemist, and has been described more recently as ""the first competent mind in modern astronomy to feel ardently the passion for exact empirical facts.""
In his De nova stella (On the New Star) of 1573, he refuted the Aristotelian belief in an unchanging celestial realm. His precise measurements indicated that ""new stars"" (stellae novae, now known as supernovae), in particular that of 1572, lacked the parallax expected in sublunar phenomena and were therefore not tailless comets in the atmosphere as previously believed but were above the atmosphere and beyond the moon. Using similar measurements he showed that comets were also not atmospheric phenomena, as previously thought, and must pass through the supposedly immutable celestial spheres.
As an astronomer, Tycho worked to combine what he saw as the geometrical benefits of the Copernican system with the philosophical benefits of the Ptolemaic system into his own model of the universe, the Tychonic system. Furthermore, he was the last of the major naked eye astronomers, working without telescopes for his observations.
Tycho was granted an estate on the island of Hven and the funding to build Uraniborg, an early research institute, where he built large astronomical instruments and took many careful measurements, and later Stjerneborg, underground, when he discovered that his instruments in Uraniborg were not sufficiently steady. On the island (where he behaved autocratically toward the residents) he founded manufactories, such as a paper mill, to provide material for printing his results.
After disagreements with the new Danish king, Christian IV, in 1597, he was invited by the Bohemian king and Holy Roman emperor Rudolph II to Prague, where he became the official imperial astronomer. He built an observatory at Benátky nad Jizerou. There, from 1600 until his death in 1601, he was assisted by Johannes Kepler, who later used Tycho's astronomical data to develop his three laws of planetary motion.
Tycho's body has been exhumed twice, in 1901 and 2010, to examine the circumstances of his death and to identify the material from which his artificial nose was made. The conclusion was that his death was likely caused by a burst bladder, as had been suggested, and that the artificial nose was more likely made of brass than silver or gold, as some had believed in his time."
United Kingdom	"The United Kingdom of Great Britain and Northern Ireland, commonly known as the United Kingdom (UK) or Britain, is a sovereign state in Europe. Lying off the north-western coast of the European mainland, it includes the island of Great Britain (the name of which is also loosely applied to the whole country), the north-eastern part of the island of Ireland and many smaller islands. Northern Ireland is the only part of the UK that shares a land border with another state—the Republic of Ireland. Apart from this land border, the UK is surrounded by the Atlantic Ocean, with the North Sea to its east, the English Channel to its south and the Celtic Sea to its south-southwest. The Irish Sea lies between Great Britain and Ireland. With an area of 93,800 square miles (243,000 km2), the UK is the 80th-largest sovereign state in the world and the 11th-largest in Europe. It is also the 21st-most populous country, with an estimated 64.5 million inhabitants.
The United Kingdom is a constitutional monarchy with a parliamentary system of governance. Its capital city is London, an important global city and financial centre with an urban population of 10,310,000, the fourth-largest in Europe and second-largest in the European Union. The current monarch—since 6 February 1952—is Queen Elizabeth II. The UK consists of four countries: England, Scotland, Wales, and Northern Ireland. The latter three have devolved administrations, each with varying powers, based in their capitals, Edinburgh, Cardiff, and Belfast, respectively. The nearby Isle of Man, Bailiwick of Guernsey and Bailiwick of Jersey are not part of the United Kingdom, being Crown dependencies with the British Government responsible for defence and international representation.
The relationships among the countries of the United Kingdom have changed over time. Wales was annexed by the Kingdom of England under the Acts of Union of 1536 and 1542. A treaty between England and Scotland resulted in 1707 in a unified Kingdom of Great Britain, which merged in 1801 with the Kingdom of Ireland to form the United Kingdom of Great Britain and Ireland. In 1922, five-sixths of Ireland seceded from the country, leaving the present formulation of the United Kingdom of Great Britain and Northern Ireland. The UK has fourteen Overseas Territories. These are the remnants of the British Empire which, at its height in the 1920s, encompassed almost a quarter of the world's land mass and was the largest empire in history. British influence can be observed in the language, culture, and legal systems of many of its former colonies.
The United Kingdom is a developed country and has the world's fifth-largest economy by nominal GDP and ninth-largest economy by purchasing power parity. The UK is considered to have a high-income economy and is categorised as very high in the Human Development Index, currently ranking 14th in the world. It was the world's first industrialised country and the world's foremost power during the 19th and early 20th centuries. The UK remains a great power with considerable economic, cultural, military, scientific, and political influence internationally. It is a recognised nuclear weapons state and its military expenditure ranks fourth or fifth in the world. The UK has been a permanent member of the United Nations Security Council since its first session in 1946. It has been a member state of the European Union (EU) and its predecessor, the European Economic Community (EEC), since 1973; it is also a member of the Commonwealth of Nations, the Council of Europe, the G7 finance ministers, the G7 forum, the G20, NATO, the Organisation for Economic Co-operation and Development (OECD), and the World Trade Organization (WTO)."
United States	"The United States of America (commonly referred to as the United States, U.S., USA, or America), is a federal republic composed of 50 states, a federal district of Washington, D,C., five major territories, and various possessions. The 48 contiguous states and Washington, D.C., are in central North America between Canada and Mexico. The state of Alaska is in the northwestern part of North America and the state of Hawaii is an archipelago in the mid-Pacific. The territories are scattered about the Pacific Ocean and the Caribbean Sea. At 3.8 million square miles (9.9 million km2) and with over 320 million people, the country is the world's third largest by total area (fourth largest by land area) and the third most populous. It is one of the world's most ethnically diverse and multicultural nations, the product of large-scale immigration from many countries. The geography and climate of the United States are also extremely diverse, and the country is home to a wide variety of wildlife.
Paleo-Indians migrated from Eurasia to what is now the U.S. mainland at least 15,000 years ago, with European colonization beginning in the 16th century. The United States emerged from 13 British colonies along the East Coast. Disputes between Great Britain and the colonies led to the American Revolution. On July 4, 1776, as the colonies were fighting Great Britain in the American Revolutionary War, delegates from the 13 colonies unanimously adopted the Declaration of Independence. The war ended in 1783 with recognition of the independence of the United States by the Kingdom of Great Britain, and was the first successful war of independence against a European colonial empire. The country's constitution was adopted on September 17, 1787, and ratified by the states in 1788. The first ten amendments, collectively named the Bill of Rights, were ratified in 1791 and designed to guarantee many fundamental civil liberties.
Driven by the doctrine of Manifest Destiny, the United States embarked on a vigorous expansion across North America throughout the 19th century. This involved displacing American Indian tribes, acquiring new territories, and gradually admitting new states, until by 1848 the nation spanned the continent. During the second half of the 19th century, the American Civil War ended legal slavery in the country. By the end of that century, the United States extended into the Pacific Ocean, and its economy, driven in large part by the Industrial Revolution, began to soar. The Spanish–American War and World War I confirmed the country's status as a global military power. The United States emerged from World War II as a global superpower, the first country to develop nuclear weapons, the only country to use them in warfare, and a permanent member of the United Nations Security Council. The end of the Cold War and the dissolution of the Soviet Union in 1991 left the United States as the world's sole superpower.
The United States is a developed country and has the world's largest national economy by nominal and real GDP, benefiting from an abundance of natural resources and high worker productivity. While the U.S. economy is considered post-industrial, the country continues to be one of the world's largest manufacturers. Accounting for 34% of global military spending and 23% of world GDP, it is the world's foremost military and economic power, a prominent political and cultural force, and a leader in scientific research and technological innovations."
Universe	"The Universe is all of time and space and its contents. The Universe includes planets, stars, galaxies, the contents of intergalactic space, the smallest subatomic particles, and all matter and energy. The observable universe is about 28 billion parsecs (91 billion light-years) in diameter at the present time. The size of the whole Universe is not known and may be either finite or infinite. Observations and the development of physical theories have led to inferences about the composition and evolution of the Universe.
Throughout recorded history, cosmologies and cosmogonies, including scientific models, have been proposed to explain observations of the Universe. The earliest quantitative geocentric models were developed by ancient Greek philosophers and Indian philosophers. Over the centuries, more precise astronomical observations led to Nicolaus Copernicus's heliocentric model of the Solar System and, based on observations by Tycho Brahe, Johannes Kepler's improvement on that model with elliptical orbits, which was eventually explained by Isaac Newton's theory of gravity. Further observational improvements led to the realization that the Solar System is located in a galaxy composed of billions of stars, the Milky Way. It was subsequently discovered that our galaxy is just one of many. On the largest scales, it is assumed that the distribution of galaxies is uniform and the same in all directions, meaning that the Universe has neither an edge nor a center. Observations of the distribution of these galaxies and their spectral lines have led to many of the theories of modern physical cosmology. The discovery in the early 20th century that galaxies are systematically redshifted suggested that the Universe is expanding, and the discovery of the cosmic microwave background radiation suggested that the Universe had a beginning. Finally, observations in the late 1990s indicated the rate of the expansion of the Universe is increasing indicating that the majority of energy is most likely in an unknown form called dark energy. The majority of mass in the universe also appears to exist in an unknown form, called dark matter.
The Big Bang theory is the prevailing cosmological model describing the development of the Universe. Space and time were created in the Big Bang, and these were imbued with a fixed amount of energy and matter; as space expands, the density of that matter and energy decreases. After the initial expansion, the Universe cooled sufficiently to allow the formation first of subatomic particles and later of simple atoms. Giant clouds of these primordial elements later coalesced through gravity to form stars. Assuming that the prevailing model is correct, the age of the Universe is measured to be 7001137990000000000♠13.799±0.021 billion years.
There are many competing hypotheses about the ultimate fate of the Universe. Physicists and philosophers remain unsure about what, if anything, preceded the Big Bang. Many refuse to speculate, doubting that any information from any such prior state could ever be accessible. There are various multiverse hypotheses, in which some physicists have suggested that the Universe might be one among many universes that likewise exist."
Vaccination	"Vaccination is the administration of antigenic material (a vaccine) to stimulate an individual's immune system to develop adaptive immunity to a pathogen. Vaccines can prevent or ameliorate morbidity from infection. When a sufficiently large percentage of a population has been vaccinated, this results in herd immunity. The effectiveness of vaccination has been widely studied and verified; for example, the influenza vaccine, the HPV vaccine, and the chicken pox vaccine. Vaccination is the most effective method of preventing infectious diseases; widespread immunity due to vaccination is largely responsible for the worldwide eradication of smallpox and the restriction of diseases such as polio, measles, and tetanus from much of the world. The World Health Organization (WHO) reports that licensed vaccines are currently available to prevent or contribute to the prevention and control of twenty-five preventable infections.
The active agent of a vaccine may be intact but inactivated (non-infective) or attenuated (with reduced infectivity) forms of the causative pathogens, or purified components of the pathogen that have been found to be highly immunogenic (e.g., outer coat proteins of a virus). Toxoids are produced for immunization against toxin-based diseases, such as the modification of tetanospasmin toxin of tetanus to remove its toxic effect but retain its immunogenic effect.
Smallpox was most likely the first disease people tried to prevent by inoculating themselves and was the first disease for which a vaccine was produced. The smallpox vaccine was discovered in 1796 by the British physician Edward Jenner, although at least six people had used the same principles years earlier. Louis Pasteur furthered the concept through his work in microbiology. The immunization was called vaccination because it was derived from a virus affecting cows (Latin: vacca—cow). Smallpox was a contagious and deadly disease, causing the deaths of 20–60% of infected adults and over 80% of infected children. When smallpox was finally eradicated in 1979, it had already killed an estimated 300–500 million people in the 20th century.
In common speech, vaccination and immunization have a similar meaning. This distinguishes it from inoculation, which uses unweakened live pathogens, although in common usage either can refer to an immunization. Vaccination efforts have been met with some controversy on scientific, ethical, political, medical safety, and religious grounds. In rare cases, vaccinations can injure people and, in the United States, they may receive compensation for those injuries under the National Vaccine Injury Compensation Program. Early success and compulsion brought widespread acceptance, and mass vaccination campaigns have greatly reduced the incidence of many diseases in numerous geographic regions."
Vannevar Bush	"Vannevar Bush (/væˈniːvɑːr/ van-NEE-var; March 11, 1890 – June 28, 1974) was an American engineer, inventor and science administrator, who during World War II headed the U.S. Office of Scientific Research and Development (OSRD), through which almost all wartime military R&D was carried out, including initiation and early administration of the Manhattan Project. He is also known in engineering for his work on analog computers, for founding Raytheon, and for the memex, a hypothetical adjustable microfilm viewer with a structure analogous to that of hypertext. In 1945, Bush published the essay ""As We May Think"" in which he predicted that ""wholly new forms of encyclopedias will appear, ready made with a mesh of associative trails running through them, ready to be dropped into the memex and there amplified"". The memex influenced generations of computer scientists, who drew inspiration from its vision of the future. He was chiefly responsible for the movement that led to the creation of the National Science Foundation.
For his master's thesis, Bush invented and patented a ""profile tracer"", a mapping device for assisting surveyors. It was the first of a string of inventions. He joined the Department of Electrical Engineering at Massachusetts Institute of Technology (MIT) in 1919, and founded the company now known as Raytheon in 1922. Starting in 1927, Bush constructed a differential analyzer, an analog computer with some digital components that could solve differential equations with as many as 18 independent variables. An offshoot of the work at MIT by Bush and others was the beginning of digital circuit design theory. Bush became vice president of MIT and dean of the MIT School of Engineering in 1932, and president of the Carnegie Institution of Washington in 1938.
Bush was appointed to the National Advisory Committee for Aeronautics (NACA) in 1938, and soon became its chairman. As chairman of the National Defense Research Committee (NDRC), and later director of OSRD, Bush coordinated the activities of some six thousand leading American scientists in the application of science to warfare. Bush was a well-known policymaker and public intellectual during World War II, when he was in effect the first presidential science advisor. As head of NDRC and OSRD, he initiated the Manhattan Project, and ensured that it received top priority from the highest levels of government. In Science, The Endless Frontier, his 1945 report to the President of the United States, Bush called for an expansion of government support for science, and he pressed for the creation of the National Science Foundation."
Virus	"A virus is a small infectious agent that replicates only inside the living cells of other organisms. Viruses can infect all types of life forms, from animals and plants to microorganisms, including bacteria and archaea.
Since Dmitri Ivanovsky's 1892 article describing a non-bacterial pathogen infecting tobacco plants, and the discovery of the tobacco mosaic virus by Martinus Beijerinck in 1898, about 5,000 virus species have been described in detail, although there are millions of types. Viruses are found in almost every ecosystem on Earth and are the most abundant type of biological entity. The study of viruses is known as virology, a sub-speciality of microbiology.
While not inside an infected cell or in the process of infecting a cell, viruses exist in the form of independent particles. These viral particles, also known as virions, consist of two or three parts: (i) the genetic material made from either DNA or RNA, long molecules that carry genetic information; (ii) a protein coat, called the capsid, which surrounds and protects the genetic material; and in some cases (iii) an envelope of lipids that surrounds the protein coat when they are outside a cell. The shapes of these virus particles range from simple helical and icosahedral forms for some virus species to more complex structures for others. Most virus species have virions that are too small to be seen with an optical microscope. The average virion is about one one-hundredth the size of the average bacterium.
The origins of viruses in the evolutionary history of life are unclear: some may have evolved from plasmids—pieces of DNA that can move between cells—while others may have evolved from bacteria. In evolution, viruses are an important means of horizontal gene transfer, which increases genetic diversity. Viruses are considered by some to be a life form, because they carry genetic material, reproduce, and evolve through natural selection. However they lack key characteristics (such as cell structure) that are generally considered necessary to count as life. Because they possess some but not all such qualities, viruses have been described as ""organisms at the edge of life"".
Viruses spread in many ways; viruses in plants are often transmitted from plant to plant by insects that feed on plant sap, such as aphids; viruses in animals can be carried by blood-sucking insects. These disease-bearing organisms are known as vectors. Influenza viruses are spread by coughing and sneezing. Norovirus and rotavirus, common causes of viral gastroenteritis, are transmitted by the faecal–oral route and are passed from person to person by contact, entering the body in food or water. HIV is one of several viruses transmitted through sexual contact and by exposure to infected blood. The range of host cells that a virus can infect is called its ""host range"". This can be narrow, meaning a virus is capable of infecting few species, or broad, meaning it is capable of infecting many.
Viral infections in animals provoke an immune response that usually eliminates the infecting virus. Immune responses can also be produced by vaccines, which confer an artificially acquired immunity to the specific viral infection. However, some viruses including those that cause AIDS and viral hepatitis evade these immune responses and result in chronic infections. Antibiotics have no effect on viruses, but several antiviral drugs have been developed."
Watch	"A watch is a small timepiece intended to be carried or worn by a person. It is designed to keep working despite the motions caused by the person's activities. A wristwatch is designed to be worn on a wrist, attached by a watch strap or other type of bracelet. A pocket watch is designed for a person to carry in a pocket.
Watches evolved in the 17th century from spring-powered clocks, which appeared as early as the 14th century. The first watches were strictly mechanical, driven by clockwork. As technology progressed, mechanical devices, used to control the speed of the watch, were largely superseded by vibrating quartz crystals that produce accurately timed electronic pulses. Some watches use radio clock technology to regularly correct the time. The first digital electronic watch was developed in 1970.
Most inexpensive and medium-priced watches, used mainly for timekeeping, are electronic watches with quartz movements. Expensive collectible watches, valued more for their elaborate craftsmanship, aesthetic appeal and glamorous design than for simple timekeeping, often have purely mechanical movements and are powered by springs, even though these movements are generally less accurate and more expensive than electronic ones. Various extra features, called ""complications"", such as moon-phase displays and the different types of tourbillon, are sometimes included. Modern watches often display the day, date, month and year, and electronic watches may have many other functions. Time-related features such as timers, chronographs and alarm functions are common. Some modern designs incorporate calculators, GPS and Bluetooth technology or have heart-rate monitoring capabilities. Watches incorporating GPS receivers use them not only to determine their position. They also receive and use time signals from the satellites, which make them essentially perfectly accurate timekeepers, even over long periods of time.
Developments in the 2010s include smartwatches, which are elaborate computer-like electronic devices designed to be worn on a wrist. They generally incorporate timekeeping functions, but these are only small fractions of what the watch can do.
The study of timekeeping is known as horology."
Weather prediction	"Weather forecasting is the application of science and technology to predict the state of the atmosphere for a given location. Human beings have attempted to predict the weather informally for millennia, and formally since the nineteenth century. Weather forecasts are made by collecting quantitative data about the current state of the atmosphere at a given place and using scientific understanding of atmospheric processes to project how the atmosphere will change.
Once an all-human endeavor based mainly upon changes in barometric pressure, current weather conditions, and sky condition, weather forecasting now relies on computer-based models that take many atmospheric factors into account. Human input is still required to pick the best possible forecast model to base the forecast upon, which involves pattern recognition skills, teleconnections, knowledge of model performance, and knowledge of model biases. The chaotic nature of the atmosphere, the massive computational power required to solve the equations that describe the atmosphere, error involved in measuring the initial conditions, and an incomplete understanding of atmospheric processes mean that forecasts become less accurate as the difference in current time and the time for which the forecast is being made (the range of the forecast) increases. The use of ensembles and model consensus help narrow the error and pick the most likely outcome.
There are a variety of end uses to weather forecasts. Weather warnings are important forecasts because they are used to protect life and property. Forecasts based on temperature and precipitation are important to agriculture, and therefore to traders within commodity markets. Temperature forecasts are used by utility companies to estimate demand over coming days. On an everyday basis, people use weather forecasts to determine what to wear on a given day. Since outdoor activities are severely curtailed by heavy rain, snow and the wind chill, forecasts can be used to plan activities around these events, and to plan ahead and survive them."
Web engineering	"The World Wide Web has become a major delivery platform for a variety of complex and sophisticated enterprise applications in several domains. In addition to their inherent multifaceted functionality, these Web applications exhibit complex behavior and place some unique demands on their usability, performance, security and ability to grow and evolve. However, a vast majority of these applications continue to be developed in an ad-hoc way, contributing to problems of usability, maintainability, quality and reliability. While Web development can benefit from established practices from other related disciplines, it has certain distinguishing characteristics that demand special considerations. In recent years, there have been developments towards addressing these considerations.
As an emerging discipline, Web engineering actively promotes systematic, disciplined and quantifiable approaches towards successful development of high-quality, ubiquitously usable Web-based systems and applications. In particular, Web engineering focuses on the methodologies, techniques and tools that are the foundation of Web application development and which support their design, development, evolution, and evaluation. Web application development has certain characteristics that make it different from traditional software, information system, or computer application development.
Web engineering is multidisciplinary and encompasses contributions from diverse areas: systems analysis and design, software engineering, hypermedia/hypertext engineering, requirements engineering, human-computer interaction, user interface, information engineering, information indexing and retrieval, testing, modelling and simulation, project management, and graphic design and presentation. Web engineering is neither a clone, nor a subset of software engineering, although both involve programming and software development. While Web Engineering uses software engineering principles, it encompasses new approaches, methodologies, tools, techniques, and guidelines to meet the unique requirements of Web-based applications."
Willard Van Orman Quine	"Willard Van Orman Quine (/kwaɪn/; June 25, 1908 – December 25, 2000) (known to intimates as ""Van"") was an American philosopher and logician in the analytic tradition, recognized as ""one of the most influential philosophers of the twentieth century."" From 1930 until his death 70 years later, Quine was continually affiliated with Harvard University in one way or another, first as a student, then as a professor of philosophy and a teacher of logic and set theory, and finally as a professor emeritus who published or revised several books in retirement. He filled the Edgar Pierce Chair of Philosophy at Harvard from 1956 to 1978. A 2009 poll conducted among analytic philosophers named Quine as the fifth most important philosopher of the past two centuries. He won the first Schock Prize in Logic and Philosophy in 1993 for ""his systematical and penetrating discussions of how learning of language and communication are based on socially available evidence and of the consequences of this for theories on knowledge and linguistic meaning."" In 1996 he was awarded the Kyoto Prize in Arts and Philosophy for his ""outstanding contributions to the progress of philosophy in the 20th century by proposing numerous theories based on keen insights in logic, epistemology, philosophy of science and philosophy of language.""
Quine falls squarely into the analytic philosophy tradition while also being the main proponent of the view that philosophy is not conceptual analysis but the abstract branch of the empirical sciences. His major writings include ""Two Dogmas of Empiricism"" (1951), which attacked the distinction between analytic and synthetic propositions and advocated a form of semantic holism, and Word and Object (1960), which further developed these positions and introduced Quine's famous indeterminacy of translation thesis, advocating a behaviorist theory of meaning. He also developed an influential naturalized epistemology that tried to provide ""an improved scientific explanation of how we have developed elaborate scientific theories on the basis of meager sensory input."" He is also important in philosophy of science for his ""systematic attempt to understand science from within the resources of science itself"" and for his conception of philosophy as continuous with science. This led to his famous quip that ""philosophy of science is philosophy enough."" In philosophy of mathematics, he and his Harvard colleague Hilary Putnam developed the ""Quine–Putnam indispensability thesis,"" an argument for the reality of mathematical entities."
Women in science	"Women have made significant contributions to science from the earliest times. Historians with an interest in gender and science have illuminated the scientific endeavors and accomplishments of women, the barriers they have faced, and the strategies implemented to have their work peer-reviewed and accepted in major scientific journals and other publications. The historical, critical and sociological study of these issues has become an academic discipline in its own right.
The involvement of women in the field of medicine occurred in several early civilizations and the study of natural philosophy in ancient Greece was open to women. Women contributed to the proto-science of alchemy in the first or second centuries AD. During the Middle Ages, convents were an important place of education for women, and some of these communities provided opportunities for women to contribute to scholarly research. While the eleventh century saw the emergence of the first universities, women were, for the most part, excluded from university education. The attitude to educating women in medical fields in Italy appears to have been more liberal than in other places. The first known woman to earn a university chair in a scientific field of studies, was eighteenth century Italian scientist, Laura Bassi.
Although gender roles were largely defined in the eighteenth century, women experienced great advances in science. During the nineteenth century, women were excluded from most formal scientific education, but they began to be admitted into learned societies during this period. In the later nineteenth century the rise of the women's college provided jobs for women scientists, and opportunities for education. Marie Curie, the first woman to win a Nobel prize in 1903 (physics), went on to become a double Nobel prize winner in 1911 (chemistry), both for her work on radiation. Forty women have been awarded the Nobel Prize between 1901 and 2010. 16 women have been awarded the Nobel Prize in physics, chemistry, physiology or medicine."
X-ray	"X-radiation (composed of X-rays) is a form of electromagnetic radiation. Most X-rays have a wavelength ranging from 0.01 to 10 nanometers, corresponding to frequencies in the range 30 petahertz to 30 exahertz (3×1016 Hz to 3×1019 Hz) and energies in the range 100 eV to 100 keV. X-ray wavelengths are shorter than those of UV rays and typically longer than those of gamma rays. In many languages, X-radiation is referred to with terms meaning Röntgen radiation, after Wilhelm Röntgen, who is usually credited as its discoverer, and who had named it X-radiation to signify an unknown type of radiation. Spelling of X-ray(s) in the English language includes the variants x-ray(s), xray(s), and X ray(s).
X-rays with photon energies above 5–10 keV (below 0.2–0.1 nm wavelength) are called hard X-rays, while those with lower energy are called soft X-rays. Due to their penetrating ability, hard X-rays are widely used to image the inside of objects, e.g., in medical radiography and airport security. As a result, the term X-ray is metonymically used to refer to a radiographic image produced using this method, in addition to the method itself. Since the wavelengths of hard X-rays are similar to the size of atoms they are also useful for determining crystal structures by X-ray crystallography. By contrast, soft X-rays are easily absorbed in air; the attenuation length of 600 eV (~2 nm) X-rays in water is less than 1 micrometer.
There is no consensus for a definition distinguishing between X-rays and gamma rays. One common practice is to distinguish between the two types of radiation based on their source: X-rays are emitted by electrons, while gamma rays are emitted by the atomic nucleus. This definition has several problems: other processes also can generate these high-energy photons, or sometimes the method of generation is not known. One common alternative is to distinguish X- and gamma radiation on the basis of wavelength (or, equivalently, frequency or photon energy), with radiation shorter than some arbitrary wavelength, such as 10−11 m (0.1 Å), defined as gamma radiation. This criterion assigns a photon to an unambiguous category, but is only possible if wavelength is known. (Some measurement techniques do not distinguish between detected wavelengths.) However, these two definitions often coincide since the electromagnetic radiation emitted by X-ray tubes generally has a longer wavelength and lower photon energy than the radiation emitted by radioactive nuclei. Occasionally, one term or the other is used in specific contexts due to historical precedent, based on measurement (detection) technique, or based on their intended use rather than their wavelength or source. Thus, gamma-rays generated for medical and industrial uses, for example radiotherapy, in the ranges of 6–20 MeV, can in this context also be referred to as X-rays."
X-rays	"X-radiation (composed of X-rays) is a form of electromagnetic radiation. Most X-rays have a wavelength ranging from 0.01 to 10 nanometers, corresponding to frequencies in the range 30 petahertz to 30 exahertz (3×1016 Hz to 3×1019 Hz) and energies in the range 100 eV to 100 keV. X-ray wavelengths are shorter than those of UV rays and typically longer than those of gamma rays. In many languages, X-radiation is referred to with terms meaning Röntgen radiation, after Wilhelm Röntgen, who is usually credited as its discoverer, and who had named it X-radiation to signify an unknown type of radiation. Spelling of X-ray(s) in the English language includes the variants x-ray(s), xray(s), and X ray(s).
X-rays with photon energies above 5–10 keV (below 0.2–0.1 nm wavelength) are called hard X-rays, while those with lower energy are called soft X-rays. Due to their penetrating ability, hard X-rays are widely used to image the inside of objects, e.g., in medical radiography and airport security. As a result, the term X-ray is metonymically used to refer to a radiographic image produced using this method, in addition to the method itself. Since the wavelengths of hard X-rays are similar to the size of atoms they are also useful for determining crystal structures by X-ray crystallography. By contrast, soft X-rays are easily absorbed in air; the attenuation length of 600 eV (~2 nm) X-rays in water is less than 1 micrometer.
There is no consensus for a definition distinguishing between X-rays and gamma rays. One common practice is to distinguish between the two types of radiation based on their source: X-rays are emitted by electrons, while gamma rays are emitted by the atomic nucleus. This definition has several problems: other processes also can generate these high-energy photons, or sometimes the method of generation is not known. One common alternative is to distinguish X- and gamma radiation on the basis of wavelength (or, equivalently, frequency or photon energy), with radiation shorter than some arbitrary wavelength, such as 10−11 m (0.1 Å), defined as gamma radiation. This criterion assigns a photon to an unambiguous category, but is only possible if wavelength is known. (Some measurement techniques do not distinguish between detected wavelengths.) However, these two definitions often coincide since the electromagnetic radiation emitted by X-ray tubes generally has a longer wavelength and lower photon energy than the radiation emitted by radioactive nuclei. Occasionally, one term or the other is used in specific contexts due to historical precedent, based on measurement (detection) technique, or based on their intended use rather than their wavelength or source. Thus, gamma-rays generated for medical and industrial uses, for example radiotherapy, in the ranges of 6–20 MeV, can in this context also be referred to as X-rays."
Yuval Levin	"Yuval Levin is an Israeli-born American political analyst, public intellectual, academic and journalist who is the founding Editor of National Affairs. He has been called ""probably the most influential conservative intellectual of the Obama era"", while The New Republic has dubbed Levin ""the right's new Irving Kristol."" Levin is also a fellow at the Ethics and Public Policy Center, a conservative think tank in Washington, D.C. In 2005 and 2006, he was a member of the White House domestic policy staff. He is the former chief of staff of the President's Council on Bioethics, a former Congressional staffer, contributing editor to National Review and the Weekly Standard, and one of the founders of The New Atlantis, where he still remains as a Senior Editor.
He is the author of Tyranny of Reason, Imagining the Future, The Great Debate: Edmund Burke, Thomas Paine, and the Birth of Left and Right and of numerous essays and articles dealing largely with political theory, science, technology, and public policy. On the relationship between political theory and public policy, Levin has said, ""For me, these things are very deeply connected. I think politics really is rooted in political philosophy, is much better understood when it’s understood in light of political philosophy. And that a lot of the policy debates we have make much more sense if you see that people are arguing about two ways of understanding what the human person is, what human society is, and especially what the liberal society is. The left and right in our country are both liberal, they both believe in the free society, but they mean something very different by that.""
In describing conservatism, Levin was said, ""That’s what conservatism really means, fundamentally, is to understand society not as just individuals and government, but to think of it in terms of everything happens in between. That huge space between the individual and the state is where society actually is. And that’s where families are, it’s where communities are, it’s where the market economy is."" 
Levin was trained in political science at American University and earned a PhD from the Committee on Social Thought at the University of Chicago."
